# Story 7.2: 性能优化与扩展

## Status
Draft

## Story
**As a** 系统架构师和运维工程师,
**I want** 一个高性能、可扩展的系统架构，能够支持大规模并发访问和数据处理,
**so that** 系统能够在高负载下保持稳定运行，并能够根据业务需求进行水平和垂直扩展

## Acceptance Criteria
1. 实现系统性能监控和分析，识别性能瓶颈
2. 建立缓存策略和分布式缓存系统
3. 实现数据库查询优化和连接池管理
4. 建立负载均衡和服务发现机制
5. 实现异步处理和消息队列优化
6. 建立自动扩缩容机制
7. 实现CDN和静态资源优化
8. 建立性能测试和压力测试体系

## Tasks / Subtasks
- [ ] 实现性能监控分析 (AC: 1)
  - [ ] 建立性能指标收集体系
  - [ ] 实现APM（应用性能监控）
  - [ ] 开发性能瓶颈识别算法
  - [ ] 建立性能基线和趋势分析
- [ ] 建立缓存系统 (AC: 2)
  - [ ] 设计多级缓存架构
  - [ ] 实现分布式缓存集群
  - [ ] 开发缓存预热和失效策略
  - [ ] 建立缓存一致性保证机制
- [ ] 优化数据库性能 (AC: 3)
  - [ ] 实现查询优化和索引策略
  - [ ] 建立数据库连接池管理
  - [ ] 实现读写分离和分库分表
  - [ ] 开发数据库监控和调优工具
- [ ] 实现负载均衡 (AC: 4)
  - [ ] 建立服务发现和注册中心
  - [ ] 实现智能负载均衡算法
  - [ ] 开发健康检查和故障转移
  - [ ] 建立服务熔断和限流机制
- [ ] 优化异步处理 (AC: 5)
  - [ ] 实现高性能消息队列
  - [ ] 开发异步任务调度系统
  - [ ] 建立消息可靠性保证机制
  - [ ] 实现批处理和流处理优化
- [ ] 建立自动扩缩容 (AC: 6)
  - [ ] 实现基于指标的自动扩缩容
  - [ ] 开发预测性扩容算法
  - [ ] 建立容器编排和管理
  - [ ] 实现资源调度和优化
- [ ] 实现CDN优化 (AC: 7)
  - [ ] 建立CDN分发策略
  - [ ] 实现静态资源压缩和合并
  - [ ] 开发图片和视频优化
  - [ ] 建立缓存策略和更新机制
- [ ] 建立性能测试体系 (AC: 8)
  - [ ] 实现自动化性能测试
  - [ ] 开发压力测试和负载测试
  - [ ] 建立性能回归测试
  - [ ] 实现性能报告和分析

## Dev Notes

### 架构上下文
性能优化与扩展是Knowledge_RAG系统的关键非功能性需求，需要在系统架构的各个层面进行优化，包括应用层、缓存层、数据库层、网络层等。系统需要支持高并发、大数据量的处理，同时保证低延迟和高可用性。

### 核心技术要求
- **缓存技术**: Redis Cluster、Caffeine、Hazelcast
- **数据库优化**: 连接池（HikariCP）、读写分离、分库分表（ShardingSphere）
- **负载均衡**: Nginx、HAProxy、Spring Cloud LoadBalancer
- **消息队列**: Apache Kafka、RabbitMQ、Apache Pulsar
- **容器编排**: Kubernetes、Docker Swarm
- **监控工具**: Prometheus、Grafana、APM工具
- **CDN服务**: CloudFlare、阿里云CDN、腾讯云CDN
- **性能测试**: JMeter、Gatling、K6

### 性能优化核心架构

#### 性能监控服务
```java
// PerformanceMonitoringService.java
@Service
@Slf4j
public class PerformanceMonitoringService {
    
    private final MeterRegistry meterRegistry;
    private final PerformanceMetricsRepository metricsRepository;
    private final AlertManager alertManager;
    private final RedisTemplate<String, Object> redisTemplate;
    
    /**
     * 记录API性能指标
     */
    public void recordApiPerformance(String apiPath, String method, long responseTime, int statusCode) {
        try {
            // 记录响应时间
            Timer.Sample sample = Timer.start(meterRegistry);
            sample.stop(Timer.builder("api.response.time")
                .description("API response time")
                .tag("path", apiPath)
                .tag("method", method)
                .tag("status", String.valueOf(statusCode))
                .register(meterRegistry));
            
            // 记录请求计数
            Counter.builder("api.requests.total")
                .description("Total API requests")
                .tag("path", apiPath)
                .tag("method", method)
                .tag("status", String.valueOf(statusCode))
                .register(meterRegistry)
                .increment();
            
            // 记录错误率
            if (statusCode >= 400) {
                Counter.builder("api.errors.total")
                    .description("Total API errors")
                    .tag("path", apiPath)
                    .tag("method", method)
                    .tag("status", String.valueOf(statusCode))
                    .register(meterRegistry)
                    .increment();
            }
            
            // 检查性能阈值
            checkPerformanceThresholds(apiPath, method, responseTime, statusCode);
            
        } catch (Exception e) {
            log.error("Failed to record API performance metrics", e);
        }
    }
    
    /**
     * 记录数据库性能指标
     */
    public void recordDatabasePerformance(String operation, String table, long executionTime, boolean success) {
        try {
            // 记录执行时间
            Timer.builder("database.query.time")
                .description("Database query execution time")
                .tag("operation", operation)
                .tag("table", table)
                .tag("success", String.valueOf(success))
                .register(meterRegistry)
                .record(executionTime, TimeUnit.MILLISECONDS);
            
            // 记录查询计数
            Counter.builder("database.queries.total")
                .description("Total database queries")
                .tag("operation", operation)
                .tag("table", table)
                .tag("success", String.valueOf(success))
                .register(meterRegistry)
                .increment();
            
            // 记录慢查询
            if (executionTime > getSlowQueryThreshold()) {
                Counter.builder("database.slow.queries.total")
                    .description("Total slow database queries")
                    .tag("operation", operation)
                    .tag("table", table)
                    .register(meterRegistry)
                    .increment();
                
                // 记录慢查询详情
                recordSlowQuery(operation, table, executionTime);
            }
            
        } catch (Exception e) {
            log.error("Failed to record database performance metrics", e);
        }
    }
    
    /**
     * 记录缓存性能指标
     */
    public void recordCachePerformance(String cacheName, String operation, boolean hit) {
        try {
            // 记录缓存命中率
            Counter.builder("cache.operations.total")
                .description("Total cache operations")
                .tag("cache", cacheName)
                .tag("operation", operation)
                .tag("result", hit ? "hit" : "miss")
                .register(meterRegistry)
                .increment();
            
            // 更新缓存命中率统计
            updateCacheHitRateStatistics(cacheName, hit);
            
        } catch (Exception e) {
            log.error("Failed to record cache performance metrics", e);
        }
    }
    
    /**
     * 获取性能报告
     */
    public PerformanceReport getPerformanceReport(Instant startTime, Instant endTime) {
        try {
            return PerformanceReport.builder()
                .timeRange(TimeRange.of(startTime, endTime))
                .apiMetrics(getApiMetrics(startTime, endTime))
                .databaseMetrics(getDatabaseMetrics(startTime, endTime))
                .cacheMetrics(getCacheMetrics(startTime, endTime))
                .systemMetrics(getSystemMetrics(startTime, endTime))
                .bottlenecks(identifyBottlenecks(startTime, endTime))
                .recommendations(generateOptimizationRecommendations(startTime, endTime))
                .build();
        } catch (Exception e) {
            log.error("Failed to generate performance report", e);
            throw new PerformanceReportException("Failed to generate performance report", e);
        }
    }
    
    /**
     * 识别性能瓶颈
     */
    public List<PerformanceBottleneck> identifyBottlenecks(Instant startTime, Instant endTime) {
        List<PerformanceBottleneck> bottlenecks = new ArrayList<>();
        
        try {
            // 分析API性能瓶颈
            bottlenecks.addAll(analyzeApiBottlenecks(startTime, endTime));
            
            // 分析数据库性能瓶颈
            bottlenecks.addAll(analyzeDatabaseBottlenecks(startTime, endTime));
            
            // 分析缓存性能瓶颈
            bottlenecks.addAll(analyzeCacheBottlenecks(startTime, endTime));
            
            // 分析系统资源瓶颈
            bottlenecks.addAll(analyzeSystemResourceBottlenecks(startTime, endTime));
            
            // 按严重程度排序
            bottlenecks.sort(Comparator.comparing(PerformanceBottleneck::getSeverity).reversed());
            
            return bottlenecks;
            
        } catch (Exception e) {
            log.error("Failed to identify performance bottlenecks", e);
            return Collections.emptyList();
        }
    }
    
    private void checkPerformanceThresholds(String apiPath, String method, long responseTime, int statusCode) {
        // 检查响应时间阈值
        long responseTimeThreshold = getResponseTimeThreshold(apiPath);
        if (responseTime > responseTimeThreshold) {
            alertManager.triggerPerformanceAlert(
                "High API Response Time",
                String.format("API %s %s response time %dms exceeds threshold %dms", 
                    method, apiPath, responseTime, responseTimeThreshold),
                AlertSeverity.WARNING
            );
        }
        
        // 检查错误率
        if (statusCode >= 500) {
            double errorRate = calculateErrorRate(apiPath, method);
            double errorRateThreshold = getErrorRateThreshold();
            
            if (errorRate > errorRateThreshold) {
                alertManager.triggerPerformanceAlert(
                    "High API Error Rate",
                    String.format("API %s %s error rate %.2f%% exceeds threshold %.2f%%", 
                        method, apiPath, errorRate * 100, errorRateThreshold * 100),
                    AlertSeverity.CRITICAL
                );
            }
        }
    }
    
    private void recordSlowQuery(String operation, String table, long executionTime) {
        SlowQueryRecord record = SlowQueryRecord.builder()
            .operation(operation)
            .table(table)
            .executionTime(executionTime)
            .timestamp(Instant.now())
            .build();
        
        // 异步保存慢查询记录
        CompletableFuture.runAsync(() -> {
            try {
                metricsRepository.saveSlowQuery(record);
            } catch (Exception e) {
                log.error("Failed to save slow query record", e);
            }
        });
    }
    
    private List<PerformanceBottleneck> analyzeApiBottlenecks(Instant startTime, Instant endTime) {
        List<PerformanceBottleneck> bottlenecks = new ArrayList<>();
        
        // 查询API性能数据
        List<ApiMetrics> apiMetrics = metricsRepository.getApiMetrics(startTime, endTime);
        
        for (ApiMetrics metrics : apiMetrics) {
            // 检查平均响应时间
            if (metrics.getAverageResponseTime() > getResponseTimeThreshold(metrics.getApiPath())) {
                bottlenecks.add(PerformanceBottleneck.builder()
                    .type(BottleneckType.API_RESPONSE_TIME)
                    .resource(metrics.getApiPath())
                    .severity(calculateSeverity(metrics.getAverageResponseTime(), getResponseTimeThreshold(metrics.getApiPath())))
                    .description(String.format("API %s average response time %.2fms exceeds threshold", 
                        metrics.getApiPath(), metrics.getAverageResponseTime()))
                    .recommendation("Consider optimizing API logic, adding caching, or scaling resources")
                    .build());
            }
            
            // 检查错误率
            if (metrics.getErrorRate() > getErrorRateThreshold()) {
                bottlenecks.add(PerformanceBottleneck.builder()
                    .type(BottleneckType.API_ERROR_RATE)
                    .resource(metrics.getApiPath())
                    .severity(calculateSeverity(metrics.getErrorRate(), getErrorRateThreshold()))
                    .description(String.format("API %s error rate %.2f%% exceeds threshold", 
                        metrics.getApiPath(), metrics.getErrorRate() * 100))
                    .recommendation("Investigate error causes and implement error handling improvements")
                    .build());
            }
        }
        
        return bottlenecks;
    }
}
```

#### 缓存管理服务
```java
// CacheManagementService.java
@Service
@Slf4j
public class CacheManagementService {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final CacheManager cacheManager;
    private final CacheConfigRepository cacheConfigRepository;
    private final PerformanceMonitoringService performanceMonitoringService;
    
    /**
     * 多级缓存获取
     */
    @SuppressWarnings("unchecked")
    public <T> Optional<T> get(String key, Class<T> type) {
        try {
            // L1缓存：本地缓存
            Cache localCache = cacheManager.getCache("local");
            if (localCache != null) {
                Cache.ValueWrapper wrapper = localCache.get(key);
                if (wrapper != null) {
                    performanceMonitoringService.recordCachePerformance("local", "get", true);
                    return Optional.of((T) wrapper.get());
                }
            }
            
            // L2缓存：Redis分布式缓存
            Object value = redisTemplate.opsForValue().get(key);
            if (value != null) {
                // 回填L1缓存
                if (localCache != null) {
                    localCache.put(key, value);
                }
                performanceMonitoringService.recordCachePerformance("redis", "get", true);
                return Optional.of((T) value);
            }
            
            performanceMonitoringService.recordCachePerformance("all", "get", false);
            return Optional.empty();
            
        } catch (Exception e) {
            log.error("Failed to get from cache: {}", key, e);
            performanceMonitoringService.recordCachePerformance("all", "get", false);
            return Optional.empty();
        }
    }
    
    /**
     * 多级缓存设置
     */
    public void put(String key, Object value, Duration ttl) {
        try {
            // 设置Redis缓存
            redisTemplate.opsForValue().set(key, value, ttl);
            
            // 设置本地缓存（较短的TTL）
            Cache localCache = cacheManager.getCache("local");
            if (localCache != null) {
                Duration localTtl = ttl.compareTo(Duration.ofMinutes(5)) > 0 ? 
                    Duration.ofMinutes(5) : ttl;
                localCache.put(key, value);
            }
            
            performanceMonitoringService.recordCachePerformance("all", "put", true);
            
        } catch (Exception e) {
            log.error("Failed to put to cache: {}", key, e);
        }
    }
    
    /**
     * 缓存预热
     */
    public void warmupCache(String cacheGroup) {
        try {
            log.info("Starting cache warmup for group: {}", cacheGroup);
            
            CacheWarmupConfig config = cacheConfigRepository.getWarmupConfig(cacheGroup);
            if (config == null) {
                log.warn("No warmup config found for cache group: {}", cacheGroup);
                return;
            }
            
            // 并行预热
            List<CompletableFuture<Void>> futures = config.getWarmupTasks().stream()
                .map(task -> CompletableFuture.runAsync(() -> executeWarmupTask(task)))
                .collect(Collectors.toList());
            
            // 等待所有预热任务完成
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
                .get(config.getTimeout().toMillis(), TimeUnit.MILLISECONDS);
            
            log.info("Cache warmup completed for group: {}", cacheGroup);
            
        } catch (Exception e) {
            log.error("Failed to warmup cache for group: {}", cacheGroup, e);
        }
    }
    
    /**
     * 智能缓存失效
     */
    public void invalidateCache(String pattern, InvalidationStrategy strategy) {
        try {
            switch (strategy) {
                case IMMEDIATE:
                    invalidateImmediately(pattern);
                    break;
                case LAZY:
                    markForLazyInvalidation(pattern);
                    break;
                case SCHEDULED:
                    scheduleInvalidation(pattern);
                    break;
                default:
                    throw new UnsupportedOperationException("Unsupported invalidation strategy: " + strategy);
            }
            
        } catch (Exception e) {
            log.error("Failed to invalidate cache with pattern: {}", pattern, e);
        }
    }
    
    /**
     * 缓存统计分析
     */
    public CacheStatistics getCacheStatistics(String cacheName, Instant startTime, Instant endTime) {
        try {
            return CacheStatistics.builder()
                .cacheName(cacheName)
                .timeRange(TimeRange.of(startTime, endTime))
                .hitRate(calculateHitRate(cacheName, startTime, endTime))
                .missRate(calculateMissRate(cacheName, startTime, endTime))
                .totalRequests(getTotalRequests(cacheName, startTime, endTime))
                .averageResponseTime(getAverageResponseTime(cacheName, startTime, endTime))
                .memoryUsage(getMemoryUsage(cacheName))
                .evictionCount(getEvictionCount(cacheName, startTime, endTime))
                .build();
        } catch (Exception e) {
            log.error("Failed to get cache statistics for: {}", cacheName, e);
            throw new CacheStatisticsException("Failed to get cache statistics", e);
        }
    }
    
    /**
     * 缓存容量管理
     */
    @Scheduled(fixedRate = 300000) // 每5分钟执行一次
    public void manageCacheCapacity() {
        try {
            // 检查Redis内存使用情况
            RedisServerInfo serverInfo = getRedisServerInfo();
            double memoryUsageRatio = (double) serverInfo.getUsedMemory() / serverInfo.getMaxMemory();
            
            if (memoryUsageRatio > 0.8) { // 内存使用超过80%
                log.warn("Redis memory usage is high: {:.2f}%", memoryUsageRatio * 100);
                
                // 执行缓存清理策略
                executeCacheCleanupStrategy(memoryUsageRatio);
            }
            
            // 检查本地缓存使用情况
            manageLocalCacheCapacity();
            
        } catch (Exception e) {
            log.error("Failed to manage cache capacity", e);
        }
    }
    
    private void executeWarmupTask(CacheWarmupTask task) {
        try {
            switch (task.getType()) {
                case QUERY_BASED:
                    executeQueryBasedWarmup(task);
                    break;
                case DATA_BASED:
                    executeDataBasedWarmup(task);
                    break;
                case PATTERN_BASED:
                    executePatternBasedWarmup(task);
                    break;
                default:
                    log.warn("Unknown warmup task type: {}", task.getType());
            }
        } catch (Exception e) {
            log.error("Failed to execute warmup task: {}", task.getName(), e);
        }
    }
    
    private void invalidateImmediately(String pattern) {
        // 删除匹配的Redis键
        Set<String> keys = redisTemplate.keys(pattern);
        if (keys != null && !keys.isEmpty()) {
            redisTemplate.delete(keys);
        }
        
        // 清除本地缓存
        Cache localCache = cacheManager.getCache("local");
        if (localCache != null) {
            localCache.clear();
        }
    }
    
    private void executeCacheCleanupStrategy(double memoryUsageRatio) {
        if (memoryUsageRatio > 0.9) {
            // 紧急清理：删除最近最少使用的键
            executeEmergencyCleanup();
        } else {
            // 常规清理：删除过期和低优先级的键
            executeRegularCleanup();
        }
    }
}
```

#### 数据库优化服务
```java
// DatabaseOptimizationService.java
@Service
@Slf4j
public class DatabaseOptimizationService {
    
    private final DataSource dataSource;
    private final JdbcTemplate jdbcTemplate;
    private final QueryAnalyzer queryAnalyzer;
    private final IndexOptimizer indexOptimizer;
    private final ConnectionPoolMonitor connectionPoolMonitor;
    
    /**
     * 查询优化分析
     */
    public QueryOptimizationResult analyzeQuery(String sql, Map<String, Object> parameters) {
        try {
            // 解析SQL语句
            ParsedQuery parsedQuery = queryAnalyzer.parse(sql);
            
            // 生成执行计划
            ExecutionPlan executionPlan = generateExecutionPlan(sql, parameters);
            
            // 分析性能瓶颈
            List<QueryBottleneck> bottlenecks = identifyQueryBottlenecks(executionPlan);
            
            // 生成优化建议
            List<OptimizationSuggestion> suggestions = generateOptimizationSuggestions(parsedQuery, executionPlan, bottlenecks);
            
            return QueryOptimizationResult.builder()
                .originalQuery(sql)
                .parsedQuery(parsedQuery)
                .executionPlan(executionPlan)
                .bottlenecks(bottlenecks)
                .suggestions(suggestions)
                .estimatedImprovement(calculateEstimatedImprovement(suggestions))
                .build();
            
        } catch (Exception e) {
            log.error("Failed to analyze query optimization", e);
            throw new QueryAnalysisException("Failed to analyze query", e);
        }
    }
    
    /**
     * 自动索引优化
     */
    public IndexOptimizationResult optimizeIndexes(String tableName) {
        try {
            // 分析表的查询模式
            TableQueryPattern queryPattern = analyzeTableQueryPattern(tableName);
            
            // 分析现有索引
            List<IndexInfo> existingIndexes = getExistingIndexes(tableName);
            
            // 识别缺失的索引
            List<IndexRecommendation> missingIndexes = identifyMissingIndexes(queryPattern, existingIndexes);
            
            // 识别冗余的索引
            List<IndexInfo> redundantIndexes = identifyRedundantIndexes(existingIndexes, queryPattern);
            
            // 生成索引优化计划
            IndexOptimizationPlan optimizationPlan = generateIndexOptimizationPlan(
                missingIndexes, redundantIndexes);
            
            return IndexOptimizationResult.builder()
                .tableName(tableName)
                .queryPattern(queryPattern)
                .existingIndexes(existingIndexes)
                .missingIndexes(missingIndexes)
                .redundantIndexes(redundantIndexes)
                .optimizationPlan(optimizationPlan)
                .estimatedImprovement(calculateIndexImprovement(optimizationPlan))
                .build();
            
        } catch (Exception e) {
            log.error("Failed to optimize indexes for table: {}", tableName, e);
            throw new IndexOptimizationException("Failed to optimize indexes", e);
        }
    }
    
    /**
     * 连接池监控和优化
     */
    public ConnectionPoolStatus monitorConnectionPool() {
        try {
            HikariDataSource hikariDataSource = (HikariDataSource) dataSource;
            HikariPoolMXBean poolMXBean = hikariDataSource.getHikariPoolMXBean();
            
            ConnectionPoolStatus status = ConnectionPoolStatus.builder()
                .totalConnections(poolMXBean.getTotalConnections())
                .activeConnections(poolMXBean.getActiveConnections())
                .idleConnections(poolMXBean.getIdleConnections())
                .threadsAwaitingConnection(poolMXBean.getThreadsAwaitingConnection())
                .maximumPoolSize(hikariDataSource.getMaximumPoolSize())
                .minimumIdle(hikariDataSource.getMinimumIdle())
                .connectionTimeout(hikariDataSource.getConnectionTimeout())
                .idleTimeout(hikariDataSource.getIdleTimeout())
                .maxLifetime(hikariDataSource.getMaxLifetime())
                .build();
            
            // 检查连接池健康状态
            checkConnectionPoolHealth(status);
            
            return status;
            
        } catch (Exception e) {
            log.error("Failed to monitor connection pool", e);
            throw new ConnectionPoolMonitoringException("Failed to monitor connection pool", e);
        }
    }
    
    /**
     * 数据库性能调优
     */
    public DatabaseTuningResult performDatabaseTuning() {
        try {
            List<TuningRecommendation> recommendations = new ArrayList<>();
            
            // 分析慢查询
            List<SlowQuery> slowQueries = analyzeSlowQueries();
            recommendations.addAll(generateSlowQueryRecommendations(slowQueries));
            
            // 分析表统计信息
            List<TableStatistics> tableStats = analyzeTableStatistics();
            recommendations.addAll(generateTableOptimizationRecommendations(tableStats));
            
            // 分析数据库配置
            DatabaseConfiguration dbConfig = analyzeDatabaseConfiguration();
            recommendations.addAll(generateConfigurationRecommendations(dbConfig));
            
            // 分析锁等待
            List<LockWaitInfo> lockWaits = analyzeLockWaits();
            recommendations.addAll(generateLockOptimizationRecommendations(lockWaits));
            
            return DatabaseTuningResult.builder()
                .slowQueries(slowQueries)
                .tableStatistics(tableStats)
                .databaseConfiguration(dbConfig)
                .lockWaitInfo(lockWaits)
                .recommendations(recommendations)
                .estimatedImprovement(calculateTuningImprovement(recommendations))
                .build();
            
        } catch (Exception e) {
            log.error("Failed to perform database tuning", e);
            throw new DatabaseTuningException("Failed to perform database tuning", e);
        }
    }
    
    /**
     * 读写分离路由
     */
    @Component
    public static class ReadWriteRoutingDataSource extends AbstractRoutingDataSource {
        
        @Override
        protected Object determineCurrentLookupKey() {
            return DatabaseContextHolder.getDataSourceType();
        }
    }
    
    /**
     * 数据库上下文持有者
     */
    public static class DatabaseContextHolder {
        private static final ThreadLocal<DataSourceType> contextHolder = new ThreadLocal<>();
        
        public static void setDataSourceType(DataSourceType dataSourceType) {
            contextHolder.set(dataSourceType);
        }
        
        public static DataSourceType getDataSourceType() {
            return contextHolder.get();
        }
        
        public static void clearDataSourceType() {
            contextHolder.remove();
        }
    }
    
    /**
     * 读写分离切面
     */
    @Aspect
    @Component
    public static class ReadWriteSplitAspect {
        
        @Around("@annotation(readOnly)")
        public Object routeDataSource(ProceedingJoinPoint joinPoint, ReadOnly readOnly) throws Throwable {
            try {
                if (readOnly.value()) {
                    DatabaseContextHolder.setDataSourceType(DataSourceType.READ);
                } else {
                    DatabaseContextHolder.setDataSourceType(DataSourceType.WRITE);
                }
                
                return joinPoint.proceed();
            } finally {
                DatabaseContextHolder.clearDataSourceType();
            }
        }
    }
    
    private void checkConnectionPoolHealth(ConnectionPoolStatus status) {
        // 检查连接池使用率
        double utilizationRate = (double) status.getActiveConnections() / status.getTotalConnections();
        if (utilizationRate > 0.8) {
            log.warn("Connection pool utilization is high: {:.2f}%", utilizationRate * 100);
            
            // 触发告警
            alertManager.triggerAlert(
                "High Connection Pool Utilization",
                String.format("Connection pool utilization %.2f%% exceeds threshold", utilizationRate * 100),
                AlertSeverity.WARNING
            );
        }
        
        // 检查等待连接的线程数
        if (status.getThreadsAwaitingConnection() > 0) {
            log.warn("Threads awaiting connection: {}", status.getThreadsAwaitingConnection());
            
            // 建议增加连接池大小
            if (status.getTotalConnections() < status.getMaximumPoolSize()) {
                log.info("Consider increasing connection pool size");
            }
        }
    }
    
    private List<SlowQuery> analyzeSlowQueries() {
        String sql = """
            SELECT query_time, lock_time, rows_sent, rows_examined, sql_text
            FROM mysql.slow_log
            WHERE start_time >= DATE_SUB(NOW(), INTERVAL 1 HOUR)
            ORDER BY query_time DESC
            LIMIT 100
            """;
        
        return jdbcTemplate.query(sql, (rs, rowNum) -> 
            SlowQuery.builder()
                .queryTime(rs.getDouble("query_time"))
                .lockTime(rs.getDouble("lock_time"))
                .rowsSent(rs.getLong("rows_sent"))
                .rowsExamined(rs.getLong("rows_examined"))
                .sqlText(rs.getString("sql_text"))
                .build()
        );
    }
}
```

#### 负载均衡服务
```java
// LoadBalancingService.java
@Service
@Slf4j
public class LoadBalancingService {
    
    private final ServiceRegistry serviceRegistry;
    private final HealthCheckService healthCheckService;
    private final LoadBalancingStrategy loadBalancingStrategy;
    private final CircuitBreakerRegistry circuitBreakerRegistry;
    
    /**
     * 选择服务实例
     */
    public ServiceInstance selectServiceInstance(String serviceName, LoadBalancingContext context) {
        try {
            // 获取可用的服务实例
            List<ServiceInstance> availableInstances = getAvailableInstances(serviceName);
            
            if (availableInstances.isEmpty()) {
                throw new NoAvailableServiceException("No available instances for service: " + serviceName);
            }
            
            // 过滤健康的实例
            List<ServiceInstance> healthyInstances = filterHealthyInstances(availableInstances);
            
            if (healthyInstances.isEmpty()) {
                log.warn("No healthy instances found for service: {}, using all available instances", serviceName);
                healthyInstances = availableInstances;
            }
            
            // 应用负载均衡策略
            ServiceInstance selectedInstance = loadBalancingStrategy.select(healthyInstances, context);
            
            // 记录选择结果
            recordInstanceSelection(serviceName, selectedInstance);
            
            return selectedInstance;
            
        } catch (Exception e) {
            log.error("Failed to select service instance for: {}", serviceName, e);
            throw new ServiceSelectionException("Failed to select service instance", e);
        }
    }
    
    /**
     * 注册服务实例
     */
    public void registerServiceInstance(ServiceInstance instance) {
        try {
            // 验证实例信息
            validateServiceInstance(instance);
            
            // 注册到服务注册中心
            serviceRegistry.register(instance);
            
            // 启动健康检查
            healthCheckService.startHealthCheck(instance);
            
            // 初始化熔断器
            initializeCircuitBreaker(instance);
            
            log.info("Service instance registered: {} - {}", instance.getServiceName(), instance.getInstanceId());
            
        } catch (Exception e) {
            log.error("Failed to register service instance: {}", instance.getInstanceId(), e);
            throw new ServiceRegistrationException("Failed to register service instance", e);
        }
    }
    
    /**
     * 注销服务实例
     */
    public void deregisterServiceInstance(String serviceId) {
        try {
            ServiceInstance instance = serviceRegistry.getInstance(serviceId);
            if (instance != null) {
                // 停止健康检查
                healthCheckService.stopHealthCheck(instance);
                
                // 从注册中心移除
                serviceRegistry.deregister(serviceId);
                
                // 清理熔断器
                cleanupCircuitBreaker(instance);
                
                log.info("Service instance deregistered: {}", serviceId);
            }
        } catch (Exception e) {
            log.error("Failed to deregister service instance: {}", serviceId, e);
        }
    }
    
    /**
     * 获取服务健康状态
     */
    public ServiceHealthStatus getServiceHealth(String serviceName) {
        try {
            List<ServiceInstance> instances = serviceRegistry.getInstances(serviceName);
            
            Map<String, InstanceHealthStatus> instanceHealthMap = new HashMap<>();
            int healthyCount = 0;
            int totalCount = instances.size();
            
            for (ServiceInstance instance : instances) {
                InstanceHealthStatus healthStatus = healthCheckService.getHealthStatus(instance.getInstanceId());
                instanceHealthMap.put(instance.getInstanceId(), healthStatus);
                
                if (healthStatus.isHealthy()) {
                    healthyCount++;
                }
            }
            
            ServiceHealthStatus.OverallStatus overallStatus;
            if (healthyCount == 0) {
                overallStatus = ServiceHealthStatus.OverallStatus.DOWN;
            } else if (healthyCount == totalCount) {
                overallStatus = ServiceHealthStatus.OverallStatus.UP;
            } else {
                overallStatus = ServiceHealthStatus.OverallStatus.DEGRADED;
            }
            
            return ServiceHealthStatus.builder()
                .serviceName(serviceName)
                .overallStatus(overallStatus)
                .totalInstances(totalCount)
                .healthyInstances(healthyCount)
                .instanceHealthMap(instanceHealthMap)
                .lastUpdated(Instant.now())
                .build();
            
        } catch (Exception e) {
            log.error("Failed to get service health for: {}", serviceName, e);
            return ServiceHealthStatus.builder()
                .serviceName(serviceName)
                .overallStatus(ServiceHealthStatus.OverallStatus.UNKNOWN)
                .build();
        }
    }
    
    /**
     * 智能负载均衡策略
     */
    @Component
    public static class IntelligentLoadBalancingStrategy implements LoadBalancingStrategy {
        
        private final PerformanceMonitoringService performanceMonitoringService;
        private final Random random = new Random();
        
        @Override
        public ServiceInstance select(List<ServiceInstance> instances, LoadBalancingContext context) {
            if (instances.size() == 1) {
                return instances.get(0);
            }
            
            // 根据上下文选择策略
            switch (context.getPreferredStrategy()) {
                case ROUND_ROBIN:
                    return selectRoundRobin(instances, context);
                case WEIGHTED_ROUND_ROBIN:
                    return selectWeightedRoundRobin(instances, context);
                case LEAST_CONNECTIONS:
                    return selectLeastConnections(instances);
                case RESPONSE_TIME:
                    return selectByResponseTime(instances);
                case CONSISTENT_HASH:
                    return selectConsistentHash(instances, context);
                default:
                    return selectAdaptive(instances, context);
            }
        }
        
        private ServiceInstance selectAdaptive(List<ServiceInstance> instances, LoadBalancingContext context) {
            // 自适应选择：综合考虑响应时间、连接数、CPU使用率等因素
            Map<ServiceInstance, Double> scores = new HashMap<>();
            
            for (ServiceInstance instance : instances) {
                double score = calculateInstanceScore(instance);
                scores.put(instance, score);
            }
            
            // 选择得分最高的实例
            return scores.entrySet().stream()
                .max(Map.Entry.comparingByValue())
                .map(Map.Entry::getKey)
                .orElse(instances.get(random.nextInt(instances.size())));
        }
        
        private double calculateInstanceScore(ServiceInstance instance) {
            // 获取实例性能指标
            InstanceMetrics metrics = performanceMonitoringService.getInstanceMetrics(instance.getInstanceId());
            
            // 计算综合得分（分数越高越好）
            double responseTimeScore = 1.0 / (1.0 + metrics.getAverageResponseTime() / 1000.0); // 响应时间越短得分越高
            double connectionScore = 1.0 / (1.0 + metrics.getActiveConnections() / 100.0); // 连接数越少得分越高
            double cpuScore = 1.0 - metrics.getCpuUsage(); // CPU使用率越低得分越高
            double memoryScore = 1.0 - metrics.getMemoryUsage(); // 内存使用率越低得分越高
            
            // 加权平均
            return responseTimeScore * 0.4 + connectionScore * 0.3 + cpuScore * 0.2 + memoryScore * 0.1;
        }
    }
    
    private List<ServiceInstance> getAvailableInstances(String serviceName) {
        List<ServiceInstance> instances = serviceRegistry.getInstances(serviceName);
        
        // 过滤掉被熔断的实例
        return instances.stream()
            .filter(instance -> !isCircuitBreakerOpen(instance))
            .collect(Collectors.toList());
    }
    
    private List<ServiceInstance> filterHealthyInstances(List<ServiceInstance> instances) {
        return instances.stream()
            .filter(instance -> {
                InstanceHealthStatus healthStatus = healthCheckService.getHealthStatus(instance.getInstanceId());
                return healthStatus != null && healthStatus.isHealthy();
            })
            .collect(Collectors.toList());
    }
    
    private boolean isCircuitBreakerOpen(ServiceInstance instance) {
        CircuitBreaker circuitBreaker = circuitBreakerRegistry.circuitBreaker(instance.getInstanceId());
        return circuitBreaker.getState() == CircuitBreaker.State.OPEN;
    }
}
```

### 自动扩缩容系统

#### 自动扩缩容服务
```java
// AutoScalingService.java
@Service
@Slf4j
public class AutoScalingService {
    
    private final KubernetesClient kubernetesClient;
    private final MetricCollector metricCollector;
    private final ScalingPolicyRepository scalingPolicyRepository;
    private final AlertManager alertManager;
    
    /**
     * 执行自动扩缩容检查
     */
    @Scheduled(fixedRate = 30000) // 每30秒检查一次
    public void performAutoScaling() {
        try {
            List<ScalingPolicy> policies = scalingPolicyRepository.findAllEnabled();
            
            for (ScalingPolicy policy : policies) {
                evaluateScalingPolicy(policy);
            }
            
        } catch (Exception e) {
            log.error("Failed to perform auto scaling", e);
        }
    }
    
    /**
     * 评估扩缩容策略
     */
    private void evaluateScalingPolicy(ScalingPolicy policy) {
        try {
            // 收集当前指标
            ScalingMetrics currentMetrics = collectScalingMetrics(policy.getServiceName());
            
            // 评估是否需要扩容
            ScalingDecision decision = evaluateScalingDecision(policy, currentMetrics);
            
            if (decision.isScalingRequired()) {
                executeScaling(policy, decision);
            }
            
        } catch (Exception e) {
            log.error("Failed to evaluate scaling policy for service: {}", policy.getServiceName(), e);
        }
    }
    
    /**
     * 执行扩缩容操作
     */
    private void executeScaling(ScalingPolicy policy, ScalingDecision decision) {
        try {
            String serviceName = policy.getServiceName();
            int currentReplicas = getCurrentReplicas(serviceName);
            int targetReplicas = decision.getTargetReplicas();
            
            log.info("Scaling service {} from {} to {} replicas", serviceName, currentReplicas, targetReplicas);
            
            // 执行Kubernetes扩缩容
            scaleKubernetesDeployment(serviceName, targetReplicas);
            
            // 记录扩缩容事件
            recordScalingEvent(policy, decision, currentReplicas, targetReplicas);
            
            // 发送通知
            sendScalingNotification(policy, decision, currentReplicas, targetReplicas);
            
        } catch (Exception e) {
            log.error("Failed to execute scaling for service: {}", policy.getServiceName(), e);
            alertManager.triggerAlert(
                "Auto Scaling Failed",
                String.format("Failed to scale service %s: %s", policy.getServiceName(), e.getMessage()),
                AlertSeverity.CRITICAL
            );
        }
    }
    
    /**
     * 预测性扩容
     */
    public PredictiveScalingResult performPredictiveScaling(String serviceName, Duration forecastPeriod) {
        try {
            // 收集历史指标数据
            List<HistoricalMetrics> historicalData = metricCollector.getHistoricalMetrics(
                serviceName, Instant.now().minus(Duration.ofDays(30)), Instant.now());
            
            // 使用机器学习模型预测未来负载
            LoadForecast forecast = predictFutureLoad(historicalData, forecastPeriod);
            
            // 计算预测性扩容建议
            PredictiveScalingRecommendation recommendation = generatePredictiveScalingRecommendation(
                serviceName, forecast);
            
            return PredictiveScalingResult.builder()
                .serviceName(serviceName)
                .forecastPeriod(forecastPeriod)
                .loadForecast(forecast)
                .recommendation(recommendation)
                .confidence(forecast.getConfidence())
                .build();
            
        } catch (Exception e) {
            log.error("Failed to perform predictive scaling for service: {}", serviceName, e);
            throw new PredictiveScalingException("Failed to perform predictive scaling", e);
        }
    }
    
    private ScalingMetrics collectScalingMetrics(String serviceName) {
        return ScalingMetrics.builder()
            .cpuUtilization(metricCollector.getCpuUtilization(serviceName))
            .memoryUtilization(metricCollector.getMemoryUtilization(serviceName))
            .requestRate(metricCollector.getRequestRate(serviceName))
            .responseTime(metricCollector.getAverageResponseTime(serviceName))
            .errorRate(metricCollector.getErrorRate(serviceName))
            .queueLength(metricCollector.getQueueLength(serviceName))
            .activeConnections(metricCollector.getActiveConnections(serviceName))
            .build();
    }
    
    private ScalingDecision evaluateScalingDecision(ScalingPolicy policy, ScalingMetrics metrics) {
        int currentReplicas = getCurrentReplicas(policy.getServiceName());
        int targetReplicas = currentReplicas;
        ScalingAction action = ScalingAction.NONE;
        String reason = "No scaling required";
        
        // 检查扩容条件
        if (shouldScaleUp(policy, metrics)) {
            targetReplicas = Math.min(currentReplicas + policy.getScaleUpStep(), policy.getMaxReplicas());
            action = ScalingAction.SCALE_UP;
            reason = generateScaleUpReason(policy, metrics);
        }
        // 检查缩容条件
        else if (shouldScaleDown(policy, metrics)) {
            targetReplicas = Math.max(currentReplicas - policy.getScaleDownStep(), policy.getMinReplicas());
            action = ScalingAction.SCALE_DOWN;
            reason = generateScaleDownReason(policy, metrics);
        }
        
        return ScalingDecision.builder()
            .action(action)
            .currentReplicas(currentReplicas)
            .targetReplicas(targetReplicas)
            .reason(reason)
            .metrics(metrics)
            .scalingRequired(action != ScalingAction.NONE)
            .build();
    }
    
    private boolean shouldScaleUp(ScalingPolicy policy, ScalingMetrics metrics) {
        // CPU使用率超过阈值
        if (metrics.getCpuUtilization() > policy.getCpuScaleUpThreshold()) {
            return true;
        }
        
        // 内存使用率超过阈值
        if (metrics.getMemoryUtilization() > policy.getMemoryScaleUpThreshold()) {
            return true;
        }
        
        // 请求率超过阈值
        if (metrics.getRequestRate() > policy.getRequestRateScaleUpThreshold()) {
            return true;
        }
        
        // 响应时间超过阈值
        if (metrics.getResponseTime() > policy.getResponseTimeScaleUpThreshold()) {
            return true;
        }
        
        // 队列长度超过阈值
        if (metrics.getQueueLength() > policy.getQueueLengthScaleUpThreshold()) {
            return true;
        }
        
        return false;
    }
    
    private boolean shouldScaleDown(ScalingPolicy policy, ScalingMetrics metrics) {
        // 所有指标都低于缩容阈值才进行缩容
        return metrics.getCpuUtilization() < policy.getCpuScaleDownThreshold() &&
               metrics.getMemoryUtilization() < policy.getMemoryScaleDownThreshold() &&
               metrics.getRequestRate() < policy.getRequestRateScaleDownThreshold() &&
               metrics.getResponseTime() < policy.getResponseTimeScaleDownThreshold() &&
               metrics.getQueueLength() < policy.getQueueLengthScaleDownThreshold();
    }
}
```

### Testing

#### 测试标准
- **性能监控测试**: 验证指标收集和分析的准确性
- **缓存系统测试**: 测试多级缓存的一致性和性能
- **数据库优化测试**: 验证查询优化和索引建议的有效性
- **负载均衡测试**: 测试负载均衡算法的公平性和效率
- **自动扩缩容测试**: 验证扩缩容决策的准确性和及时性

#### 测试框架
- **JUnit 5**: 单元测试框架
- **Spring Boot Test**: 集成测试支持
- **TestContainers**: Redis、Kafka等服务的测试容器
- **JMeter**: 性能测试和负载测试
- **Gatling**: 高性能压力测试

#### 测试覆盖率要求
- 性能监控服务测试覆盖率 > 85%
- 缓存管理服务测试覆盖率 > 90%
- 数据库优化服务测试覆盖率 > 80%
- 负载均衡服务测试覆盖率 > 85%
- 自动扩缩容服务测试覆盖率 > 80%

#### 性能测试指标
- 系统吞吐量提升 > 50%
- 响应时间减少 > 30%
- 资源利用率优化 > 20%
- 扩缩容响应时间 < 2分钟

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-01-XX | 1.0 | 初始故事创建 | Scrum Master |

## Dev Agent Record

### Agent Model Used
*待开发代理填写*

### Debug Log References
*待开发代理填写*

### Completion Notes List
*待开发代理填写*

### File List
*待开发代理填写*

## QA Results
*待QA代理填写*