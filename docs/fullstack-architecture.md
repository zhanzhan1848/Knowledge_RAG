# Knowledge RAG å…¨æ ˆæ¶æ„æ–‡æ¡£

## æ–‡æ¡£ä¿¡æ¯

| å±æ€§ | å€¼ |
|------|----|
| æ–‡æ¡£ID | knowledge-rag-fullstack-arch |
| ç‰ˆæœ¬ | 1.0.0 |
| åˆ›å»ºæ—¥æœŸ | 2025-01-06 |
| æœ€åæ›´æ–° | 2025-01-06 |
| ä½œè€… | AIæ¶æ„å¸ˆ |
| çŠ¶æ€ | è‰æ¡ˆ |

## å˜æ›´æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | æè¿° | ä½œè€… |
|------|------|------|------|
| 2025-01-06 | 1.0.0 | åˆå§‹ç‰ˆæœ¬åˆ›å»º | AIæ¶æ„å¸ˆ |

## 1. å¼•è¨€

### é¡¹ç›®èƒŒæ™¯

Knowledge RAGæ˜¯ä¸€ä¸ªåŸºäºGraphRAGæŠ€æœ¯çš„æ™ºèƒ½çŸ¥è¯†ç®¡ç†ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡å…ˆè¿›çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›é«˜æ•ˆã€å‡†ç¡®çš„çŸ¥è¯†æ£€ç´¢å’Œé—®ç­”æœåŠ¡ã€‚è¯¥ç³»ç»Ÿä¸“æ³¨äºå¤„ç†å¤§è§„æ¨¡æ–‡æ¡£é›†åˆï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ï¼Œå¹¶æä¾›æ™ºèƒ½åŒ–çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ã€‚

### æ¶æ„æ–¹æ³•

æœ¬æ–‡æ¡£é‡‡ç”¨API-Firstçš„åç«¯æ¶æ„è®¾è®¡æ–¹æ³•ï¼Œä¸“æ³¨äºæ„å»ºé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„åç«¯æœåŠ¡ä½“ç³»ã€‚æˆ‘ä»¬çš„æ¶æ„è®¾è®¡éµå¾ªä»¥ä¸‹æ ¸å¿ƒåŸåˆ™ï¼š

- **å¾®æœåŠ¡æ¶æ„**ï¼šå°†ç³»ç»Ÿæ‹†åˆ†ä¸ºç‹¬ç«‹çš„ã€å¯æ‰©å±•çš„æœåŠ¡å•å…ƒ
- **å¼‚æ­¥å¤„ç†**ï¼šé‡‡ç”¨äº‹ä»¶é©±åŠ¨å’Œæ¶ˆæ¯é˜Ÿåˆ—æœºåˆ¶å¤„ç†å¤æ‚çš„æ–‡æ¡£å¤„ç†æµç¨‹
- **å¤šæ•°æ®åº“ç­–ç•¥**ï¼šé’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹é€‰æ‹©æœ€é€‚åˆçš„å­˜å‚¨æ–¹æ¡ˆ
- **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§å’Œéƒ¨ç½²çµæ´»æ€§

### é¡¹ç›®ç±»å‹

æœ¬é¡¹ç›®ä¸º**çº¯åç«¯APIæœåŠ¡**ï¼ŒåŸºäºFastAPIå¾®æœåŠ¡æ¨¡æ¿æ„å»ºå…¨æ–°çš„çŸ¥è¯†ç®¡ç†å¹³å°ã€‚ç³»ç»ŸåŒ…å«ä»¥ä¸‹6ä¸ªæ ¸å¿ƒåç«¯æœåŠ¡ï¼š

1. **APIç½‘å…³æœåŠ¡** - ç»Ÿä¸€å…¥å£å’Œè·¯ç”±ç®¡ç†
2. **æ–‡æ¡£å¤„ç†æœåŠ¡** - å¤šæ ¼å¼æ–‡æ¡£è§£æå’Œé¢„å¤„ç†
3. **å‘é‡æ£€ç´¢æœåŠ¡** - åŸºäºWeaviateçš„è¯­ä¹‰æ£€ç´¢
4. **çŸ¥è¯†å›¾è°±æœåŠ¡** - åŸºäºNeo4jçš„å›¾æ•°æ®ç®¡ç†
5. **æŸ¥è¯¢å¼•æ“æœåŠ¡** - GraphRAGæ··åˆæ£€ç´¢å’ŒLLMé›†æˆ
6. **ç”¨æˆ·ç®¡ç†æœåŠ¡** - è®¤è¯æˆæƒå’Œç”¨æˆ·æ•°æ®ç®¡ç†

### æŠ€æœ¯é€‰å‹ä¼˜åŠ¿

é€‰æ‹©FastAPIå¾®æœåŠ¡æ¶æ„çš„æ ¸å¿ƒåŸå› ï¼š

- **é«˜æ€§èƒ½å¼‚æ­¥å¤„ç†**ï¼šåŸç”Ÿæ”¯æŒasync/awaitï¼Œé€‚åˆI/Oå¯†é›†å‹çš„æ–‡æ¡£å¤„ç†ä»»åŠ¡
- **è‡ªåŠ¨APIæ–‡æ¡£ç”Ÿæˆ**ï¼šå†…ç½®OpenAPIæ”¯æŒï¼Œä¾¿äºAPIç®¡ç†å’Œæµ‹è¯•
- **ç±»å‹å®‰å…¨**ï¼šåŸºäºPythonç±»å‹æç¤ºï¼Œæé«˜ä»£ç è´¨é‡å’Œç»´æŠ¤æ€§
- **AI/MLç”Ÿæ€å…¼å®¹**ï¼šä¸Pythonæœºå™¨å­¦ä¹ åº“æ— ç¼é›†æˆ
- **å®¹å™¨åŒ–å‹å¥½**ï¼šè½»é‡çº§éƒ¨ç½²ï¼Œé€‚åˆKubernetesç¯å¢ƒ

### å…³é”®çº¦æŸæ¡ä»¶

- **æ€§èƒ½è¦æ±‚**ï¼šæŸ¥è¯¢å“åº”æ—¶é—´ < 2ç§’ï¼Œæ”¯æŒå¹¶å‘ç”¨æˆ·æ•° > 1000
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒ10ä¸‡+æ–‡æ¡£å­˜å‚¨ï¼Œæ°´å¹³æ‰©å±•èƒ½åŠ›
- **å¯ç”¨æ€§**ï¼šç³»ç»Ÿå¯ç”¨æ€§ > 99.5%ï¼Œæ•…éšœæ¢å¤æ—¶é—´ < 5åˆ†é’Ÿ
- **å®‰å…¨åˆè§„**ï¼šGDPRåˆè§„ï¼Œæ•°æ®åŠ å¯†å­˜å‚¨å’Œä¼ è¾“

### æ ¸å¿ƒå†³ç­–æƒè¡¡

1. **å¾®æœåŠ¡ vs å•ä½“æ¶æ„**ï¼šé€‰æ‹©å¾®æœåŠ¡ä»¥æ”¯æŒç‹¬ç«‹æ‰©å±•å’ŒæŠ€æœ¯æ ˆå¤šæ ·æ€§
2. **åŒæ­¥ vs å¼‚æ­¥å¤„ç†**ï¼šé‡‡ç”¨å¼‚æ­¥å¤„ç†æé«˜ç³»ç»Ÿååé‡
3. **SQL vs NoSQL**ï¼šå¤šæ•°æ®åº“ç­–ç•¥ï¼Œæ ¹æ®æ•°æ®ç‰¹æ€§é€‰æ‹©æœ€ä¼˜å­˜å‚¨
4. **è‡ªå»º vs æ‰˜ç®¡æœåŠ¡**ï¼šå¹³è¡¡æˆæœ¬å’Œæ§åˆ¶åŠ›ï¼Œå…³é”®æœåŠ¡è‡ªå»ºï¼Œè¾…åŠ©æœåŠ¡æ‰˜ç®¡

### æ ¸å¿ƒå‡è®¾

- ç”¨æˆ·ä¸»è¦é€šè¿‡APIæ¥å£è®¿é—®ç³»ç»ŸåŠŸèƒ½
- æ–‡æ¡£å¤„ç†ä¸ºæ‰¹é‡å¼‚æ­¥æ“ä½œï¼Œå®æ—¶æ€§è¦æ±‚ä¸é«˜
- çŸ¥è¯†å›¾è°±æ„å»ºä¸ºç¦»çº¿è®¡ç®—å¯†é›†å‹ä»»åŠ¡
- ç³»ç»Ÿéƒ¨ç½²åœ¨äº‘ç¯å¢ƒï¼Œæ”¯æŒå¼¹æ€§æ‰©ç¼©å®¹

### å¾…éªŒè¯å†³ç­–

- LLMæœåŠ¡æä¾›å•†é€‰æ‹©ï¼ˆOpenAI vs è‡ªéƒ¨ç½²æ¨¡å‹ï¼‰
- å‘é‡æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- çŸ¥è¯†å›¾è°±æ›´æ–°é¢‘ç‡å’Œä¸€è‡´æ€§ä¿è¯
- å¤šç§Ÿæˆ·æ•°æ®éš”ç¦»æ–¹æ¡ˆ

---

## 2. é«˜å±‚æ¶æ„è®¾è®¡

### æŠ€æœ¯æ‘˜è¦

Knowledge RAGé‡‡ç”¨åŸºäºFastAPIçš„å¾®æœåŠ¡æ¶æ„ï¼Œé€šè¿‡APIç½‘å…³ç»Ÿä¸€ç®¡ç†6ä¸ªæ ¸å¿ƒåç«¯æœåŠ¡ã€‚ç³»ç»Ÿé‡‡ç”¨å¼‚æ­¥äº‹ä»¶é©±åŠ¨æ¨¡å¼å¤„ç†æ–‡æ¡£ä¸Šä¼ ã€å‘é‡åŒ–ã€çŸ¥è¯†å›¾è°±æ„å»ºç­‰å¤æ‚æµç¨‹ã€‚æ•°æ®å­˜å‚¨é‡‡ç”¨å¤šæ•°æ®åº“ç­–ç•¥ï¼šPostgreSQLå­˜å‚¨ç»“æ„åŒ–æ•°æ®ï¼ŒWeaviateç®¡ç†å‘é‡æ•°æ®ï¼ŒNeo4jæ„å»ºçŸ¥è¯†å›¾è°±ï¼ŒRedisæä¾›ç¼“å­˜å’Œä¼šè¯ç®¡ç†ã€‚æ•´ä½“æ¶æ„é€šè¿‡Dockerå®¹å™¨åŒ–éƒ¨ç½²åœ¨Kubernetesé›†ç¾¤ä¸Šï¼Œå®ç°é«˜å¯ç”¨å’Œå¼¹æ€§æ‰©ç¼©å®¹ã€‚è¯¥æ¶æ„è®¾è®¡å……åˆ†æ»¡è¶³PRDä¸­æå‡ºçš„é«˜æ€§èƒ½æ£€ç´¢ï¼ˆ<2ç§’å“åº”ï¼‰ã€å¤§è§„æ¨¡å­˜å‚¨ï¼ˆ10ä¸‡+æ–‡æ¡£ï¼‰å’Œé«˜å¯ç”¨æ€§ï¼ˆ99.5%ï¼‰è¦æ±‚ã€‚

### å¹³å°å’ŒåŸºç¡€è®¾æ–½é€‰æ‹©

åŸºäºPRDè¦æ±‚å’ŒæŠ€æœ¯å‡è®¾ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä»¥ä¸‹å¹³å°é€‰é¡¹ï¼š

#### é€‰é¡¹å¯¹æ¯”

**1. AWSå…¨æ ˆæ–¹æ¡ˆ**
- **ä¼˜åŠ¿**ï¼šæˆç†Ÿçš„å¾®æœåŠ¡ç”Ÿæ€ï¼ˆEKSã€API Gatewayã€Lambdaï¼‰ã€ä¸°å¯Œçš„AI/MLæœåŠ¡ï¼ˆSageMakerã€Bedrockï¼‰ã€å…¨çƒCDNå’Œé«˜å¯ç”¨æ€§
- **åŠ£åŠ¿**ï¼šæˆæœ¬è¾ƒé«˜ã€å‚å•†é”å®šé£é™©ã€å­¦ä¹ æ›²çº¿é™¡å³­
- **é€‚ç”¨åœºæ™¯**ï¼šä¼ä¸šçº§éƒ¨ç½²ï¼Œéœ€è¦å…¨çƒåŒ–æœåŠ¡

**2. Google Cloudæ–¹æ¡ˆ**
- **ä¼˜åŠ¿**ï¼šAI/MLæœåŠ¡é¢†å…ˆï¼ˆVertex AIã€BigQuery MLï¼‰ã€KubernetesåŸç”Ÿæ”¯æŒï¼ˆGKEï¼‰ã€æˆæœ¬æ•ˆç›Šå¥½
- **åŠ£åŠ¿**ï¼šç”Ÿæ€ç›¸å¯¹è¾ƒå°ã€éƒ¨åˆ†åœ°åŒºæœåŠ¡æœ‰é™
- **é€‚ç”¨åœºæ™¯**ï¼šAI/MLé‡åº¦åº”ç”¨ï¼Œæˆæœ¬æ•æ„Ÿé¡¹ç›®

**3. æ··åˆäº‘æ–¹æ¡ˆï¼ˆæ¨èï¼‰**
- **ä¼˜åŠ¿**ï¼šé¿å…å‚å•†é”å®šã€æˆæœ¬å¯æ§ã€æŠ€æœ¯æ ˆçµæ´»ã€æ”¯æŒå¤šäº‘éƒ¨ç½²
- **åŠ£åŠ¿**ï¼šè¿ç»´å¤æ‚åº¦è¾ƒé«˜ã€éœ€è¦æ›´å¤šDevOpsæŠ•å…¥
- **é€‚ç”¨åœºæ™¯**ï¼šä¸­é•¿æœŸé¡¹ç›®ï¼Œéœ€è¦æŠ€æœ¯è‡ªä¸»å¯æ§

#### æ¨èæ–¹æ¡ˆ

**å¹³å°ï¼š** æ··åˆäº‘æ¶æ„ï¼ˆä¸»è¦åŸºäºKubernetesï¼‰  
**æ ¸å¿ƒæœåŠ¡ï¼š** 
- **å®¹å™¨ç¼–æ’**ï¼šKubernetes (EKS/GKE/AKS)
- **APIç½‘å…³**ï¼šKong + Nginx Ingress
- **æ¶ˆæ¯é˜Ÿåˆ—**ï¼šRedis + Celery
- **ç›‘æ§ä½“ç³»**ï¼šPrometheus + Grafana + Jaeger
- **CI/CD**ï¼šGitLab CI/CD + ArgoCD
- **å­˜å‚¨**ï¼šäº‘å¯¹è±¡å­˜å‚¨ï¼ˆS3/GCS/Azure Blobï¼‰

**éƒ¨ç½²ä¸»æœºå’ŒåŒºåŸŸï¼š** å¤šåŒºåŸŸéƒ¨ç½²ï¼ˆä¸»åŒºåŸŸ + ç¾å¤‡åŒºåŸŸï¼‰ï¼Œæ”¯æŒå°±è¿‘è®¿é—®

### ä»“åº“ç»“æ„

**ç»“æ„ï¼š** Monorepoï¼ˆå•ä¸€ä»“åº“ï¼‰  
**Monorepoå·¥å…·ï¼š** Python Poetry + Docker Composeï¼ˆå¼€å‘ç¯å¢ƒï¼‰  
**åŒ…ç»„ç»‡ç­–ç•¥ï¼š** æŒ‰æœåŠ¡è¾¹ç•Œç»„ç»‡ï¼Œå…±äº«ç»„ä»¶ç‹¬ç«‹ç®¡ç†

```
knowledge-rag/
â”œâ”€â”€ services/                 # å¾®æœåŠ¡ç›®å½•
â”‚   â”œâ”€â”€ api-gateway/         # APIç½‘å…³æœåŠ¡
â”‚   â”œâ”€â”€ document-processor/  # æ–‡æ¡£å¤„ç†æœåŠ¡
â”‚   â”œâ”€â”€ vector-search/       # å‘é‡æ£€ç´¢æœåŠ¡
â”‚   â”œâ”€â”€ knowledge-graph/     # çŸ¥è¯†å›¾è°±æœåŠ¡
â”‚   â”œâ”€â”€ query-engine/        # æŸ¥è¯¢å¼•æ“æœåŠ¡
â”‚   â””â”€â”€ user-management/     # ç”¨æˆ·ç®¡ç†æœåŠ¡
â”œâ”€â”€ shared/                  # å…±äº«ç»„ä»¶
â”‚   â”œâ”€â”€ common/             # é€šç”¨å·¥å…·å’Œé…ç½®
â”‚   â”œâ”€â”€ models/             # æ•°æ®æ¨¡å‹å®šä¹‰
â”‚   â””â”€â”€ clients/            # æœåŠ¡é—´é€šä¿¡å®¢æˆ·ç«¯
â”œâ”€â”€ infrastructure/          # åŸºç¡€è®¾æ–½ä»£ç 
â”‚   â”œâ”€â”€ k8s/               # Kubernetesé…ç½®
â”‚   â”œâ”€â”€ docker/            # Dockeré…ç½®
â”‚   â””â”€â”€ terraform/         # åŸºç¡€è®¾æ–½å³ä»£ç 
â”œâ”€â”€ docs/                   # æ–‡æ¡£ç›®å½•
â”œâ”€â”€ tests/                  # é›†æˆæµ‹è¯•
â””â”€â”€ tools/                  # å¼€å‘å·¥å…·
```

### é«˜å±‚æ¶æ„å›¾

```mermaid
graph TB
    %% å®¢æˆ·ç«¯å±‚
    Client["ğŸ–¥ï¸ å®¢æˆ·ç«¯åº”ç”¨<br/>(Web/Mobile/API)"] 
    
    %% APIç½‘å…³å±‚
    subgraph "APIç½‘å…³å±‚"
        Kong["ğŸšª Kong API Gateway<br/>è·¯ç”±/è®¤è¯/é™æµ"]
        Nginx["âš¡ Nginx Ingress<br/>è´Ÿè½½å‡è¡¡/SSL"]
    end
    
    %% æ ¸å¿ƒæœåŠ¡å±‚
    subgraph "æ ¸å¿ƒæœåŠ¡å±‚"
        UserMgmt["ğŸ‘¤ ç”¨æˆ·ç®¡ç†æœåŠ¡<br/>è®¤è¯/æˆæƒ/ç”¨æˆ·æ•°æ®"]
        DocProcessor["ğŸ“„ æ–‡æ¡£å¤„ç†æœåŠ¡<br/>è§£æ/é¢„å¤„ç†/OCR"]
        VectorSearch["ğŸ” å‘é‡æ£€ç´¢æœåŠ¡<br/>è¯­ä¹‰æœç´¢/ç›¸ä¼¼åº¦"]
        KnowledgeGraph["ğŸ•¸ï¸ çŸ¥è¯†å›¾è°±æœåŠ¡<br/>å®ä½“å…³ç³»/å›¾æŸ¥è¯¢"]
        QueryEngine["ğŸ§  æŸ¥è¯¢å¼•æ“æœåŠ¡<br/>GraphRAG/LLMé›†æˆ"]
        Notification["ğŸ“¢ é€šçŸ¥æœåŠ¡<br/>æ¶ˆæ¯æ¨é€/é‚®ä»¶"]
    end
    
    %% æ•°æ®å­˜å‚¨å±‚
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        PostgreSQL[("ğŸ—„ï¸ PostgreSQL<br/>ç»“æ„åŒ–æ•°æ®")]
        MinIO[("ğŸ“¦ MinIO/S3<br/>æ–‡ä»¶å­˜å‚¨")]
        Weaviate[("ğŸ”¢ Weaviate<br/>å‘é‡æ•°æ®åº“")]
        Neo4j[("ğŸ•¸ï¸ Neo4j<br/>å›¾æ•°æ®åº“")]
        Redis[("âš¡ Redis<br/>ç¼“å­˜/ä¼šè¯")]
    end
    
    %% å¤–éƒ¨æœåŠ¡
    subgraph "å¤–éƒ¨æœåŠ¡"
        LLM["ğŸ¤– å¤§è¯­è¨€æ¨¡å‹<br/>(OpenAI/Claude)"] 
        OCR["ğŸ‘ï¸ OCRæœåŠ¡<br/>(Tesseract/äº‘OCR)"]
    end
    
    %% æ¶ˆæ¯é˜Ÿåˆ—
    subgraph "æ¶ˆæ¯é˜Ÿåˆ—"
        Celery["ğŸ“¨ Celery + Redis<br/>å¼‚æ­¥ä»»åŠ¡å¤„ç†"]
    end
    
    %% è¿æ¥å…³ç³»
    Client --> Nginx
    Nginx --> Kong
    Kong --> UserMgmt
    Kong --> DocProcessor
    Kong --> VectorSearch
    Kong --> KnowledgeGraph
    Kong --> QueryEngine
    Kong --> Notification
    
    %% æœåŠ¡é—´é€šä¿¡
    DocProcessor --> Celery
    VectorSearch --> Celery
    KnowledgeGraph --> Celery
    QueryEngine --> VectorSearch
    QueryEngine --> KnowledgeGraph
    QueryEngine --> LLM
    DocProcessor --> OCR
    
    %% æ•°æ®è¿æ¥
    UserMgmt --> PostgreSQL
    DocProcessor --> MinIO
    DocProcessor --> PostgreSQL
    VectorSearch --> Weaviate
    KnowledgeGraph --> Neo4j
    QueryEngine --> Redis
    Notification --> Redis
    
    %% æ ·å¼å®šä¹‰
    classDef serviceBox fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef dataBox fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef externalBox fill:#fff3e0,stroke:#e65100,stroke-width:2px
    
    class UserMgmt,DocProcessor,VectorSearch,KnowledgeGraph,QueryEngine,Notification serviceBox
    class PostgreSQL,MinIO,Weaviate,Neo4j,Redis dataBox
    class LLM,OCR externalBox
```

### æ¶æ„æ¨¡å¼

ä»¥ä¸‹æ˜¯æŒ‡å¯¼æ•´ä¸ªç³»ç»Ÿå¼€å‘çš„æ ¸å¿ƒæ¶æ„æ¨¡å¼ï¼š

- **å¾®æœåŠ¡æ¶æ„**ï¼šæŒ‰ä¸šåŠ¡é¢†åŸŸæ‹†åˆ†æœåŠ¡ï¼Œå®ç°ç‹¬ç«‹éƒ¨ç½²å’Œæ‰©å±• - _ç†ç”±ï¼š_ æ”¯æŒå›¢é˜Ÿç‹¬ç«‹å¼€å‘ï¼ŒæŠ€æœ¯æ ˆçµæ´»é€‰æ‹©ï¼Œæ•…éšœéš”ç¦»

- **APIç½‘å…³æ¨¡å¼**ï¼šç»Ÿä¸€APIå…¥å£ï¼Œé›†ä¸­å¤„ç†è®¤è¯ã€é™æµã€ç›‘æ§ - _ç†ç”±ï¼š_ ç®€åŒ–å®¢æˆ·ç«¯é›†æˆï¼Œç»Ÿä¸€å®‰å…¨ç­–ç•¥ï¼Œä¾¿äºAPIç®¡ç†

- **äº‹ä»¶é©±åŠ¨æ¶æ„**ï¼šé€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å®ç°æœåŠ¡é—´å¼‚æ­¥é€šä¿¡ - _ç†ç”±ï¼š_ æé«˜ç³»ç»Ÿååé‡ï¼Œé™ä½æœåŠ¡è€¦åˆåº¦ï¼Œæ”¯æŒå¤æ‚ä¸šåŠ¡æµç¨‹

- **CQRSæ¨¡å¼**ï¼šè¯»å†™åˆ†ç¦»ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ - _ç†ç”±ï¼š_ GraphRAGæŸ¥è¯¢å¤æ‚åº¦é«˜ï¼Œéœ€è¦ä¸“é—¨çš„è¯»å–ä¼˜åŒ–

- **ä»“å‚¨æ¨¡å¼**ï¼šæŠ½è±¡æ•°æ®è®¿é—®å±‚ï¼Œæ”¯æŒå¤šæ•°æ®åº“ç­–ç•¥ - _ç†ç”±ï¼š_ ä¾¿äºå•å…ƒæµ‹è¯•ï¼Œæ”¯æŒæ•°æ®åº“è¿ç§»ï¼Œä»£ç å¯ç»´æŠ¤æ€§

- **æ–­è·¯å™¨æ¨¡å¼**ï¼šé˜²æ­¢çº§è”æ•…éšœï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§ - _ç†ç”±ï¼š_ å¤–éƒ¨LLMæœåŠ¡å¯èƒ½ä¸ç¨³å®šï¼Œéœ€è¦æ•…éšœéš”ç¦»æœºåˆ¶

- **ç¼“å­˜æ¨¡å¼**ï¼šå¤šå±‚ç¼“å­˜ç­–ç•¥ï¼Œæå‡å“åº”æ€§èƒ½ - _ç†ç”±ï¼š_ å‘é‡æ£€ç´¢å’Œå›¾æŸ¥è¯¢è®¡ç®—å¯†é›†ï¼Œç¼“å­˜å¯æ˜¾è‘—æå‡æ€§èƒ½

---

## 3. æŠ€æœ¯æ ˆ

æœ¬èŠ‚å®šä¹‰Knowledge RAGé¡¹ç›®çš„å®Œæ•´æŠ€æœ¯æ ˆé€‰å‹ï¼Œè¿™æ˜¯æ•´ä¸ªé¡¹ç›®å¼€å‘çš„æŠ€æœ¯åŸºå‡†ï¼Œæ‰€æœ‰å¼€å‘å·¥ä½œå¿…é¡»ä¸¥æ ¼éµå¾ªè¿™äº›æŠ€æœ¯é€‰æ‹©å’Œç‰ˆæœ¬è¦æ±‚ã€‚

### æŠ€æœ¯æ ˆé€‰å‹è¡¨

| ç±»åˆ« | æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰æ‹©ç†ç”± |
|------|------|------|------|----------|
| **å¼€å‘è¯­è¨€** | Python | 3.11+ | æ ¸å¿ƒå¼€å‘è¯­è¨€ | AI/MLç”Ÿæ€ä¸°å¯Œï¼Œå¼‚æ­¥æ”¯æŒä¼˜ç§€ï¼Œå¼€å‘æ•ˆç‡é«˜ |
| **Webæ¡†æ¶** | FastAPI | 0.104+ | Webæ¡†æ¶å’ŒAPIæœåŠ¡ | é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶ï¼Œè‡ªåŠ¨APIæ–‡æ¡£ï¼Œç±»å‹å®‰å…¨ |
| **APIé£æ ¼** | REST API | OpenAPI 3.0 | HTTP APIæ¥å£ | æ ‡å‡†åŒ–æ¥å£ï¼Œæ˜“äºé›†æˆå’Œæµ‹è¯•ï¼Œå·¥å…·é“¾æˆç†Ÿ |
| **ä¸»æ•°æ®åº“** | PostgreSQL | 15+ | ç»“æ„åŒ–æ•°æ®å­˜å‚¨ | ACIDäº‹åŠ¡æ”¯æŒï¼ŒJSONæ”¯æŒï¼Œæˆç†Ÿç¨³å®š |
| **å‘é‡æ•°æ®åº“** | Weaviate | 1.22+ | å‘é‡å­˜å‚¨å’Œæ£€ç´¢ | GraphQLæŸ¥è¯¢ï¼Œå¤šæ¨¡æ€æ”¯æŒï¼Œäº‘åŸç”Ÿæ¶æ„ |
| **å›¾æ•°æ®åº“** | Neo4j | 5.0+ | çŸ¥è¯†å›¾è°±å­˜å‚¨ | CypheræŸ¥è¯¢è¯­è¨€ï¼Œå›¾ç®—æ³•ä¸°å¯Œï¼Œå¯è§†åŒ–å·¥å…· |
| **ç¼“å­˜** | Redis | 7.0+ | ç¼“å­˜å’Œä¼šè¯å­˜å‚¨ | é«˜æ€§èƒ½å†…å­˜å­˜å‚¨ï¼Œæ•°æ®ç»“æ„ä¸°å¯Œï¼Œé›†ç¾¤æ”¯æŒ |
| **æ–‡ä»¶å­˜å‚¨** | MinIO/S3 | Latest | å¯¹è±¡å­˜å‚¨æœåŠ¡ | S3å…¼å®¹APIï¼Œå¯æ‰©å±•ï¼Œæ”¯æŒå¤šäº‘éƒ¨ç½² |
| **æ¶ˆæ¯é˜Ÿåˆ—** | Celery + Redis | 5.3+ | å¼‚æ­¥ä»»åŠ¡å¤„ç† | PythonåŸç”Ÿæ”¯æŒï¼Œä»»åŠ¡è°ƒåº¦çµæ´»ï¼Œç›‘æ§å®Œå–„ |
| **è®¤è¯æˆæƒ** | JWT + OAuth2 | - | èº«ä»½è®¤è¯å’Œæˆæƒ | æ— çŠ¶æ€è®¤è¯ï¼Œæ ‡å‡†åè®®ï¼Œæ˜“äºæ‰©å±• |
| **APIç½‘å…³** | Kong | 3.4+ | APIç®¡ç†å’Œè·¯ç”± | æ’ä»¶ç”Ÿæ€ä¸°å¯Œï¼Œæ€§èƒ½ä¼˜ç§€ï¼Œä¼ä¸šçº§ç‰¹æ€§ |
| **è´Ÿè½½å‡è¡¡** | Nginx | 1.24+ | åå‘ä»£ç†å’Œè´Ÿè½½å‡è¡¡ | é«˜æ€§èƒ½ï¼Œé…ç½®çµæ´»ï¼ŒSSLç»ˆç«¯ |
| **å®¹å™¨åŒ–** | Docker | 24.0+ | åº”ç”¨å®¹å™¨åŒ– | ç¯å¢ƒä¸€è‡´æ€§ï¼Œéƒ¨ç½²ç®€åŒ–ï¼Œèµ„æºéš”ç¦» |
| **å®¹å™¨ç¼–æ’** | Kubernetes | 1.28+ | å®¹å™¨é›†ç¾¤ç®¡ç† | è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ŒæœåŠ¡å‘ç°ï¼Œæ»šåŠ¨æ›´æ–° |
| **å•å…ƒæµ‹è¯•** | pytest + httpx | 7.4+ | å•å…ƒå’Œé›†æˆæµ‹è¯• | å¼‚æ­¥æµ‹è¯•æ”¯æŒï¼Œfixtureæœºåˆ¶ï¼Œæ’ä»¶ä¸°å¯Œ |
| **APIæµ‹è¯•** | pytest-asyncio | 0.21+ | å¼‚æ­¥APIæµ‹è¯• | FastAPIåŸç”Ÿæ”¯æŒï¼Œæµ‹è¯•è¦†ç›–å®Œæ•´ |
| **E2Eæµ‹è¯•** | Postman/Newman | Latest | ç«¯åˆ°ç«¯APIæµ‹è¯• | è‡ªåŠ¨åŒ–æµ‹è¯•ï¼ŒCI/CDé›†æˆï¼Œå›¢é˜Ÿåä½œ |
| **ä»£ç è´¨é‡** | Black + isort + flake8 | Latest | ä»£ç æ ¼å¼åŒ–å’Œæ£€æŸ¥ | ä»£ç é£æ ¼ç»Ÿä¸€ï¼Œè´¨é‡ä¿è¯ï¼ŒCIé›†æˆ |
| **ä¾èµ–ç®¡ç†** | Poetry | 1.6+ | PythonåŒ…ç®¡ç† | ä¾èµ–è§£æï¼Œè™šæ‹Ÿç¯å¢ƒï¼Œæ„å»ºå‘å¸ƒ |
| **æ„å»ºå·¥å…·** | Docker Compose | 2.21+ | æœ¬åœ°å¼€å‘ç¯å¢ƒ | å¤šæœåŠ¡ç¼–æ’ï¼Œç¯å¢ƒéš”ç¦»ï¼Œå¿«é€Ÿå¯åŠ¨ |
| **CI/CD** | GitLab CI/CD | - | æŒç»­é›†æˆå’Œéƒ¨ç½² | ä»£ç è´¨é‡æ£€æŸ¥ï¼Œè‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œéƒ¨ç½²æµæ°´çº¿ |
| **åŸºç¡€è®¾æ–½å³ä»£ç ** | Terraform | 1.6+ | äº‘èµ„æºç®¡ç† | å¤šäº‘æ”¯æŒï¼ŒçŠ¶æ€ç®¡ç†ï¼Œç‰ˆæœ¬æ§åˆ¶ |
| **é…ç½®ç®¡ç†** | Helm | 3.13+ | Kubernetesåº”ç”¨ç®¡ç† | æ¨¡æ¿åŒ–éƒ¨ç½²ï¼Œç‰ˆæœ¬ç®¡ç†ï¼Œå›æ»šæ”¯æŒ |
| **ç›‘æ§** | Prometheus + Grafana | 2.47+ / 10.2+ | ç³»ç»Ÿç›‘æ§å’Œå¯è§†åŒ– | æŒ‡æ ‡æ”¶é›†ï¼Œå‘Šè­¦è§„åˆ™ï¼Œä»ªè¡¨æ¿ä¸°å¯Œ |
| **é“¾è·¯è¿½è¸ª** | Jaeger | 1.50+ | åˆ†å¸ƒå¼è¿½è¸ª | å¾®æœåŠ¡è°ƒç”¨é“¾ï¼Œæ€§èƒ½åˆ†æï¼Œæ•…éšœå®šä½ |
| **æ—¥å¿—ç®¡ç†** | ELK Stack | 8.10+ | æ—¥å¿—æ”¶é›†å’Œåˆ†æ | é›†ä¸­åŒ–æ—¥å¿—ï¼Œå…¨æ–‡æœç´¢ï¼Œå¯è§†åŒ–åˆ†æ |
| **æ–‡æ¡£ç”Ÿæˆ** | Swagger UI | 5.9+ | APIæ–‡æ¡£å±•ç¤º | äº¤äº’å¼æ–‡æ¡£ï¼Œåœ¨çº¿æµ‹è¯•ï¼Œè‡ªåŠ¨ç”Ÿæˆ |
| **å¼€å‘å·¥å…·** | VS Code + Pythonæ‰©å±• | Latest | é›†æˆå¼€å‘ç¯å¢ƒ | æ™ºèƒ½æç¤ºï¼Œè°ƒè¯•æ”¯æŒï¼Œæ’ä»¶ä¸°å¯Œ |

### æ ¸å¿ƒæŠ€æœ¯é€‰å‹è¯´æ˜

#### æ ¸å¿ƒæŠ€æœ¯æ ˆ

**FastAPI + Python 3.11**
- **å¼‚æ­¥æ€§èƒ½**ï¼šåŸç”Ÿasync/awaitæ”¯æŒï¼Œå¤„ç†é«˜å¹¶å‘è¯·æ±‚
- **ç±»å‹å®‰å…¨**ï¼šåŸºäºPydanticçš„æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
- **è‡ªåŠ¨æ–‡æ¡£**ï¼šOpenAPI/Swaggerè‡ªåŠ¨ç”Ÿæˆï¼Œå‡å°‘æ–‡æ¡£ç»´æŠ¤æˆæœ¬
- **ç”Ÿæ€å…¼å®¹**ï¼šä¸AI/MLåº“ï¼ˆtransformersã€langchainç­‰ï¼‰æ— ç¼é›†æˆ

#### æ•°æ®å­˜å‚¨ç­–ç•¥

**å¤šæ•°æ®åº“æ¶æ„è®¾è®¡**
- **PostgreSQL**ï¼šç”¨æˆ·æ•°æ®ã€æ–‡æ¡£å…ƒæ•°æ®ã€ç³»ç»Ÿé…ç½®ç­‰ç»“æ„åŒ–æ•°æ®
- **Weaviate**ï¼šæ–‡æ¡£å‘é‡ã€è¯­ä¹‰æ£€ç´¢ã€ç›¸ä¼¼åº¦è®¡ç®—
- **Neo4j**ï¼šå®ä½“å…³ç³»ã€çŸ¥è¯†å›¾è°±ã€å›¾ç®—æ³•è®¡ç®—
- **Redis**ï¼šä¼šè¯ç¼“å­˜ã€æŸ¥è¯¢ç»“æœç¼“å­˜ã€åˆ†å¸ƒå¼é”

#### å¾®æœåŠ¡é€šä¿¡

**åŒæ­¥ + å¼‚æ­¥æ··åˆæ¨¡å¼**
- **åŒæ­¥é€šä¿¡**ï¼šREST APIç”¨äºå®æ—¶æŸ¥è¯¢å’Œç”¨æˆ·äº¤äº’
- **å¼‚æ­¥é€šä¿¡**ï¼šCeleryä»»åŠ¡é˜Ÿåˆ—å¤„ç†æ–‡æ¡£è§£æã€å‘é‡åŒ–ã€å›¾æ„å»º
- **äº‹ä»¶é©±åŠ¨**ï¼šRedis Pub/Subå®ç°æœåŠ¡é—´äº‹ä»¶é€šçŸ¥

#### éƒ¨ç½²å’Œè¿ç»´

**äº‘åŸç”Ÿæ¶æ„**
- **å®¹å™¨åŒ–**ï¼šDockerç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§
- **ç¼–æ’ç®¡ç†**ï¼šKubernetesæä¾›è‡ªåŠ¨æ‰©ç¼©å®¹å’Œæ•…éšœæ¢å¤
- **æœåŠ¡ç½‘æ ¼**ï¼šKong APIç½‘å…³ç»Ÿä¸€ç®¡ç†APIè·¯ç”±å’Œå®‰å…¨
- **å¯è§‚æµ‹æ€§**ï¼šPrometheus + Grafana + Jaegerå…¨æ–¹ä½ç›‘æ§

### ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ

| ç»„ä»¶ | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ | å…¼å®¹æ€§è¯´æ˜ |
|------|----------|----------|------------|
| Python | 3.11.0 | 3.11.6 | å¿…é¡»æ”¯æŒasync/awaitå’Œç±»å‹æç¤º |
| FastAPI | 0.104.0 | 0.104.1 | éœ€è¦OpenAPI 3.0æ”¯æŒ |
| PostgreSQL | 15.0 | 15.4 | éœ€è¦JSONå’Œå…¨æ–‡æœç´¢æ”¯æŒ |
| Weaviate | 1.22.0 | 1.22.4 | éœ€è¦GraphQLå’Œå¤šæ¨¡æ€æ”¯æŒ |
| Neo4j | 5.0.0 | 5.13.0 | éœ€è¦APOCæ’ä»¶å’Œå›¾ç®—æ³•åº“ |
| Redis | 7.0.0 | 7.2.3 | éœ€è¦Streamå’Œæ¨¡å—æ”¯æŒ |
| Kubernetes | 1.28.0 | 1.28.4 | éœ€è¦CRDå’ŒOperatoræ”¯æŒ |

### å¼€å‘ç¯å¢ƒé…ç½®

**æœ¬åœ°å¼€å‘æ ˆ**
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  postgres:
    image: postgres:15.4
    environment:
      POSTGRES_DB: knowledge_rag
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev123
    ports:
      - "5432:5432"
  
  redis:
    image: redis:7.2.3
    ports:
      - "6379:6379"
  
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    ports:
      - "8080:8080"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
  
  neo4j:
    image: neo4j:5.13.0
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: neo4j/dev123
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
```

**Pythonä¾èµ–ç®¡ç†**
```toml
# pyproject.toml
[tool.poetry]
name = "knowledge-rag"
version = "0.1.0"
description = "GraphRAG-based Knowledge Management System"

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.104.1"
uvicorn = {extras = ["standard"], version = "^0.24.0"}
sqlalchemy = "^2.0.23"
alembic = "^1.12.1"
psycopg2-binary = "^2.9.9"
redis = "^5.0.1"
celery = "^5.3.4"
weaviate-client = "^3.25.3"
neo4j = "^5.14.1"
pydantic = "^2.5.0"
python-jose = {extras = ["cryptography"], version = "^3.3.0"}
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
langchain = "^0.0.350"
openai = "^1.3.7"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.3"
pytest-asyncio = "^0.21.1"
httpx = "^0.25.2"
black = "^23.11.0"
isort = "^5.12.0"
flake8 = "^6.1.0"
mypy = "^1.7.1"
```

## 4. æ•°æ®æ¨¡å‹

### 4.1 æ ¸å¿ƒä¸šåŠ¡å®ä½“æ¦‚è¿°

Knowledge RAGç³»ç»Ÿçš„æ•°æ®æ¨¡å‹å›´ç»•çŸ¥è¯†ç®¡ç†å’Œæ™ºèƒ½æ£€ç´¢çš„æ ¸å¿ƒä¸šåŠ¡æµç¨‹è®¾è®¡ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ ¸å¿ƒå®ä½“ï¼š

- **æ–‡æ¡£å®ä½“**ï¼šç³»ç»Ÿä¸­çš„æ ¸å¿ƒçŸ¥è¯†è½½ä½“ï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹
- **ç”¨æˆ·å®ä½“**ï¼šç³»ç»Ÿç”¨æˆ·å’Œæƒé™ç®¡ç†çš„åŸºç¡€
- **çŸ¥è¯†å›¾è°±å®ä½“**ï¼šè¯­ä¹‰å…³ç³»å’Œæ¦‚å¿µçš„ç»“æ„åŒ–è¡¨ç¤º
- **æŸ¥è¯¢ä¼šè¯**ï¼šç”¨æˆ·äº¤äº’å’Œä¸Šä¸‹æ–‡ç®¡ç†
- **å‘é‡ç´¢å¼•**ï¼šè¯­ä¹‰æ£€ç´¢çš„æŠ€æœ¯åŸºç¡€
- **å·¥ä½œç©ºé—´**ï¼šå›¢é˜Ÿåä½œå’Œæƒé™éš”ç¦»çš„ç»„ç»‡å•ä½

### 4.2 æ–‡æ¡£ç®¡ç†æ¨¡å‹

#### Documentï¼ˆæ–‡æ¡£ï¼‰

**Purpose:** ç³»ç»Ÿä¸­çš„æ ¸å¿ƒçŸ¥è¯†è½½ä½“ï¼Œå­˜å‚¨å’Œç®¡ç†ç”¨æˆ·ä¸Šä¼ çš„å„ç±»å­¦æœ¯æ–‡æ¡£å’Œå¤šåª’ä½“å†…å®¹ã€‚

**Key Attributes:**
- id: string - æ–‡æ¡£å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆUUIDæ ¼å¼ï¼‰
- title: string - æ–‡æ¡£æ ‡é¢˜
- originalFilename: string - åŸå§‹æ–‡ä»¶å
- fileType: DocumentType - æ–‡æ¡£ç±»å‹æšä¸¾
- fileSize: number - æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
- uploadedAt: Date - ä¸Šä¼ æ—¶é—´
- processedAt: Date | null - å¤„ç†å®Œæˆæ—¶é—´
- status: ProcessingStatus - å¤„ç†çŠ¶æ€
- metadata: DocumentMetadata - æ–‡æ¡£å…ƒæ•°æ®
- content: DocumentContent - è§£æåçš„å†…å®¹ç»“æ„
- workspaceId: string - æ‰€å±å·¥ä½œç©ºé—´ID
- uploadedBy: string - ä¸Šä¼ ç”¨æˆ·ID
- tags: string[] - æ–‡æ¡£æ ‡ç­¾
- version: number - æ–‡æ¡£ç‰ˆæœ¬å·

```typescript
interface Document {
  id: string;
  title: string;
  originalFilename: string;
  fileType: DocumentType;
  fileSize: number;
  uploadedAt: Date;
  processedAt: Date | null;
  status: ProcessingStatus;
  metadata: DocumentMetadata;
  content: DocumentContent;
  workspaceId: string;
  uploadedBy: string;
  tags: string[];
  version: number;
  createdAt: Date;
  updatedAt: Date;
}

enum DocumentType {
  PDF = 'pdf',
  DOCX = 'docx',
  PPTX = 'pptx',
  IMAGE = 'image',
  TEXT = 'text',
  MARKDOWN = 'markdown'
}

enum ProcessingStatus {
  PENDING = 'pending',
  PROCESSING = 'processing',
  COMPLETED = 'completed',
  FAILED = 'failed',
  ARCHIVED = 'archived'
}

interface DocumentMetadata {
  author?: string;
  subject?: string;
  keywords?: string[];
  creationDate?: Date;
  language?: string;
  pageCount?: number;
  wordCount?: number;
  extractedEntities?: string[];
}

interface DocumentContent {
  rawText: string;
  structuredContent: ContentBlock[];
  extractedImages?: ImageContent[];
  extractedTables?: TableContent[];
  extractedFormulas?: FormulaContent[];
}
```

**Relationships:**
- å±äºä¸€ä¸ªå·¥ä½œç©ºé—´ï¼ˆWorkspaceï¼‰
- ç”±ä¸€ä¸ªç”¨æˆ·ä¸Šä¼ ï¼ˆUserï¼‰
- åŒ…å«å¤šä¸ªå†…å®¹å—ï¼ˆContentBlockï¼‰
- å…³è”å¤šä¸ªå‘é‡åµŒå…¥ï¼ˆVectorEmbeddingï¼‰
- å‚ä¸å¤šä¸ªçŸ¥è¯†å›¾è°±å…³ç³»ï¼ˆKnowledgeGraphRelationï¼‰

#### ContentBlockï¼ˆå†…å®¹å—ï¼‰

**Purpose:** æ–‡æ¡£å†…å®¹çš„ç»“æ„åŒ–è¡¨ç¤ºå•å…ƒï¼Œæ”¯æŒä¸åŒç±»å‹çš„å¤šæ¨¡æ€å†…å®¹å—ã€‚

**Key Attributes:**
- id: string - å†…å®¹å—å”¯ä¸€æ ‡è¯†ç¬¦
- documentId: string - æ‰€å±æ–‡æ¡£ID
- type: ContentBlockType - å†…å®¹å—ç±»å‹
- content: string - æ–‡æœ¬å†…å®¹
- position: BlockPosition - åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®ä¿¡æ¯
- metadata: BlockMetadata - å†…å®¹å—å…ƒæ•°æ®
- vectorId: string | null - å…³è”çš„å‘é‡åµŒå…¥ID

```typescript
interface ContentBlock {
  id: string;
  documentId: string;
  type: ContentBlockType;
  content: string;
  position: BlockPosition;
  metadata: BlockMetadata;
  vectorId: string | null;
  createdAt: Date;
}

enum ContentBlockType {
  PARAGRAPH = 'paragraph',
  HEADING = 'heading',
  TABLE = 'table',
  IMAGE = 'image',
  FORMULA = 'formula',
  CODE = 'code',
  LIST = 'list'
}

interface BlockPosition {
  pageNumber?: number;
  startOffset: number;
  endOffset: number;
  boundingBox?: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
}

interface BlockMetadata {
  confidence?: number;
  language?: string;
  fontSize?: number;
  fontFamily?: string;
  extractionMethod?: string;
}
```

### 4.3 ç”¨æˆ·ç®¡ç†æ¨¡å‹

#### Userï¼ˆç”¨æˆ·ï¼‰

**Purpose:** ç³»ç»Ÿç”¨æˆ·çš„åŸºç¡€ä¿¡æ¯å’Œèº«ä»½è®¤è¯ç®¡ç†ã€‚

**Key Attributes:**
- id: string - ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
- email: string - ç”¨æˆ·é‚®ç®±ï¼ˆç™»å½•å‡­è¯ï¼‰
- username: string - ç”¨æˆ·å
- displayName: string - æ˜¾ç¤ºåç§°
- avatar: string | null - å¤´åƒURL
- role: UserRole - ç”¨æˆ·è§’è‰²
- preferences: UserPreferences - ç”¨æˆ·åå¥½è®¾ç½®
- researchFields: string[] - ç ”ç©¶é¢†åŸŸæ ‡ç­¾
- isActive: boolean - è´¦æˆ·çŠ¶æ€
- lastLoginAt: Date | null - æœ€åç™»å½•æ—¶é—´

```typescript
interface User {
  id: string;
  email: string;
  username: string;
  displayName: string;
  avatar: string | null;
  role: UserRole;
  preferences: UserPreferences;
  researchFields: string[];
  isActive: boolean;
  lastLoginAt: Date | null;
  createdAt: Date;
  updatedAt: Date;
}

enum UserRole {
  ADMIN = 'admin',
  RESEARCHER = 'researcher',
  STUDENT = 'student',
  GUEST = 'guest'
}

interface UserPreferences {
  language: string;
  timezone: string;
  theme: 'light' | 'dark' | 'auto';
  notificationSettings: {
    email: boolean;
    inApp: boolean;
    documentProcessing: boolean;
    weeklyDigest: boolean;
  };
  searchSettings: {
    defaultSearchMode: 'vector' | 'graph' | 'hybrid';
    resultsPerPage: number;
    includeImages: boolean;
  };
}
```

**Relationships:**
- æ‹¥æœ‰å¤šä¸ªå·¥ä½œç©ºé—´ï¼ˆWorkspaceï¼‰
- ä¸Šä¼ å¤šä¸ªæ–‡æ¡£ï¼ˆDocumentï¼‰
- åˆ›å»ºå¤šä¸ªæŸ¥è¯¢ä¼šè¯ï¼ˆQuerySessionï¼‰
- å‚ä¸å¤šä¸ªå·¥ä½œç©ºé—´åä½œï¼ˆWorkspaceMemberï¼‰

#### Workspaceï¼ˆå·¥ä½œç©ºé—´ï¼‰

**Purpose:** å›¢é˜Ÿåä½œå’Œæƒé™éš”ç¦»çš„ç»„ç»‡å•ä½ï¼Œæ”¯æŒä¸ªäººå’Œå›¢é˜ŸçŸ¥è¯†åº“ç®¡ç†ã€‚

**Key Attributes:**
- id: string - å·¥ä½œç©ºé—´å”¯ä¸€æ ‡è¯†ç¬¦
- name: string - å·¥ä½œç©ºé—´åç§°
- description: string - å·¥ä½œç©ºé—´æè¿°
- type: WorkspaceType - å·¥ä½œç©ºé—´ç±»å‹
- ownerId: string - æ‰€æœ‰è€…ç”¨æˆ·ID
- settings: WorkspaceSettings - å·¥ä½œç©ºé—´è®¾ç½®
- isPublic: boolean - æ˜¯å¦å…¬å¼€å¯è§
- documentCount: number - æ–‡æ¡£æ•°é‡ç»Ÿè®¡
- memberCount: number - æˆå‘˜æ•°é‡ç»Ÿè®¡

```typescript
interface Workspace {
  id: string;
  name: string;
  description: string;
  type: WorkspaceType;
  ownerId: string;
  settings: WorkspaceSettings;
  isPublic: boolean;
  documentCount: number;
  memberCount: number;
  createdAt: Date;
  updatedAt: Date;
}

enum WorkspaceType {
  PERSONAL = 'personal',
  TEAM = 'team',
  ORGANIZATION = 'organization',
  PUBLIC = 'public'
}

interface WorkspaceSettings {
  allowGuestAccess: boolean;
  requireApprovalForJoin: boolean;
  maxDocuments: number;
  maxStorageSize: number;
  enableVersionControl: boolean;
  defaultPermissions: {
    read: boolean;
    write: boolean;
    delete: boolean;
    share: boolean;
  };
}
```

### 4.4 çŸ¥è¯†å›¾è°±æ¨¡å‹

#### KnowledgeEntityï¼ˆçŸ¥è¯†å®ä½“ï¼‰

**Purpose:** çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“èŠ‚ç‚¹ï¼Œè¡¨ç¤ºä»æ–‡æ¡£ä¸­æå–çš„æ¦‚å¿µã€äººç‰©ã€æœºæ„ç­‰è¯­ä¹‰å®ä½“ã€‚

**Key Attributes:**
- id: string - å®ä½“å”¯ä¸€æ ‡è¯†ç¬¦
- name: string - å®ä½“åç§°
- type: EntityType - å®ä½“ç±»å‹
- description: string - å®ä½“æè¿°
- aliases: string[] - å®ä½“åˆ«å
- properties: Record<string, any> - å®ä½“å±æ€§
- confidence: number - æå–ç½®ä¿¡åº¦
- sourceDocuments: string[] - æ¥æºæ–‡æ¡£IDåˆ—è¡¨
- workspaceId: string - æ‰€å±å·¥ä½œç©ºé—´

```typescript
interface KnowledgeEntity {
  id: string;
  name: string;
  type: EntityType;
  description: string;
  aliases: string[];
  properties: Record<string, any>;
  confidence: number;
  sourceDocuments: string[];
  workspaceId: string;
  createdAt: Date;
  updatedAt: Date;
}

enum EntityType {
  PERSON = 'person',
  ORGANIZATION = 'organization',
  CONCEPT = 'concept',
  TECHNOLOGY = 'technology',
  METHOD = 'method',
  DATASET = 'dataset',
  PUBLICATION = 'publication',
  LOCATION = 'location'
}
```

#### KnowledgeRelationï¼ˆçŸ¥è¯†å…³ç³»ï¼‰

**Purpose:** çŸ¥è¯†å›¾è°±ä¸­çš„å…³ç³»è¾¹ï¼Œè¡¨ç¤ºå®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³è”ã€‚

**Key Attributes:**
- id: string - å…³ç³»å”¯ä¸€æ ‡è¯†ç¬¦
- sourceEntityId: string - æºå®ä½“ID
- targetEntityId: string - ç›®æ ‡å®ä½“ID
- relationType: RelationType - å…³ç³»ç±»å‹
- properties: Record<string, any> - å…³ç³»å±æ€§
- confidence: number - å…³ç³»ç½®ä¿¡åº¦
- evidence: RelationEvidence[] - å…³ç³»è¯æ®
- workspaceId: string - æ‰€å±å·¥ä½œç©ºé—´

```typescript
interface KnowledgeRelation {
  id: string;
  sourceEntityId: string;
  targetEntityId: string;
  relationType: RelationType;
  properties: Record<string, any>;
  confidence: number;
  evidence: RelationEvidence[];
  workspaceId: string;
  createdAt: Date;
  updatedAt: Date;
}

enum RelationType {
  AUTHORED_BY = 'authored_by',
  BELONGS_TO = 'belongs_to',
  USES = 'uses',
  IMPLEMENTS = 'implements',
  EXTENDS = 'extends',
  RELATED_TO = 'related_to',
  PART_OF = 'part_of',
  INFLUENCES = 'influences'
}

interface RelationEvidence {
  documentId: string;
  contentBlockId: string;
  extractedText: string;
  confidence: number;
}
```

### 4.5 æŸ¥è¯¢å’Œæ£€ç´¢æ¨¡å‹

#### QuerySessionï¼ˆæŸ¥è¯¢ä¼šè¯ï¼‰

**Purpose:** ç”¨æˆ·æŸ¥è¯¢ä¼šè¯çš„ç®¡ç†ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ä¿æŒã€‚

**Key Attributes:**
- id: string - ä¼šè¯å”¯ä¸€æ ‡è¯†ç¬¦
- userId: string - ç”¨æˆ·ID
- workspaceId: string - å·¥ä½œç©ºé—´ID
- title: string - ä¼šè¯æ ‡é¢˜
- context: SessionContext - ä¼šè¯ä¸Šä¸‹æ–‡
- queries: Query[] - æŸ¥è¯¢å†å²
- isActive: boolean - ä¼šè¯çŠ¶æ€
- lastActivityAt: Date - æœ€åæ´»åŠ¨æ—¶é—´

```typescript
interface QuerySession {
  id: string;
  userId: string;
  workspaceId: string;
  title: string;
  context: SessionContext;
  queries: Query[];
  isActive: boolean;
  lastActivityAt: Date;
  createdAt: Date;
  updatedAt: Date;
}

interface SessionContext {
  researchTopic?: string;
  focusDocuments?: string[];
  preferredLanguage: string;
  searchMode: 'vector' | 'graph' | 'hybrid';
  conversationHistory: ConversationTurn[];
}

interface ConversationTurn {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  metadata?: Record<string, any>;
}
```

#### Queryï¼ˆæŸ¥è¯¢ï¼‰

**Purpose:** å•æ¬¡æŸ¥è¯¢è¯·æ±‚çš„è¯¦ç»†è®°å½•ï¼ŒåŒ…å«æŸ¥è¯¢å‚æ•°ã€ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡ã€‚

**Key Attributes:**
- id: string - æŸ¥è¯¢å”¯ä¸€æ ‡è¯†ç¬¦
- sessionId: string - æ‰€å±ä¼šè¯ID
- queryText: string - æŸ¥è¯¢æ–‡æœ¬
- queryType: QueryType - æŸ¥è¯¢ç±»å‹
- parameters: QueryParameters - æŸ¥è¯¢å‚æ•°
- results: QueryResult[] - æŸ¥è¯¢ç»“æœ
- performance: QueryPerformance - æ€§èƒ½æŒ‡æ ‡
- feedback: QueryFeedback | null - ç”¨æˆ·åé¦ˆ

```typescript
interface Query {
  id: string;
  sessionId: string;
  queryText: string;
  queryType: QueryType;
  parameters: QueryParameters;
  results: QueryResult[];
  performance: QueryPerformance;
  feedback: QueryFeedback | null;
  createdAt: Date;
}

enum QueryType {
  SEMANTIC_SEARCH = 'semantic_search',
  GRAPH_TRAVERSAL = 'graph_traversal',
  HYBRID_RAG = 'hybrid_rag',
  ENTITY_LOOKUP = 'entity_lookup',
  DOCUMENT_QA = 'document_qa'
}

interface QueryParameters {
  maxResults: number;
  similarityThreshold: number;
  includeMetadata: boolean;
  filterCriteria?: {
    documentTypes?: DocumentType[];
    dateRange?: {
      start: Date;
      end: Date;
    };
    tags?: string[];
    authors?: string[];
  };
  graphTraversalDepth?: number;
  rerankingEnabled: boolean;
}

interface QueryResult {
  id: string;
  type: 'document' | 'content_block' | 'entity' | 'relation';
  sourceId: string;
  title: string;
  content: string;
  score: number;
  metadata: Record<string, any>;
  highlights?: TextHighlight[];
  citations?: Citation[];
}

interface QueryPerformance {
  totalDuration: number;
  vectorSearchDuration: number;
  graphTraversalDuration: number;
  rerankingDuration: number;
  resultsCount: number;
  cacheHit: boolean;
}
```

### 4.6 å‘é‡æ£€ç´¢æ¨¡å‹

#### VectorEmbeddingï¼ˆå‘é‡åµŒå…¥ï¼‰

**Purpose:** æ–‡æ¡£å†…å®¹çš„å‘é‡åŒ–è¡¨ç¤ºï¼Œæ”¯æŒè¯­ä¹‰ç›¸ä¼¼æ€§æ£€ç´¢ã€‚

**Key Attributes:**
- id: string - å‘é‡åµŒå…¥å”¯ä¸€æ ‡è¯†ç¬¦
- contentId: string - å…³è”å†…å®¹IDï¼ˆæ–‡æ¡£æˆ–å†…å®¹å—ï¼‰
- contentType: 'document' | 'content_block' - å†…å®¹ç±»å‹
- vector: number[] - å‘é‡æ•°æ®
- model: string - åµŒå…¥æ¨¡å‹åç§°
- dimensions: number - å‘é‡ç»´åº¦
- metadata: EmbeddingMetadata - åµŒå…¥å…ƒæ•°æ®
- workspaceId: string - æ‰€å±å·¥ä½œç©ºé—´

```typescript
interface VectorEmbedding {
  id: string;
  contentId: string;
  contentType: 'document' | 'content_block';
  vector: number[];
  model: string;
  dimensions: number;
  metadata: EmbeddingMetadata;
  workspaceId: string;
  createdAt: Date;
  updatedAt: Date;
}

interface EmbeddingMetadata {
  textLength: number;
  language: string;
  processingTime: number;
  chunkIndex?: number;
  chunkOverlap?: number;
}
```

### 4.7 æ•°æ®æ¨¡å‹å…³ç³»å›¾

```mermaid
erDiagram
    User ||--o{ Workspace : owns
    User ||--o{ Document : uploads
    User ||--o{ QuerySession : creates
    
    Workspace ||--o{ Document : contains
    Workspace ||--o{ KnowledgeEntity : contains
    Workspace ||--o{ KnowledgeRelation : contains
    Workspace ||--o{ WorkspaceMember : has
    
    Document ||--o{ ContentBlock : contains
    Document ||--o{ VectorEmbedding : generates
    
    ContentBlock ||--o| VectorEmbedding : has
    
    KnowledgeEntity ||--o{ KnowledgeRelation : participates
    KnowledgeEntity }o--o{ Document : extracted_from
    
    QuerySession ||--o{ Query : contains
    Query ||--o{ QueryResult : produces
    
    WorkspaceMember {
        string userId
        string workspaceId
        string role
        Date joinedAt
        boolean isActive
    }
```

### 4.8 æ•°æ®æ¨¡å‹è®¾è®¡åŸåˆ™

#### 4.8.1 å¯æ‰©å±•æ€§è®¾è®¡
- **æ¨¡å—åŒ–ç»“æ„**ï¼šæ¯ä¸ªä¸šåŠ¡åŸŸç‹¬ç«‹å»ºæ¨¡ï¼Œæ”¯æŒç‹¬ç«‹æ¼”è¿›
- **å…ƒæ•°æ®æ‰©å±•**ï¼šä½¿ç”¨çµæ´»çš„metadataå­—æ®µæ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šå…³é”®å®ä½“æ”¯æŒç‰ˆæœ¬ç®¡ç†ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§

#### 4.8.2 æ€§èƒ½ä¼˜åŒ–
- **ç´¢å¼•ç­–ç•¥**ï¼šåŸºäºæŸ¥è¯¢æ¨¡å¼è®¾è®¡å¤åˆç´¢å¼•
- **åˆ†åŒºè®¾è®¡**ï¼šå¤§è¡¨æŒ‰å·¥ä½œç©ºé—´æˆ–æ—¶é—´åˆ†åŒº
- **ç¼“å­˜å‹å¥½**ï¼šè®¾è®¡æ”¯æŒRedisç¼“å­˜çš„æ•°æ®ç»“æ„

#### 4.8.3 æ•°æ®ä¸€è‡´æ€§
- **å¤–é”®çº¦æŸ**ï¼šç¡®ä¿å¼•ç”¨å®Œæ•´æ€§
- **äº‹åŠ¡è¾¹ç•Œ**ï¼šæ˜ç¡®å®šä¹‰ä¸šåŠ¡äº‹åŠ¡èŒƒå›´
- **æœ€ç»ˆä¸€è‡´æ€§**ï¼šå¼‚æ­¥å¤„ç†åœºæ™¯é‡‡ç”¨äº‹ä»¶é©±åŠ¨æ¨¡å¼

#### 4.8.4 å®‰å…¨å’Œéšç§
- **æ•°æ®éš”ç¦»**ï¼šå·¥ä½œç©ºé—´çº§åˆ«çš„æ•°æ®éš”ç¦»
- **æ•æ„Ÿä¿¡æ¯**ï¼šPIIæ•°æ®åŠ å¯†å­˜å‚¨
- **å®¡è®¡è¿½è¸ª**ï¼šå…³é”®æ“ä½œè®°å½•å®¡è®¡æ—¥å¿—

## 5. APIè§„èŒƒ

åŸºäºKnowledge RAGé¡¹ç›®çš„åŠŸèƒ½éœ€æ±‚å’ŒREST APIæŠ€æœ¯é€‰å‹ï¼Œæˆ‘è®¾è®¡äº†å®Œæ•´çš„OpenAPI 3.0è§„èŒƒã€‚APIè®¾è®¡éµå¾ªRESTfulåŸåˆ™ï¼Œé‡‡ç”¨èµ„æºå¯¼å‘çš„URLè®¾è®¡ï¼Œæ”¯æŒæ ‡å‡†HTTPæ–¹æ³•ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œè®¤è¯æœºåˆ¶ã€‚

### 5.1 APIè®¾è®¡åŸåˆ™

**èµ„æºå¯¼å‘è®¾è®¡**
- ä½¿ç”¨åè¯è¡¨ç¤ºèµ„æºï¼ŒåŠ¨è¯é€šè¿‡HTTPæ–¹æ³•è¡¨è¾¾
- é‡‡ç”¨å±‚æ¬¡åŒ–URLç»“æ„ï¼Œä½“ç°èµ„æºé—´çš„å…³ç³»
- æ”¯æŒèµ„æºçš„CRUDæ“ä½œå’Œå¤æ‚æŸ¥è¯¢

**ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥**
- é‡‡ç”¨URLè·¯å¾„ç‰ˆæœ¬æ§åˆ¶ï¼ˆ/api/v1/ï¼‰
- å‘åå…¼å®¹æ€§ä¿è¯ï¼Œæ¸è¿›å¼APIæ¼”è¿›
- æ˜ç¡®çš„åºŸå¼ƒç­–ç•¥å’Œè¿ç§»æŒ‡å—

**ç»Ÿä¸€å“åº”æ ¼å¼**
- æ ‡å‡†åŒ–çš„æˆåŠŸå’Œé”™è¯¯å“åº”ç»“æ„
- ä¸°å¯Œçš„HTTPçŠ¶æ€ç ä½¿ç”¨
- è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè°ƒè¯•æ”¯æŒ

### 5.2 æ ¸å¿ƒAPIç«¯ç‚¹è®¾è®¡

#### 5.2.1 æ–‡æ¡£ç®¡ç†API

```yaml
# æ–‡æ¡£ä¸Šä¼ å’Œç®¡ç†
POST /api/v1/workspaces/{workspaceId}/documents
GET /api/v1/workspaces/{workspaceId}/documents
GET /api/v1/workspaces/{workspaceId}/documents/{documentId}
PUT /api/v1/workspaces/{workspaceId}/documents/{documentId}
DELETE /api/v1/workspaces/{workspaceId}/documents/{documentId}

# æ–‡æ¡£å¤„ç†çŠ¶æ€
GET /api/v1/workspaces/{workspaceId}/documents/{documentId}/processing-status
POST /api/v1/workspaces/{workspaceId}/documents/{documentId}/reprocess
```

#### 5.2.2 æ™ºèƒ½æ£€ç´¢API

```yaml
# å‘é‡è¯­ä¹‰æ£€ç´¢
POST /api/v1/workspaces/{workspaceId}/search/semantic
POST /api/v1/workspaces/{workspaceId}/search/hybrid

# çŸ¥è¯†å›¾è°±æŸ¥è¯¢
POST /api/v1/workspaces/{workspaceId}/knowledge-graph/query
GET /api/v1/workspaces/{workspaceId}/knowledge-graph/entities
GET /api/v1/workspaces/{workspaceId}/knowledge-graph/relations
```

#### 5.2.3 é—®ç­”ç³»ç»ŸAPI

```yaml
# ä¼šè¯ç®¡ç†
POST /api/v1/workspaces/{workspaceId}/sessions
GET /api/v1/workspaces/{workspaceId}/sessions
GET /api/v1/workspaces/{workspaceId}/sessions/{sessionId}

# é—®ç­”äº¤äº’
POST /api/v1/workspaces/{workspaceId}/sessions/{sessionId}/queries
GET /api/v1/workspaces/{workspaceId}/sessions/{sessionId}/queries
```

### 5.3 è®¤è¯å’Œæˆæƒ

**JWT Tokenè®¤è¯**
- Bearer Tokenæ–¹å¼ä¼ é€’è®¤è¯ä¿¡æ¯
- TokenåŒ…å«ç”¨æˆ·èº«ä»½å’Œæƒé™ä¿¡æ¯
- æ”¯æŒTokenåˆ·æ–°å’Œæ’¤é”€æœºåˆ¶

**åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRBACï¼‰**
- å·¥ä½œç©ºé—´çº§åˆ«çš„æƒé™ç®¡ç†
- ç»†ç²’åº¦çš„èµ„æºè®¿é—®æ§åˆ¶
- æ”¯æŒè‡ªå®šä¹‰è§’è‰²å’Œæƒé™ç»„åˆ

### 5.4 è¯·æ±‚/å“åº”ç¤ºä¾‹

#### æ–‡æ¡£ä¸Šä¼ è¯·æ±‚
```json
POST /api/v1/workspaces/ws-123/documents
Content-Type: multipart/form-data
Authorization: Bearer eyJhbGciOiJIUzI1NiIs...

{
  "file": "<binary_data>",
  "metadata": {
    "title": "æœºå™¨å­¦ä¹ åŸºç¡€ç†è®º",
    "description": "æ·±åº¦å­¦ä¹ ç®—æ³•ç ”ç©¶è®ºæ–‡",
    "tags": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç®—æ³•"]
  }
}
```

#### è¯­ä¹‰æ£€ç´¢è¯·æ±‚
```json
POST /api/v1/workspaces/ws-123/search/semantic
Content-Type: application/json
Authorization: Bearer eyJhbGciOiJIUzI1NiIs...

{
  "query": "ä»€ä¹ˆæ˜¯å·ç§¯ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­ç®—æ³•ï¼Ÿ",
  "limit": 10,
  "filters": {
    "documentTypes": ["pdf", "docx"],
    "tags": ["æœºå™¨å­¦ä¹ "]
  },
  "includeMetadata": true
}
```

#### ç»Ÿä¸€å“åº”æ ¼å¼
```json
{
  "success": true,
  "data": {
    "results": [...],
    "pagination": {
      "page": 1,
      "limit": 10,
      "total": 156,
      "hasNext": true
    }
  },
  "metadata": {
    "requestId": "req-abc123",
    "timestamp": "2025-01-06T10:30:00Z",
    "processingTime": 245
  }
}
```

### 5.5 é”™è¯¯å¤„ç†

**æ ‡å‡†é”™è¯¯å“åº”**
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
    "details": [
      {
        "field": "query",
        "message": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"
      }
    ]
  },
  "metadata": {
    "requestId": "req-def456",
    "timestamp": "2025-01-06T10:30:00Z"
  }
}
```

### 5.6 APIè®¾è®¡å†³ç­–è¯´æ˜

**å·¥ä½œç©ºé—´éš”ç¦»è®¾è®¡**
é€‰æ‹©åœ¨URLè·¯å¾„ä¸­åŒ…å«workspaceIdçš„åŸå› ï¼š
- æ˜ç¡®çš„æ•°æ®éš”ç¦»è¾¹ç•Œï¼Œé¿å…è·¨ç©ºé—´æ•°æ®æ³„éœ²
- ç®€åŒ–æƒé™éªŒè¯é€»è¾‘ï¼ŒURLçº§åˆ«çš„è®¿é—®æ§åˆ¶
- æ”¯æŒå¤šç§Ÿæˆ·æ¶æ„ï¼Œä¾¿äºåç»­æ‰©å±•

**å¼‚æ­¥å¤„ç†æ¨¡å¼**
æ–‡æ¡£å¤„ç†é‡‡ç”¨å¼‚æ­¥æ¨¡å¼çš„è€ƒè™‘ï¼š
- å¤§æ–‡ä»¶å¤„ç†è€—æ—¶è¾ƒé•¿ï¼Œé¿å…HTTPè¶…æ—¶
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œé˜Ÿåˆ—ç®¡ç†
- æä¾›å¤„ç†çŠ¶æ€æŸ¥è¯¢ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒ

**æ··åˆæ£€ç´¢APIè®¾è®¡**
ç»“åˆå‘é‡æ£€ç´¢å’Œå›¾è°±æŸ¥è¯¢çš„åŸå› ï¼š
- è¯­ä¹‰æ£€ç´¢æä¾›ç›¸å…³æ€§æ’åº
- å›¾è°±æ¨ç†å¢å¼ºç­”æ¡ˆå‡†ç¡®æ€§
- ç»Ÿä¸€æ¥å£ç®€åŒ–å®¢æˆ·ç«¯è°ƒç”¨

## 6. ç»„ä»¶è®¾è®¡

åŸºäºå¾®æœåŠ¡æ¶æ„åŸåˆ™ï¼ŒKnowledge RAGç³»ç»Ÿè¢«è®¾è®¡ä¸º6ä¸ªæ ¸å¿ƒæœåŠ¡ç»„ä»¶ï¼Œæ¯ä¸ªç»„ä»¶è´Ÿè´£ç‰¹å®šçš„ä¸šåŠ¡é¢†åŸŸï¼Œé€šè¿‡æ˜ç¡®çš„æ¥å£è¿›è¡Œäº¤äº’ã€‚ç»„ä»¶è®¾è®¡éµå¾ªå•ä¸€èŒè´£åŸåˆ™ã€é«˜å†…èšä½è€¦åˆçš„è®¾è®¡ç†å¿µã€‚

### 6.1 ç»„ä»¶æ¶æ„æ¦‚è§ˆ

```mermaid
C4Container
    title Knowledge RAG ç³»ç»Ÿç»„ä»¶æ¶æ„
    
    Person(user, "ç”¨æˆ·", "ç ”ç©¶äººå‘˜ã€å­¦è€…")
    
    Container_Boundary(api_layer, "APIå±‚") {
        Container(gateway, "APIç½‘å…³", "Kong", "ç»Ÿä¸€å…¥å£ã€è·¯ç”±ã€è®¤è¯")
    }
    
    Container_Boundary(core_services, "æ ¸å¿ƒæœåŠ¡å±‚") {
        Container(auth_service, "ç”¨æˆ·ç®¡ç†æœåŠ¡", "FastAPI", "è®¤è¯æˆæƒã€ç”¨æˆ·ç®¡ç†")
        Container(doc_service, "æ–‡æ¡£å¤„ç†æœåŠ¡", "FastAPI", "æ–‡æ¡£è§£æã€é¢„å¤„ç†")
        Container(vector_service, "å‘é‡æ£€ç´¢æœåŠ¡", "FastAPI", "è¯­ä¹‰æ£€ç´¢ã€å‘é‡ç®¡ç†")
        Container(graph_service, "çŸ¥è¯†å›¾è°±æœåŠ¡", "FastAPI", "å›¾è°±æ„å»ºã€æ¨ç†æŸ¥è¯¢")
        Container(query_service, "æŸ¥è¯¢å¼•æ“æœåŠ¡", "FastAPI", "GraphRAGã€é—®ç­”")
    }
    
    Container_Boundary(data_layer, "æ•°æ®å­˜å‚¨å±‚") {
        ContainerDb(postgres, "PostgreSQL", "å…³ç³»æ•°æ®åº“", "ç”¨æˆ·ã€æ–‡æ¡£å…ƒæ•°æ®")
        ContainerDb(weaviate, "Weaviate", "å‘é‡æ•°æ®åº“", "æ–‡æ¡£å‘é‡ã€è¯­ä¹‰æ£€ç´¢")
        ContainerDb(neo4j, "Neo4j", "å›¾æ•°æ®åº“", "çŸ¥è¯†å›¾è°±ã€å®ä½“å…³ç³»")
        ContainerDb(redis, "Redis", "ç¼“å­˜æ•°æ®åº“", "ä¼šè¯ã€ç¼“å­˜")
        ContainerDb(minio, "MinIO", "å¯¹è±¡å­˜å‚¨", "æ–‡æ¡£æ–‡ä»¶å­˜å‚¨")
    }
    
    Container_Boundary(message_queue, "æ¶ˆæ¯é˜Ÿåˆ—") {
        Container(celery, "Celery", "ä»»åŠ¡é˜Ÿåˆ—", "å¼‚æ­¥ä»»åŠ¡å¤„ç†")
    }
    
    Rel(user, gateway, "HTTPSè¯·æ±‚")
    Rel(gateway, auth_service, "è®¤è¯è¯·æ±‚")
    Rel(gateway, doc_service, "æ–‡æ¡£ç®¡ç†")
    Rel(gateway, vector_service, "è¯­ä¹‰æ£€ç´¢")
    Rel(gateway, graph_service, "å›¾è°±æŸ¥è¯¢")
    Rel(gateway, query_service, "é—®ç­”æŸ¥è¯¢")
    
    Rel(doc_service, celery, "å¼‚æ­¥å¤„ç†ä»»åŠ¡")
    Rel(vector_service, celery, "å‘é‡åŒ–ä»»åŠ¡")
    Rel(graph_service, celery, "å›¾è°±æ„å»ºä»»åŠ¡")
    
    Rel(auth_service, postgres, "ç”¨æˆ·æ•°æ®")
    Rel(doc_service, postgres, "æ–‡æ¡£å…ƒæ•°æ®")
    Rel(doc_service, minio, "æ–‡æ¡£æ–‡ä»¶")
    Rel(vector_service, weaviate, "å‘é‡æ•°æ®")
    Rel(graph_service, neo4j, "å›¾è°±æ•°æ®")
    Rel(query_service, redis, "ä¼šè¯ç¼“å­˜")
```

### 6.2 æ ¸å¿ƒç»„ä»¶è¯¦ç»†è®¾è®¡

#### 6.2.1 APIç½‘å…³æœåŠ¡ (Kong)

**èŒè´£èŒƒå›´**
- ç»Ÿä¸€APIå…¥å£å’Œè·¯ç”±ç®¡ç†
- è¯·æ±‚è®¤è¯å’ŒæˆæƒéªŒè¯
- æµé‡æ§åˆ¶å’Œé€Ÿç‡é™åˆ¶
- APIç›‘æ§å’Œæ—¥å¿—è®°å½•
- è·¨åŸŸå¤„ç†å’Œå®‰å…¨é˜²æŠ¤

**å…³é”®æ¥å£**
```python
# Kongé…ç½®æ¥å£
class GatewayConfig:
    def configure_routes(self) -> Dict[str, Any]
    def setup_auth_plugins(self) -> List[Dict]
    def configure_rate_limiting(self) -> Dict[str, int]
    def setup_cors_policy(self) -> Dict[str, Any]
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: æ— 
- **ä¸‹æ¸¸ä¾èµ–**: æ‰€æœ‰åç«¯å¾®æœåŠ¡
- **æ•°æ®å­˜å‚¨**: Kongå†…ç½®æ•°æ®åº“ï¼ˆPostgreSQLï¼‰

**æŠ€æœ¯ç»†èŠ‚**
- **éƒ¨ç½²æ–¹å¼**: Dockerå®¹å™¨ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•
- **é…ç½®ç®¡ç†**: å£°æ˜å¼é…ç½®ï¼Œæ”¯æŒçƒ­æ›´æ–°
- **ç›‘æ§æŒ‡æ ‡**: è¯·æ±‚é‡ã€å“åº”æ—¶é—´ã€é”™è¯¯ç‡

#### 6.2.2 ç”¨æˆ·ç®¡ç†æœåŠ¡ (User Management Service)

**èŒè´£èŒƒå›´**
- ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€æ³¨é”€
- JWT Tokenç”Ÿæˆå’ŒéªŒè¯
- å·¥ä½œç©ºé—´ç®¡ç†å’Œæƒé™æ§åˆ¶
- ç”¨æˆ·é…ç½®æ–‡ä»¶ç®¡ç†

**å…³é”®æ¥å£**
```python
class UserService:
    async def authenticate_user(self, credentials: UserCredentials) -> AuthResult
    async def create_workspace(self, user_id: str, workspace_data: WorkspaceCreate) -> Workspace
    async def manage_permissions(self, workspace_id: str, permissions: PermissionUpdate) -> bool
    async def get_user_profile(self, user_id: str) -> UserProfile
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: APIç½‘å…³
- **ä¸‹æ¸¸ä¾èµ–**: PostgreSQLæ•°æ®åº“
- **å¤–éƒ¨æœåŠ¡**: é‚®ä»¶æœåŠ¡ï¼ˆç”¨æˆ·éªŒè¯ï¼‰

**æŠ€æœ¯ç»†èŠ‚**
- **è®¤è¯æœºåˆ¶**: JWT + Refresh Token
- **å¯†ç å®‰å…¨**: bcryptå“ˆå¸ŒåŠ å¯†
- **ä¼šè¯ç®¡ç†**: Redisç¼“å­˜ç”¨æˆ·ä¼šè¯

#### 6.2.3 æ–‡æ¡£å¤„ç†æœåŠ¡ (Document Processing Service)

**èŒè´£èŒƒå›´**
- å¤šæ ¼å¼æ–‡æ¡£ä¸Šä¼ å’Œå­˜å‚¨
- æ–‡æ¡£å†…å®¹è§£æå’Œæå–
- æ–‡æœ¬é¢„å¤„ç†å’Œæ¸…æ´—
- æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†
- å¼‚æ­¥å¤„ç†ä»»åŠ¡è°ƒåº¦

**å…³é”®æ¥å£**
```python
class DocumentService:
    async def upload_document(self, file: UploadFile, metadata: DocumentMetadata) -> Document
    async def parse_document(self, document_id: str) -> ParseResult
    async def extract_content_blocks(self, document_id: str) -> List[ContentBlock]
    async def get_processing_status(self, document_id: str) -> ProcessingStatus
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: APIç½‘å…³
- **ä¸‹æ¸¸ä¾èµ–**: PostgreSQLã€MinIOã€Celeryé˜Ÿåˆ—
- **å¤–éƒ¨æœåŠ¡**: OCRæœåŠ¡ã€æ–‡æ¡£è½¬æ¢æœåŠ¡

**æŠ€æœ¯ç»†èŠ‚**
- **æ–‡ä»¶å¤„ç†**: PyPDF2ã€python-docxã€Pillow
- **å¼‚æ­¥ä»»åŠ¡**: Celery + Redis
- **å­˜å‚¨ç­–ç•¥**: å…ƒæ•°æ®å­˜PostgreSQLï¼Œæ–‡ä»¶å­˜MinIO

#### 6.2.4 å‘é‡æ£€ç´¢æœåŠ¡ (Vector Retrieval Service)

**èŒè´£èŒƒå›´**
- æ–‡æ¡£å†…å®¹å‘é‡åŒ–å¤„ç†
- è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
- å‘é‡ç´¢å¼•ç®¡ç†å’Œä¼˜åŒ–
- æ£€ç´¢ç»“æœæ’åºå’Œè¿‡æ»¤

**å…³é”®æ¥å£**
```python
class VectorService:
    async def vectorize_content(self, content: str, model: str) -> VectorEmbedding
    async def semantic_search(self, query: str, filters: SearchFilters) -> List[SearchResult]
    async def batch_vectorize(self, contents: List[str]) -> List[VectorEmbedding]
    async def update_vector_index(self, document_id: str) -> bool
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: APIç½‘å…³ã€æ–‡æ¡£å¤„ç†æœåŠ¡
- **ä¸‹æ¸¸ä¾èµ–**: Weaviateå‘é‡æ•°æ®åº“
- **å¤–éƒ¨æœåŠ¡**: OpenAI Embedding APIã€æœ¬åœ°åµŒå…¥æ¨¡å‹

**æŠ€æœ¯ç»†èŠ‚**
- **åµŒå…¥æ¨¡å‹**: text-embedding-ada-002ã€sentence-transformers
- **å‘é‡ç»´åº¦**: 1536ç»´ï¼ˆOpenAIï¼‰ã€768ç»´ï¼ˆBERTï¼‰
- **æ£€ç´¢ç®—æ³•**: HNSWè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢

#### 6.2.5 çŸ¥è¯†å›¾è°±æœåŠ¡ (Knowledge Graph Service)

**èŒè´£èŒƒå›´**
- å®ä½“å’Œå…³ç³»æŠ½å–
- çŸ¥è¯†å›¾è°±æ„å»ºå’Œç»´æŠ¤
- å›¾è°±æ¨ç†å’Œè·¯å¾„æŸ¥è¯¢
- å®ä½“é“¾æ¥å’Œæ¶ˆæ­§

**å…³é”®æ¥å£**
```python
class GraphService:
    async def extract_entities(self, text: str) -> List[Entity]
    async def build_knowledge_graph(self, document_id: str) -> GraphBuildResult
    async def query_graph(self, cypher_query: str) -> List[Dict]
    async def find_entity_relations(self, entity_id: str, depth: int) -> RelationGraph
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: APIç½‘å…³ã€æ–‡æ¡£å¤„ç†æœåŠ¡
- **ä¸‹æ¸¸ä¾èµ–**: Neo4jå›¾æ•°æ®åº“
- **å¤–éƒ¨æœåŠ¡**: NLPå®ä½“è¯†åˆ«æœåŠ¡ã€çŸ¥è¯†åº“API

**æŠ€æœ¯ç»†èŠ‚**
- **NLPæ¨¡å‹**: spaCyã€BERT-NERã€GPT-4å®ä½“æŠ½å–
- **å›¾ç®—æ³•**: PageRankã€ç¤¾åŒºå‘ç°ã€è·¯å¾„æœç´¢
- **æŸ¥è¯¢è¯­è¨€**: CypheræŸ¥è¯¢è¯­è¨€

#### 6.2.6 æŸ¥è¯¢å¼•æ“æœåŠ¡ (Query Engine Service)

**èŒè´£èŒƒå›´**
- GraphRAGæ··åˆæ£€ç´¢å®ç°
- LLMé›†æˆå’Œæç¤ºå·¥ç¨‹
- å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†
- ç­”æ¡ˆè´¨é‡è¯„ä¼°å’Œä¼˜åŒ–

**å…³é”®æ¥å£**
```python
class QueryEngine:
    async def graphrag_query(self, query: str, context: QueryContext) -> QueryResult
    async def create_session(self, workspace_id: str) -> QuerySession
    async def multi_turn_chat(self, session_id: str, message: str) -> ChatResponse
    async def evaluate_answer_quality(self, query: str, answer: str) -> QualityScore
```

**ä¾èµ–å…³ç³»**
- **ä¸Šæ¸¸ä¾èµ–**: APIç½‘å…³
- **ä¸‹æ¸¸ä¾èµ–**: å‘é‡æ£€ç´¢æœåŠ¡ã€çŸ¥è¯†å›¾è°±æœåŠ¡ã€Redisç¼“å­˜
- **å¤–éƒ¨æœåŠ¡**: OpenAI GPT-4ã€Claude API

**æŠ€æœ¯ç»†èŠ‚**
- **æ£€ç´¢ç­–ç•¥**: å‘é‡æ£€ç´¢ + å›¾è°±æ¨ç† + é‡æ’åº
- **LLMé›†æˆ**: OpenAI APIã€Anthropic Claude
- **ä¸Šä¸‹æ–‡ç®¡ç†**: æ»‘åŠ¨çª—å£ã€é‡è¦ä¿¡æ¯æå–

### 6.3 ç»„ä»¶é—´é€šä¿¡æ¨¡å¼

#### 6.3.1 åŒæ­¥é€šä¿¡
- **åè®®**: HTTP/HTTPS REST API
- **æ ¼å¼**: JSONè¯·æ±‚/å“åº”
- **è¶…æ—¶**: 30ç§’æ ‡å‡†è¶…æ—¶ï¼Œé•¿ä»»åŠ¡é‡‡ç”¨å¼‚æ­¥æ¨¡å¼
- **é‡è¯•**: æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥

#### 6.3.2 å¼‚æ­¥é€šä¿¡
- **æ¶ˆæ¯é˜Ÿåˆ—**: Celery + Redis
- **ä»»åŠ¡ç±»å‹**: æ–‡æ¡£å¤„ç†ã€å‘é‡åŒ–ã€å›¾è°±æ„å»º
- **å¯é æ€§**: ä»»åŠ¡æŒä¹…åŒ–ã€å¤±è´¥é‡è¯•ã€æ­»ä¿¡é˜Ÿåˆ—

#### 6.3.3 äº‹ä»¶é©±åŠ¨
- **äº‹ä»¶æ€»çº¿**: Redis Pub/Sub
- **äº‹ä»¶ç±»å‹**: æ–‡æ¡£ä¸Šä¼ ã€å¤„ç†å®Œæˆã€ç”¨æˆ·æ“ä½œ
- **å¤„ç†æ¨¡å¼**: å¼‚æ­¥äº‹ä»¶å¤„ç†ã€æœ€ç»ˆä¸€è‡´æ€§

### 6.4 ç»„ä»¶è®¾è®¡å†³ç­–è¯´æ˜

**å¾®æœåŠ¡æ‹†åˆ†åŸåˆ™**
æŒ‰ä¸šåŠ¡é¢†åŸŸæ‹†åˆ†çš„åŸå› ï¼š
- æ¯ä¸ªæœåŠ¡ä¸“æ³¨å•ä¸€ä¸šåŠ¡èŒè´£ï¼Œä¾¿äºç‹¬ç«‹å¼€å‘å’Œéƒ¨ç½²
- ä¸åŒæœåŠ¡å¯é€‰æ‹©æœ€é€‚åˆçš„æŠ€æœ¯æ ˆå’Œæ•°æ®å­˜å‚¨
- æ”¯æŒå›¢é˜Ÿç‹¬ç«‹å·¥ä½œï¼Œå‡å°‘å¼€å‘ä¾èµ–

**å¼‚æ­¥å¤„ç†è®¾è®¡**
é‡‡ç”¨Celeryä»»åŠ¡é˜Ÿåˆ—çš„è€ƒè™‘ï¼š
- æ–‡æ¡£å¤„ç†å’Œå‘é‡åŒ–æ˜¯CPUå¯†é›†å‹ä»»åŠ¡ï¼Œéœ€è¦å¼‚æ­¥å¤„ç†
- æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§ã€é‡è¯•å’Œç›‘æ§
- å¯æ°´å¹³æ‰©å±•workerèŠ‚ç‚¹ï¼Œæé«˜å¤„ç†èƒ½åŠ›

**æ•°æ®å­˜å‚¨ç­–ç•¥**
å¤šæ•°æ®åº“æ¶æ„çš„é€‰æ‹©ï¼š
- PostgreSQLï¼šå…³ç³»å‹æ•°æ®ï¼ŒACIDäº‹åŠ¡ä¿è¯
- Weaviateï¼šå‘é‡æ•°æ®ï¼Œé«˜æ•ˆè¯­ä¹‰æ£€ç´¢
- Neo4jï¼šå›¾æ•°æ®ï¼Œå¤æ‚å…³ç³»æŸ¥è¯¢
- Redisï¼šç¼“å­˜å’Œä¼šè¯ï¼Œé«˜æ€§èƒ½è¯»å†™
- MinIOï¼šå¯¹è±¡å­˜å‚¨ï¼Œå¤§æ–‡ä»¶ç®¡ç†

## 7. é¡¹ç›®ç»“æ„

åŸºäºå¾®æœåŠ¡æ¶æ„å’ŒMonorepoç®¡ç†ç­–ç•¥ï¼ŒKnowledge RAGé¡¹ç›®é‡‡ç”¨ç»Ÿä¸€ä»£ç ä»“åº“ç®¡ç†å¤šä¸ªæœåŠ¡ç»„ä»¶ã€‚é¡¹ç›®ç»“æ„è®¾è®¡éµå¾ªå…³æ³¨ç‚¹åˆ†ç¦»ã€æ¨¡å—åŒ–å¼€å‘å’Œå¯ç»´æŠ¤æ€§åŸåˆ™ï¼Œæ”¯æŒç‹¬ç«‹å¼€å‘ã€æµ‹è¯•å’Œéƒ¨ç½²ã€‚

### 7.1 Monorepoå¸ƒå±€è®¾è®¡

```
knowledge-rag/
â”œâ”€â”€ README.md                          # é¡¹ç›®æ€»ä½“è¯´æ˜
â”œâ”€â”€ docker-compose.yml                 # æœ¬åœ°å¼€å‘ç¯å¢ƒ
â”œâ”€â”€ docker-compose.prod.yml            # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”œâ”€â”€ .env.example                       # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore                         # Gitå¿½ç•¥è§„åˆ™
â”œâ”€â”€ Makefile                           # æ„å»ºå’Œéƒ¨ç½²è„šæœ¬
â”œâ”€â”€ package.json                       # æ ¹çº§ä¾èµ–ç®¡ç†
â”œâ”€â”€ requirements.txt                   # Pythonä¾èµ–æ±‡æ€»
â”œâ”€â”€ pyproject.toml                     # Pythoné¡¹ç›®é…ç½®
â”œâ”€â”€ .pre-commit-config.yaml           # ä»£ç è´¨é‡æ£€æŸ¥
â”œâ”€â”€ .github/                           # GitHub Actions CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                     # æŒç»­é›†æˆ
â”‚       â”œâ”€â”€ cd.yml                     # æŒç»­éƒ¨ç½²
â”‚       â””â”€â”€ security-scan.yml          # å®‰å…¨æ‰«æ
â”œâ”€â”€ docs/                              # é¡¹ç›®æ–‡æ¡£
â”‚   â”œâ”€â”€ api/                           # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ architecture/                  # æ¶æ„è®¾è®¡æ–‡æ¡£
â”‚   â”œâ”€â”€ deployment/                    # éƒ¨ç½²æŒ‡å—
â”‚   â””â”€â”€ development/                   # å¼€å‘æŒ‡å—
â”œâ”€â”€ scripts/                           # æ„å»ºå’Œéƒ¨ç½²è„šæœ¬
â”‚   â”œâ”€â”€ build.sh                       # æ„å»ºè„šæœ¬
â”‚   â”œâ”€â”€ deploy.sh                      # éƒ¨ç½²è„šæœ¬
â”‚   â”œâ”€â”€ test.sh                        # æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ setup-dev.sh                   # å¼€å‘ç¯å¢ƒè®¾ç½®
â”œâ”€â”€ config/                            # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ development/                   # å¼€å‘ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ staging/                       # æµ‹è¯•ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ production/                    # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ k8s/                           # Kubernetesé…ç½®
â”‚       â”œâ”€â”€ namespace.yaml
â”‚       â”œâ”€â”€ configmap.yaml
â”‚       â”œâ”€â”€ secrets.yaml
â”‚       â””â”€â”€ services/
â”œâ”€â”€ services/                          # å¾®æœåŠ¡ç›®å½•
â”‚   â”œâ”€â”€ api-gateway/                   # APIç½‘å…³æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPIåº”ç”¨å…¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/            # ä¸­é—´ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/                # è·¯ç”±å®šä¹‰
â”‚   â”‚   â”‚   â””â”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ tests/                     # å•å…ƒæµ‹è¯•
â”‚   â”‚   â””â”€â”€ k8s/                       # Kubernetesé…ç½®
â”‚   â”œâ”€â”€ user-service/                  # ç”¨æˆ·ç®¡ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models/                # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/               # Pydanticæ¨¡å¼
â”‚   â”‚   â”‚   â”œâ”€â”€ services/              # ä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”‚   â”œâ”€â”€ repositories/          # æ•°æ®è®¿é—®å±‚
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/                  # è®¤è¯æˆæƒ
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ migrations/                # æ•°æ®åº“è¿ç§»
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ k8s/
â”‚   â”œâ”€â”€ document-service/              # æ–‡æ¡£å¤„ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ processors/            # æ–‡æ¡£å¤„ç†å™¨
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ docx_processor.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ txt_processor.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ image_processor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ parsers/               # å†…å®¹è§£æå™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/               # å­˜å‚¨ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ tasks/                 # Celeryä»»åŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ k8s/
â”‚   â”œâ”€â”€ vector-service/                # å‘é‡æ£€ç´¢æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings/            # åµŒå…¥æ¨¡å‹ç®¡ç†
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openai_embedder.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ local_embedder.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ embedding_cache.py
â”‚   â”‚   â”‚   â”œâ”€â”€ search/                # æ£€ç´¢å¼•æ“
â”‚   â”‚   â”‚   â”œâ”€â”€ indexing/              # ç´¢å¼•ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ k8s/
â”‚   â”œâ”€â”€ graph-service/                 # çŸ¥è¯†å›¾è°±æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ extractors/            # å®ä½“å…³ç³»æŠ½å–
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ner_extractor.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ relation_extractor.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ entity_linker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/                 # å›¾è°±æ“ä½œ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ builder.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ query_engine.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ reasoner.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ k8s/
â”‚   â””â”€â”€ query-service/                 # æŸ¥è¯¢å¼•æ“æœåŠ¡
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ main.py
â”‚       â”‚   â”œâ”€â”€ engines/               # æŸ¥è¯¢å¼•æ“
â”‚       â”‚   â”‚   â”œâ”€â”€ graphrag_engine.py
â”‚       â”‚   â”‚   â”œâ”€â”€ retrieval_engine.py
â”‚       â”‚   â”‚   â””â”€â”€ ranking_engine.py
â”‚       â”‚   â”œâ”€â”€ llm/                   # LLMé›†æˆ
â”‚       â”‚   â”‚   â”œâ”€â”€ openai_client.py
â”‚       â”‚   â”‚   â”œâ”€â”€ claude_client.py
â”‚       â”‚   â”‚   â””â”€â”€ prompt_templates.py
â”‚       â”‚   â”œâ”€â”€ context/               # ä¸Šä¸‹æ–‡ç®¡ç†
â”‚       â”‚   â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ tests/
â”‚       â””â”€â”€ k8s/

â”œâ”€â”€ shared/                            # å…±äº«ä»£ç åº“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                        # å…±äº«æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â”œâ”€â”€ workspace.py
â”‚   â”‚   â””â”€â”€ query.py
â”‚   â”œâ”€â”€ schemas/                       # å…±äº«Pydanticæ¨¡å¼
â”‚   â”œâ”€â”€ utils/                         # å…±äº«å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â”œâ”€â”€ validation.py
â”‚   â”‚   â””â”€â”€ constants.py
â”‚   â”œâ”€â”€ exceptions/                    # è‡ªå®šä¹‰å¼‚å¸¸
â”‚   â””â”€â”€ middleware/                    # å…±äº«ä¸­é—´ä»¶
â”œâ”€â”€ infrastructure/                    # åŸºç¡€è®¾æ–½ä»£ç 
â”‚   â”œâ”€â”€ terraform/                     # Terraformé…ç½®
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â””â”€â”€ modules/
â”‚   â”œâ”€â”€ ansible/                       # Ansibleé…ç½®
â”‚   â””â”€â”€ monitoring/                    # ç›‘æ§é…ç½®
â”‚       â”œâ”€â”€ prometheus/
â”‚       â”œâ”€â”€ grafana/
â”‚       â””â”€â”€ alertmanager/
â”œâ”€â”€ data/                              # æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ migrations/                    # æ•°æ®åº“è¿ç§»
â”‚   â”œâ”€â”€ seeds/                         # ç§å­æ•°æ®
â”‚   â””â”€â”€ fixtures/                      # æµ‹è¯•æ•°æ®
â””â”€â”€ tests/                             # é›†æˆæµ‹è¯•
    â”œâ”€â”€ integration/                   # é›†æˆæµ‹è¯•
    â”œâ”€â”€ e2e/                           # ç«¯åˆ°ç«¯æµ‹è¯•
    â”œâ”€â”€ performance/                   # æ€§èƒ½æµ‹è¯•
    â””â”€â”€ fixtures/                      # æµ‹è¯•å¤¹å…·
```

### 7.2 æœåŠ¡ç»„ä»¶ç»“æ„è¯¦è§£

#### 7.2.1 æ ‡å‡†æœåŠ¡ç»“æ„æ¨¡æ¿

æ¯ä¸ªå¾®æœåŠ¡éµå¾ªç»Ÿä¸€çš„ç›®å½•ç»“æ„ï¼š

```python
# æœåŠ¡æ ‡å‡†ç»“æ„
service-name/
â”œâ”€â”€ Dockerfile                         # å®¹å™¨åŒ–é…ç½®
â”œâ”€â”€ requirements.txt                   # Pythonä¾èµ–
â”œâ”€â”€ .env.example                       # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ app/                               # åº”ç”¨ä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                        # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ config.py                      # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ models/                        # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ *.py                       # å…·ä½“æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ schemas/                       # Pydanticæ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ request.py                 # è¯·æ±‚æ¨¡å¼
â”‚   â”‚   â””â”€â”€ response.py                # å“åº”æ¨¡å¼
â”‚   â”œâ”€â”€ services/                      # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ *.py                       # ä¸šåŠ¡æœåŠ¡
â”‚   â”œâ”€â”€ repositories/                  # æ•°æ®è®¿é—®å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ *.py                       # æ•°æ®ä»“åº“
â”‚   â”œâ”€â”€ routes/                        # APIè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ *.py                       # è·¯ç”±å®šä¹‰
â”‚   â”œâ”€â”€ middleware/                    # ä¸­é—´ä»¶
â”‚   â”œâ”€â”€ utils/                         # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ tasks/                         # å¼‚æ­¥ä»»åŠ¡
â”œâ”€â”€ tests/                             # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                    # pytesté…ç½®
â”‚   â”œâ”€â”€ test_*.py                      # æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ fixtures/                      # æµ‹è¯•å¤¹å…·
â”œâ”€â”€ migrations/                        # æ•°æ®åº“è¿ç§»ï¼ˆå¦‚éœ€è¦ï¼‰
â””â”€â”€ k8s/                               # Kubernetesé…ç½®
    â”œâ”€â”€ deployment.yaml
    â”œâ”€â”€ service.yaml
    â”œâ”€â”€ configmap.yaml
    â””â”€â”€ ingress.yaml
```



### 7.3 å…±äº«ä»£ç ç®¡ç†

#### 7.3.1 å…±äº«æ¨¡å‹å®šä¹‰

```python
# shared/models/base.py
"""
åŸºç¡€æ¨¡å‹å®šä¹‰
æä¾›æ‰€æœ‰ä¸šåŠ¡æ¨¡å‹çš„åŸºç±»å’Œé€šç”¨å­—æ®µ
"""
from datetime import datetime
from typing import Optional
from pydantic import BaseModel, Field
from uuid import UUID, uuid4

class BaseEntity(BaseModel):
    """åŸºç¡€å®ä½“æ¨¡å‹"""
    id: UUID = Field(default_factory=uuid4, description="å”¯ä¸€æ ‡è¯†ç¬¦")
    created_at: datetime = Field(default_factory=datetime.utcnow, description="åˆ›å»ºæ—¶é—´")
    updated_at: Optional[datetime] = Field(None, description="æ›´æ–°æ—¶é—´")
    is_active: bool = Field(True, description="æ˜¯å¦æ¿€æ´»")
    
    class Config:
        from_attributes = True
        json_encoders = {
            datetime: lambda v: v.isoformat(),
            UUID: lambda v: str(v)
        }

class TimestampMixin(BaseModel):
    """æ—¶é—´æˆ³æ··å…¥ç±»"""
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: Optional[datetime] = None
    
class WorkspaceScoped(BaseModel):
    """å·¥ä½œç©ºé—´èŒƒå›´æ··å…¥ç±»"""
    workspace_id: UUID = Field(..., description="å·¥ä½œç©ºé—´ID")
```

#### 7.3.2 å…±äº«å·¥å…·å‡½æ•°

```python
# shared/utils/logging.py
"""
ç»Ÿä¸€æ—¥å¿—é…ç½®
ä¸ºæ‰€æœ‰æœåŠ¡æä¾›æ ‡å‡†åŒ–çš„æ—¥å¿—è®°å½•åŠŸèƒ½
"""
import logging
import sys
from typing import Optional
from pythonjsonlogger import jsonlogger

def setup_logging(
    service_name: str,
    log_level: str = "INFO",
    json_format: bool = True
) -> logging.Logger:
    """è®¾ç½®æœåŠ¡æ—¥å¿—é…ç½®"""
    logger = logging.getLogger(service_name)
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    logger.handlers.clear()
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    handler = logging.StreamHandler(sys.stdout)
    
    if json_format:
        # JSONæ ¼å¼æ—¥å¿—
        formatter = jsonlogger.JsonFormatter(
            '%(asctime)s %(name)s %(levelname)s %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
    else:
        # æ ‡å‡†æ ¼å¼æ—¥å¿—
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
    
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    return logger
```

### 7.4 é…ç½®ç®¡ç†ç­–ç•¥

#### 7.4.1 ç¯å¢ƒé…ç½®åˆ†ç¦»

```python
# shared/config/base.py
"""
åŸºç¡€é…ç½®ç±»
å®šä¹‰æ‰€æœ‰æœåŠ¡çš„é€šç”¨é…ç½®é¡¹
"""
from typing import Optional, List
from pydantic import BaseSettings, Field

class BaseConfig(BaseSettings):
    """åŸºç¡€é…ç½®ç±»"""
    # åº”ç”¨åŸºç¡€é…ç½®
    app_name: str = Field(..., description="åº”ç”¨åç§°")
    app_version: str = Field("1.0.0", description="åº”ç”¨ç‰ˆæœ¬")
    debug: bool = Field(False, description="è°ƒè¯•æ¨¡å¼")
    
    # æ•°æ®åº“é…ç½®
    database_url: str = Field(..., description="æ•°æ®åº“è¿æ¥URL")
    database_pool_size: int = Field(10, description="æ•°æ®åº“è¿æ¥æ± å¤§å°")
    
    # Redisé…ç½®
    redis_url: str = Field(..., description="Redisè¿æ¥URL")
    redis_max_connections: int = Field(20, description="Redisæœ€å¤§è¿æ¥æ•°")
    
    # æ—¥å¿—é…ç½®
    log_level: str = Field("INFO", description="æ—¥å¿—çº§åˆ«")
    log_format: str = Field("json", description="æ—¥å¿—æ ¼å¼")
    
    # å®‰å…¨é…ç½®
    secret_key: str = Field(..., description="åº”ç”¨å¯†é’¥")
    jwt_algorithm: str = Field("HS256", description="JWTç®—æ³•")
    jwt_expire_minutes: int = Field(30, description="JWTè¿‡æœŸæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
    
    # CORSé…ç½®
    cors_origins: List[str] = Field(["*"], description="CORSå…è®¸çš„æº")
    
    class Config:
        env_file = ".env"
        case_sensitive = False

class DatabaseConfig(BaseSettings):
    """æ•°æ®åº“ä¸“ç”¨é…ç½®"""
    postgres_host: str = Field(..., description="PostgreSQLä¸»æœº")
    postgres_port: int = Field(5432, description="PostgreSQLç«¯å£")
    postgres_db: str = Field(..., description="æ•°æ®åº“å")
    postgres_user: str = Field(..., description="æ•°æ®åº“ç”¨æˆ·")
    postgres_password: str = Field(..., description="æ•°æ®åº“å¯†ç ")
    
    @property
    def database_url(self) -> str:
        return f"postgresql://{self.postgres_user}:{self.postgres_password}@{self.postgres_host}:{self.postgres_port}/{self.postgres_db}"
```

### 7.5 æ„å»ºå’Œéƒ¨ç½²é…ç½®

#### 7.5.1 Dockeré…ç½®æ¨¡æ¿

```dockerfile
# services/*/Dockerfileæ¨¡æ¿
# å¤šé˜¶æ®µæ„å»ºï¼Œä¼˜åŒ–é•œåƒå¤§å°
FROM python:3.11-slim as builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY ../shared ./shared

# å®‰è£…Pythonä¾èµ–
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-dev

# ç”Ÿäº§é˜¶æ®µ
FROM python:3.11-slim

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶ä¾èµ–
COPY --from=builder /root/.local /home/appuser/.local
COPY --from=builder /app/shared ./shared

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY app ./app
COPY *.py ./

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PATH=/home/appuser/.local/bin:$PATH
ENV PYTHONPATH=/app

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 7.5.2 Kubernetesé…ç½®æ¨¡æ¿

```yaml
# services/*/k8s/deployment.yamlæ¨¡æ¿
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ service-name }}
  namespace: knowledge-rag
  labels:
    app: {{ service-name }}
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: {{ service-name }}
  template:
    metadata:
      labels:
        app: {{ service-name }}
        version: v1
    spec:
      containers:
      - name: {{ service-name }}
        image: knowledge-rag/{{ service-name }}:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: url
        - name: REDIS_URL
          valueFrom:
            configMapKeyRef:
              name: redis-config
              key: url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### 7.6 é¡¹ç›®ç»“æ„è®¾è®¡å†³ç­–

**Monorepoé€‰æ‹©ç†ç”±**
é‡‡ç”¨Monorepoç®¡ç†çš„ä¼˜åŠ¿ï¼š
- ç»Ÿä¸€çš„ä»£ç ç‰ˆæœ¬ç®¡ç†å’Œä¾èµ–ç®¡ç†
- ç®€åŒ–è·¨æœåŠ¡çš„ä»£ç å…±äº«å’Œé‡æ„
- ç»Ÿä¸€çš„CI/CDæµæ°´çº¿å’Œæ„å»ºå·¥å…·
- ä¾¿äºä»£ç å®¡æŸ¥å’Œè´¨é‡æ§åˆ¶

**æœåŠ¡æ‹†åˆ†ç­–ç•¥**
æŒ‰ä¸šåŠ¡é¢†åŸŸæ‹†åˆ†æœåŠ¡çš„è€ƒè™‘ï¼š
- æ¯ä¸ªæœåŠ¡ä¸“æ³¨å•ä¸€ä¸šåŠ¡èŒè´£
- æ”¯æŒç‹¬ç«‹å¼€å‘ã€æµ‹è¯•å’Œéƒ¨ç½²
- ä¾¿äºå›¢é˜Ÿåˆ†å·¥å’Œå¹¶è¡Œå¼€å‘
- é™ä½æœåŠ¡é—´çš„è€¦åˆåº¦

**å…±äº«ä»£ç ç®¡ç†**
å»ºç«‹sharedç›®å½•çš„åŸå› ï¼š
- é¿å…ä»£ç é‡å¤ï¼Œæé«˜å¼€å‘æ•ˆç‡
- ç»Ÿä¸€æ•°æ®æ¨¡å‹å’Œæ¥å£å®šä¹‰
- ç®€åŒ–è·¨æœåŠ¡çš„ç±»å‹æ£€æŸ¥
- ä¾¿äºç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

**é…ç½®ç®¡ç†ç­–ç•¥**
ç¯å¢ƒé…ç½®åˆ†ç¦»çš„è®¾è®¡ï¼š
- æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½²ï¼ˆå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ï¼‰
- æ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡ç®¡ç†
- é…ç½®çƒ­æ›´æ–°å’Œç‰ˆæœ¬æ§åˆ¶
- ç¬¦åˆ12-Factoråº”ç”¨åŸåˆ™

---

## 7. éƒ¨ç½²æ¶æ„

æœ¬èŠ‚å®šä¹‰Knowledge RAGç³»ç»Ÿçš„å®Œæ•´éƒ¨ç½²æ¶æ„ï¼ŒåŒ…æ‹¬Kubernetesé›†ç¾¤è®¾è®¡ã€æœåŠ¡ç¼–æ’ç­–ç•¥ã€CI/CDæµæ°´çº¿å’Œè¿ç»´ç›‘æ§ä½“ç³»ã€‚

### 7.1 Kubernetesé›†ç¾¤æ¶æ„

#### é›†ç¾¤æ‹“æ‰‘è®¾è®¡

```mermaid
graph TB
    subgraph "Production Cluster"
        subgraph "Control Plane"
            Master1["Master Node 1"]
            Master2["Master Node 2"]
            Master3["Master Node 3"]
        end
        
        subgraph "Worker Nodes"
            Worker1["Worker Node 1<br/>App Services"]
            Worker2["Worker Node 2<br/>App Services"]
            Worker3["Worker Node 3<br/>Data Services"]
            Worker4["Worker Node 4<br/>Data Services"]
        end
        
        subgraph "Storage"
            PV1["Persistent Volume<br/>PostgreSQL"]
            PV2["Persistent Volume<br/>Neo4j"]
            PV3["Persistent Volume<br/>Weaviate"]
            PV4["Persistent Volume<br/>Redis"]
        end
    end
    
    subgraph "External Services"
        LB["Load Balancer"]
        DNS["DNS Service"]
        Registry["Container Registry"]
        Monitoring["Monitoring Stack"]
    end
    
    LB --> Master1
    LB --> Master2
    LB --> Master3
    
    Worker1 --> PV1
    Worker2 --> PV2
    Worker3 --> PV3
    Worker4 --> PV4
```

#### èŠ‚ç‚¹è§„æ ¼é…ç½®

**MasterèŠ‚ç‚¹ï¼ˆæ§åˆ¶å¹³é¢ï¼‰**
- **è§„æ ¼**ï¼š4 vCPU, 8GB RAM, 100GB SSD
- **æ•°é‡**ï¼š3ä¸ªï¼ˆé«˜å¯ç”¨ï¼‰
- **èŒè´£**ï¼šAPI Serverã€etcdã€Controller Managerã€Scheduler
- **ç½‘ç»œ**ï¼šå†…ç½‘é€šä¿¡ï¼Œå¤–éƒ¨APIè®¿é—®

**WorkerèŠ‚ç‚¹ï¼ˆåº”ç”¨æœåŠ¡ï¼‰**
- **è§„æ ¼**ï¼š8 vCPU, 16GB RAM, 200GB SSD
- **æ•°é‡**ï¼š2-6ä¸ªï¼ˆè‡ªåŠ¨æ‰©ç¼©å®¹ï¼‰
- **èŒè´£**ï¼šè¿è¡Œåº”ç”¨æœåŠ¡Pod
- **æ ‡ç­¾**ï¼š`node-type=app-services`

**WorkerèŠ‚ç‚¹ï¼ˆæ•°æ®æœåŠ¡ï¼‰**
- **è§„æ ¼**ï¼š16 vCPU, 32GB RAM, 1TB SSD
- **æ•°é‡**ï¼š2-4ä¸ªï¼ˆæ ¹æ®æ•°æ®é‡æ‰©å±•ï¼‰
- **èŒè´£**ï¼šè¿è¡Œæ•°æ®åº“å’Œå­˜å‚¨æœåŠ¡
- **æ ‡ç­¾**ï¼š`node-type=data-services`

### 7.2 æœåŠ¡ç¼–æ’ç­–ç•¥

#### Namespaceè®¾è®¡

```yaml
# å‘½åç©ºé—´åˆ’åˆ†
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-prod
  labels:
    environment: production
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-staging
  labels:
    environment: staging
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-monitoring
  labels:
    environment: shared
    project: knowledge-rag
```

#### æœåŠ¡éƒ¨ç½²é…ç½®

**APIç½‘å…³éƒ¨ç½²**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: knowledge-rag-prod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: kong
        image: kong:3.4-alpine
        ports:
        - containerPort: 8000
        - containerPort: 8001
        env:
        - name: KONG_DATABASE
          value: "postgres"
        - name: KONG_PG_HOST
          value: "postgresql-service"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      nodeSelector:
        node-type: app-services
```

**å¾®æœåŠ¡éƒ¨ç½²æ¨¡æ¿**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.serviceName }}
  namespace: {{ .Values.namespace }}
spec:
  replicas: {{ .Values.replicas }}
  selector:
    matchLabels:
      app: {{ .Values.serviceName }}
  template:
    metadata:
      labels:
        app: {{ .Values.serviceName }}
        version: {{ .Values.version }}
    spec:
      containers:
      - name: {{ .Values.serviceName }}
        image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
        ports:
        - containerPort: {{ .Values.service.port }}
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: url
        - name: REDIS_URL
          valueFrom:
            configMapKeyRef:
              name: redis-config
              key: url
        livenessProbe:
          httpGet:
            path: /health
            port: {{ .Values.service.port }}
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: {{ .Values.service.port }}
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: {{ .Values.resources.requests.memory }}
            cpu: {{ .Values.resources.requests.cpu }}
          limits:
            memory: {{ .Values.resources.limits.memory }}
            cpu: {{ .Values.resources.limits.cpu }}
```

#### æ•°æ®æœåŠ¡éƒ¨ç½²

**PostgreSQLé›†ç¾¤**
```yaml
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: postgresql-cluster
  namespace: knowledge-rag-prod
spec:
  instances: 3
  primaryUpdateStrategy: unsupervised
  
  postgresql:
    parameters:
      max_connections: "200"
      shared_buffers: "256MB"
      effective_cache_size: "1GB"
      work_mem: "4MB"
  
  bootstrap:
    initdb:
      database: knowledge_rag
      owner: app_user
      secret:
        name: postgresql-credentials
  
  storage:
    size: 100Gi
    storageClass: fast-ssd
  
  nodeSelector:
    node-type: data-services
  
  monitoring:
    enabled: true
```

**Weaviateå‘é‡æ•°æ®åº“**
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: weaviate
  namespace: knowledge-rag-prod
spec:
  serviceName: weaviate
  replicas: 2
  selector:
    matchLabels:
      app: weaviate
  template:
    metadata:
      labels:
        app: weaviate
    spec:
      containers:
      - name: weaviate
        image: semitechnologies/weaviate:1.22.4
        ports:
        - containerPort: 8080
        env:
        - name: QUERY_DEFAULTS_LIMIT
          value: "25"
        - name: AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED
          value: "false"
        - name: PERSISTENCE_DATA_PATH
          value: "/var/lib/weaviate"
        - name: CLUSTER_HOSTNAME
          value: "weaviate"
        volumeMounts:
        - name: weaviate-data
          mountPath: /var/lib/weaviate
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      nodeSelector:
        node-type: data-services
  volumeClaimTemplates:
  - metadata:
      name: weaviate-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 200Gi
```

### 7.3 CI/CDæµæ°´çº¿

#### GitLab CI/CDé…ç½®

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - security
  - deploy-staging
  - integration-test
  - deploy-production

variables:
  DOCKER_REGISTRY: registry.gitlab.com/knowledge-rag
  KUBERNETES_NAMESPACE_STAGING: knowledge-rag-staging
  KUBERNETES_NAMESPACE_PROD: knowledge-rag-prod

# ä»£ç è´¨é‡æ£€æŸ¥
code-quality:
  stage: test
  image: python:3.11-slim
  script:
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - uv sync --prerelease=allow
    - black --check .
    - isort --check-only .
    - flake8 .
    - mypy .
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"

# å•å…ƒæµ‹è¯•
unit-tests:
  stage: test
  image: python:3.11-slim
  services:
    - postgres:15
    - redis:7
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: test_user
    POSTGRES_PASSWORD: test_pass
    DATABASE_URL: postgresql://test_user:test_pass@postgres:5432/test_db
    REDIS_URL: redis://redis:6379/0
  script:
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - uv sync --prerelease=allow
    - poetry run pytest --cov=src --cov-report=xml
  coverage: '/TOTAL.+ ([0-9]{1,3}%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

# æ„å»ºDockeré•œåƒ
build-images:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - |
      for service in api-gateway user-service document-service vector-service knowledge-service query-service; do
        docker build -t $DOCKER_REGISTRY/$service:$CI_COMMIT_SHA -f services/$service/Dockerfile .
        docker push $DOCKER_REGISTRY/$service:$CI_COMMIT_SHA
        docker tag $DOCKER_REGISTRY/$service:$CI_COMMIT_SHA $DOCKER_REGISTRY/$service:latest
        docker push $DOCKER_REGISTRY/$service:latest
      done
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

# å®‰å…¨æ‰«æ
security-scan:
  stage: security
  image: aquasec/trivy:latest
  script:
    - |
      for service in api-gateway user-service document-service vector-service knowledge-service query-service; do
        trivy image --exit-code 1 --severity HIGH,CRITICAL $DOCKER_REGISTRY/$service:$CI_COMMIT_SHA
      done
  allow_failure: true
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "develop"

# éƒ¨ç½²åˆ°Stagingç¯å¢ƒ
deploy-staging:
  stage: deploy-staging
  image: bitnami/kubectl:latest
  environment:
    name: staging
    url: https://staging.knowledge-rag.com
  script:
    - kubectl config use-context $KUBE_CONTEXT_STAGING
    - helm upgrade --install knowledge-rag-staging ./helm/knowledge-rag \
        --namespace $KUBERNETES_NAMESPACE_STAGING \
        --set image.tag=$CI_COMMIT_SHA \
        --set environment=staging \
        --values ./helm/values-staging.yaml
    - kubectl rollout status deployment/api-gateway -n $KUBERNETES_NAMESPACE_STAGING
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"

# é›†æˆæµ‹è¯•
integration-tests:
  stage: integration-test
  image: postman/newman:latest
  script:
    - newman run tests/postman/integration-tests.json \
        --environment tests/postman/staging-environment.json \
        --reporters cli,junit \
        --reporter-junit-export integration-test-results.xml
  artifacts:
    reports:
      junit: integration-test-results.xml
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"

# éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
deploy-production:
  stage: deploy-production
  image: bitnami/kubectl:latest
  environment:
    name: production
    url: https://knowledge-rag.com
  script:
    - kubectl config use-context $KUBE_CONTEXT_PROD
    - helm upgrade --install knowledge-rag-prod ./helm/knowledge-rag \
        --namespace $KUBERNETES_NAMESPACE_PROD \
        --set image.tag=$CI_COMMIT_SHA \
        --set environment=production \
        --values ./helm/values-production.yaml
    - kubectl rollout status deployment/api-gateway -n $KUBERNETES_NAMESPACE_PROD
  when: manual
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
```

#### Helm Charté…ç½®

**Chart.yaml**
```yaml
apiVersion: v2
name: knowledge-rag
description: GraphRAG-based Knowledge Management System
type: application
version: 0.1.0
appVersion: "1.0.0"

dependencies:
  - name: postgresql
    version: 12.12.10
    repository: https://charts.bitnami.com/bitnami
    condition: postgresql.enabled
  - name: redis
    version: 18.1.5
    repository: https://charts.bitnami.com/bitnami
    condition: redis.enabled
  - name: prometheus
    version: 25.1.0
    repository: https://prometheus-community.github.io/helm-charts
    condition: monitoring.prometheus.enabled
```

**values.yaml**
```yaml
# å…¨å±€é…ç½®
global:
  imageRegistry: registry.gitlab.com/knowledge-rag
  storageClass: fast-ssd
  
# åº”ç”¨é…ç½®
image:
  tag: latest
  pullPolicy: Always

environment: production

# æœåŠ¡é…ç½®
services:
  apiGateway:
    enabled: true
    replicas: 3
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 500m
  
  userService:
    enabled: true
    replicas: 2
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 200m
  
  documentService:
    enabled: true
    replicas: 3
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m
  
  vectorService:
    enabled: true
    replicas: 2
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m
  
  knowledgeService:
    enabled: true
    replicas: 2
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m
  
  queryService:
    enabled: true
    replicas: 3
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m

# æ•°æ®åº“é…ç½®
postgresql:
  enabled: true
  auth:
    postgresPassword: "secure-postgres-password"
    database: knowledge_rag
  primary:
    persistence:
      enabled: true
      size: 100Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m

redis:
  enabled: true
  auth:
    enabled: true
    password: "secure-redis-password"
  master:
    persistence:
      enabled: true
      size: 20Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m

# å¤–éƒ¨æ•°æ®åº“
weaviate:
  enabled: true
  replicas: 2
  persistence:
    size: 200Gi
    storageClass: fast-ssd
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m

neo4j:
  enabled: true
  core:
    numberOfServers: 3
  readReplica:
    numberOfServers: 2
  persistence:
    size: 100Gi
    storageClass: fast-ssd
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 4Gi
      cpu: 2000m

# ç›‘æ§é…ç½®
monitoring:
  prometheus:
    enabled: true
  grafana:
    enabled: true
  jaeger:
    enabled: true

# ç½‘ç»œé…ç½®
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
  hosts:
    - host: api.knowledge-rag.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: knowledge-rag-tls
      hosts:
        - api.knowledge-rag.com

# è‡ªåŠ¨æ‰©ç¼©å®¹
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
```

### 7.4 ç›‘æ§å’Œå¯è§‚æµ‹æ€§

#### Prometheusç›‘æ§é…ç½®

```yaml
# prometheus-config.yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "knowledge-rag-rules.yml"

scrape_configs:
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

  - job_name: 'knowledge-rag-services'
    kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
            - knowledge-rag-prod
            - knowledge-rag-staging
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name

  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgresql-service:5432']
    metrics_path: /metrics
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-service:6379']
    metrics_path: /metrics
    scrape_interval: 30s
```

#### å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# knowledge-rag-rules.yml
groups:
  - name: knowledge-rag-alerts
    rules:
      # æœåŠ¡å¯ç”¨æ€§å‘Šè­¦
      - alert: ServiceDown
        expr: up{job=~"knowledge-rag-.*"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "Service {{ $labels.job }} has been down for more than 1 minute."
      
      # é«˜é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: |
          (
            rate(http_requests_total{status=~"5.."}[5m]) /
            rate(http_requests_total[5m])
          ) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"
      
      # é«˜å»¶è¿Ÿå‘Šè­¦
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.job }}"
      
      # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighMemoryUsage
        expr: |
          (
            container_memory_working_set_bytes{pod=~"knowledge-rag-.*"} /
            container_spec_memory_limit_bytes{pod=~"knowledge-rag-.*"}
          ) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value | humanizePercentage }} for {{ $labels.pod }}"
      
      # CPUä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighCPUUsage
        expr: |
          (
            rate(container_cpu_usage_seconds_total{pod=~"knowledge-rag-.*"}[5m]) /
            container_spec_cpu_quota{pod=~"knowledge-rag-.*"} * container_spec_cpu_period{pod=~"knowledge-rag-.*"}
          ) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value | humanizePercentage }} for {{ $labels.pod }}"
      
      # æ•°æ®åº“è¿æ¥å‘Šè­¦
      - alert: DatabaseConnectionHigh
        expr: pg_stat_activity_count > 150
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "PostgreSQL has {{ $value }} active connections"
      
      # å‘é‡æ•°æ®åº“å‘Šè­¦
      - alert: WeaviateDown
        expr: up{job="weaviate"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Weaviate is down"
          description: "Weaviate vector database has been down for more than 1 minute"
```

#### Grafanaä»ªè¡¨æ¿

**ç³»ç»Ÿæ¦‚è§ˆä»ªè¡¨æ¿**
```json
{
  "dashboard": {
    "title": "Knowledge RAG System Overview",
    "panels": [
      {
        "title": "Service Status",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=~\"knowledge-rag-.*\"}",
            "legendFormat": "{{ job }}"
          }
        ]
      },
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{ job }} - {{ method }}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "{{ job }}"
          }
        ]
      },
      {
        "title": "Resource Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{pod=~\"knowledge-rag-.*\"}[5m])",
            "legendFormat": "CPU - {{ pod }}"
          },
          {
            "expr": "container_memory_working_set_bytes{pod=~\"knowledge-rag-.*\"} / 1024 / 1024 / 1024",
            "legendFormat": "Memory (GB) - {{ pod }}"
          }
        ]
      }
    ]
  }
}
```

### 7.5 å®‰å…¨å’Œåˆè§„

#### ç½‘ç»œå®‰å…¨ç­–ç•¥

```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: knowledge-rag-network-policy
  namespace: knowledge-rag-prod
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: knowledge-rag-prod
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: knowledge-rag-prod
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
  - to: []
    ports:
    - protocol: TCP
      port: 443
```

#### Podå®‰å…¨ç­–ç•¥

```yaml
# pod-security-policy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: knowledge-rag-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
```

### 7.6 ç¾éš¾æ¢å¤

#### å¤‡ä»½ç­–ç•¥

**æ•°æ®åº“å¤‡ä»½**
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgresql-backup
  namespace: knowledge-rag-prod
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: postgres-backup
            image: postgres:15
            command:
            - /bin/bash
            - -c
            - |
              BACKUP_FILE="/backup/postgresql-$(date +%Y%m%d-%H%M%S).sql"
              pg_dump $DATABASE_URL > $BACKUP_FILE
              aws s3 cp $BACKUP_FILE s3://knowledge-rag-backups/postgresql/
              find /backup -name "postgresql-*.sql" -mtime +7 -delete
            env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: database-secret
                  key: url
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

**å‘é‡æ•°æ®å¤‡ä»½**
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: weaviate-backup
  namespace: knowledge-rag-prod
spec:
  schedule: "0 3 * * *"  # æ¯å¤©å‡Œæ™¨3ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: weaviate-backup
            image: semitechnologies/weaviate:1.22.4
            command:
            - /bin/bash
            - -c
            - |
              BACKUP_FILE="/backup/weaviate-$(date +%Y%m%d-%H%M%S).tar.gz"
              tar -czf $BACKUP_FILE /var/lib/weaviate
              aws s3 cp $BACKUP_FILE s3://knowledge-rag-backups/weaviate/
              find /backup -name "weaviate-*.tar.gz" -mtime +7 -delete
            volumeMounts:
            - name: weaviate-data
              mountPath: /var/lib/weaviate
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: weaviate-data
            persistentVolumeClaim:
              claimName: weaviate-pvc
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

#### æ¢å¤æµç¨‹

**æ•°æ®æ¢å¤è„šæœ¬**
```bash
#!/bin/bash
# restore-database.sh

set -e

BACKUP_DATE=${1:-$(date +%Y%m%d)}
NAMESPACE=${2:-knowledge-rag-prod}

echo "Starting database restore for date: $BACKUP_DATE"

# ä¸‹è½½å¤‡ä»½æ–‡ä»¶
aws s3 cp s3://knowledge-rag-backups/postgresql/postgresql-${BACKUP_DATE}*.sql /tmp/restore.sql

# åœæ­¢åº”ç”¨æœåŠ¡
kubectl scale deployment --replicas=0 -l app.kubernetes.io/component=application -n $NAMESPACE

# ç­‰å¾…Podç»ˆæ­¢
kubectl wait --for=delete pod -l app.kubernetes.io/component=application -n $NAMESPACE --timeout=300s

# æ¢å¤æ•°æ®åº“
kubectl exec -n $NAMESPACE postgresql-cluster-1 -- psql -U postgres -d knowledge_rag -f /tmp/restore.sql

# é‡å¯åº”ç”¨æœåŠ¡
kubectl scale deployment --replicas=2 -l app.kubernetes.io/component=application -n $NAMESPACE

# ç­‰å¾…æœåŠ¡å°±ç»ª
kubectl wait --for=condition=available deployment -l app.kubernetes.io/component=application -n $NAMESPACE --timeout=600s

echo "Database restore completed successfully"
```

### 7.7 éƒ¨ç½²æ¶æ„æ€»ç»“

#### æ¶æ„ä¼˜åŠ¿

1. **é«˜å¯ç”¨æ€§**
   - å¤šèŠ‚ç‚¹Kubernetesé›†ç¾¤ç¡®ä¿æœåŠ¡è¿ç»­æ€§
   - æ•°æ®åº“ä¸»ä»å¤åˆ¶å’Œè‡ªåŠ¨æ•…éšœè½¬ç§»
   - å¤šå¯ç”¨åŒºéƒ¨ç½²é™ä½å•ç‚¹æ•…éšœé£é™©

2. **å¯æ‰©å±•æ€§**
   - æ°´å¹³Podè‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆHPAï¼‰
   - å‚ç›´Podè‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆVPAï¼‰
   - é›†ç¾¤èŠ‚ç‚¹è‡ªåŠ¨æ‰©ç¼©å®¹

3. **å®‰å…¨æ€§**
   - ç½‘ç»œç­–ç•¥éš”ç¦»æœåŠ¡é€šä¿¡
   - Podå®‰å…¨ç­–ç•¥é™åˆ¶å®¹å™¨æƒé™
   - å¯†é’¥ç®¡ç†å’Œè¯ä¹¦è‡ªåŠ¨è½®æ¢

4. **å¯è§‚æµ‹æ€§**
   - å…¨æ–¹ä½ç›‘æ§æŒ‡æ ‡æ”¶é›†
   - åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª
   - é›†ä¸­åŒ–æ—¥å¿—ç®¡ç†å’Œåˆ†æ

5. **è¿ç»´æ•ˆç‡**
   - GitOpså·¥ä½œæµè‡ªåŠ¨åŒ–éƒ¨ç½²
   - åŸºç¡€è®¾æ–½å³ä»£ç ç®¡ç†
   - è‡ªåŠ¨åŒ–å¤‡ä»½å’Œæ¢å¤æµç¨‹

#### éƒ¨ç½²æ¸…å•

**åŸºç¡€è®¾æ–½å‡†å¤‡**
- [ ] Kubernetesé›†ç¾¤æ­å»ºï¼ˆ3 Master + 4 Workerï¼‰
- [ ] å­˜å‚¨ç±»é…ç½®ï¼ˆfast-ssdï¼‰
- [ ] ç½‘ç»œæ’ä»¶å®‰è£…ï¼ˆCalico/Flannelï¼‰
- [ ] Ingressæ§åˆ¶å™¨éƒ¨ç½²ï¼ˆNginxï¼‰
- [ ] è¯ä¹¦ç®¡ç†å™¨å®‰è£…ï¼ˆcert-managerï¼‰

**ç›‘æ§ä½“ç³»éƒ¨ç½²**
- [ ] Prometheus Operatorå®‰è£…
- [ ] Grafanaä»ªè¡¨æ¿é…ç½®
- [ ] Jaegeré“¾è·¯è¿½è¸ªéƒ¨ç½²
- [ ] ELKæ—¥å¿—æ ˆå®‰è£…
- [ ] å‘Šè­¦è§„åˆ™é…ç½®

**åº”ç”¨éƒ¨ç½²**
- [ ] Helm Chartå¼€å‘å’Œæµ‹è¯•
- [ ] CI/CDæµæ°´çº¿é…ç½®
- [ ] æ•°æ®åº“é›†ç¾¤éƒ¨ç½²
- [ ] å¾®æœåŠ¡åº”ç”¨éƒ¨ç½²
- [ ] APIç½‘å…³é…ç½®

**å®‰å…¨åŠ å›º**
- [ ] ç½‘ç»œç­–ç•¥é…ç½®
- [ ] Podå®‰å…¨ç­–ç•¥å®æ–½
- [ ] RBACæƒé™é…ç½®
- [ ] å¯†é’¥ç®¡ç†é…ç½®
- [ ] å®‰å…¨æ‰«æé›†æˆ

**å¤‡ä»½æ¢å¤**
- [ ] è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡é…ç½®
- [ ] å¤‡ä»½å­˜å‚¨é…ç½®
- [ ] æ¢å¤æµç¨‹æµ‹è¯•
- [ ] ç¾éš¾æ¢å¤æ¼”ç»ƒ

---

---

## 8. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

æœ¬èŠ‚è¯¦ç»†é˜è¿°Knowledge RAGç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæ€§èƒ½è°ƒä¼˜ã€æ‰©å±•æ–¹æ¡ˆã€ç¼“å­˜ç­–ç•¥å’Œèµ„æºä¼˜åŒ–ç­‰å…³é”®æŠ€æœ¯ã€‚

### 8.1 ç³»ç»Ÿæ€§èƒ½åˆ†æ

#### æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

**è®¡ç®—å¯†é›†å‹ç“¶é¢ˆ**
- **å‘é‡åŒ–å¤„ç†**ï¼šæ–‡æ¡£å‘é‡åŒ–å’Œç›¸ä¼¼åº¦è®¡ç®—
- **LLMæ¨ç†**ï¼šå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†å»¶è¿Ÿ
- **å›¾æ•°æ®åº“æŸ¥è¯¢**ï¼šå¤æ‚çš„å›¾éå†å’Œæ¨¡å¼åŒ¹é…
- **å®ä½“æŠ½å–**ï¼šNLPæ¨¡å‹çš„å®ä½“è¯†åˆ«å’Œå…³ç³»æŠ½å–

**I/Oå¯†é›†å‹ç“¶é¢ˆ**
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šPostgreSQLçš„å¤æ‚å…³è”æŸ¥è¯¢
- **å‘é‡æ£€ç´¢**ï¼šWeaviateçš„å¤§è§„æ¨¡å‘é‡æœç´¢
- **æ–‡ä»¶å­˜å‚¨**ï¼šå¤§æ–‡æ¡£çš„ä¸Šä¼ å’Œä¸‹è½½
- **ç½‘ç»œé€šä¿¡**ï¼šå¾®æœåŠ¡é—´çš„APIè°ƒç”¨

**å†…å­˜ç“¶é¢ˆ**
- **å‘é‡ç¼“å­˜**ï¼šå¤§é‡å‘é‡æ•°æ®çš„å†…å­˜å ç”¨
- **æ¨¡å‹åŠ è½½**ï¼šLLMå’ŒNLPæ¨¡å‹çš„å†…å­˜æ¶ˆè€—
- **å›¾æ•°æ®ç¼“å­˜**ï¼šçŸ¥è¯†å›¾è°±çš„å†…å­˜å­˜å‚¨
- **ä¼šè¯çŠ¶æ€**ï¼šç”¨æˆ·ä¼šè¯å’Œä¸Šä¸‹æ–‡çš„å†…å­˜ç®¡ç†

#### æ€§èƒ½ç›‘æ§æŒ‡æ ‡

```yaml
# å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰
performance_metrics:
  response_time:
    api_gateway: "< 100ms (P95)"
    document_upload: "< 5s (P95)"
    vector_search: "< 500ms (P95)"
    qa_generation: "< 3s (P95)"
    graph_query: "< 1s (P95)"
  
  throughput:
    concurrent_users: "> 1000"
    documents_per_hour: "> 10000"
    queries_per_second: "> 100"
    vector_operations_per_second: "> 1000"
  
  resource_utilization:
    cpu_usage: "< 70% (average)"
    memory_usage: "< 80% (average)"
    disk_io: "< 80% (peak)"
    network_bandwidth: "< 60% (peak)"
  
  availability:
    system_uptime: "> 99.9%"
    service_availability: "> 99.95%"
    data_consistency: "100%"
```

### 8.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

#### å¤šå±‚ç¼“å­˜æ¶æ„

```mermaid
graph TB
    subgraph "ç¼“å­˜å±‚æ¬¡ç»“æ„"
        L1["L1: åº”ç”¨å†…å­˜ç¼“å­˜<br/>Redis Cluster"]
        L2["L2: åˆ†å¸ƒå¼ç¼“å­˜<br/>Redis Sentinel"]
        L3["L3: æ•°æ®åº“ç¼“å­˜<br/>PostgreSQL Buffer"]
        L4["L4: å‘é‡ç¼“å­˜<br/>Weaviate Memory"]
    end
    
    subgraph "ç¼“å­˜ç­–ç•¥"
        LRU["LRUæ·˜æ±°ç­–ç•¥"]
        TTL["TTLè¿‡æœŸç­–ç•¥"]
        WriteThrough["å†™é€ç­–ç•¥"]
        WriteBack["å†™å›ç­–ç•¥"]
    end
    
    L1 --> LRU
    L2 --> TTL
    L3 --> WriteThrough
    L4 --> WriteBack
```

#### Redisç¼“å­˜é…ç½®

**Redisé›†ç¾¤é…ç½®**
```yaml
# redis-cluster.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: knowledge-rag-prod
spec:
  serviceName: redis-cluster
  replicas: 6
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        - containerPort: 16379
        command:
        - redis-server
        args:
        - /etc/redis/redis.conf
        - --cluster-enabled yes
        - --cluster-config-file nodes.conf
        - --cluster-node-timeout 5000
        - --appendonly yes
        - --maxmemory 2gb
        - --maxmemory-policy allkeys-lru
        - --save 900 1
        - --save 300 10
        - --save 60 10000
        volumeMounts:
        - name: redis-data
          mountPath: /data
        - name: redis-config
          mountPath: /etc/redis
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "1000m"
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 50Gi
```

**ç¼“å­˜ç­–ç•¥å®ç°**
```python
# cache_manager.py
"""
Knowledge RAGç³»ç»Ÿç¼“å­˜ç®¡ç†å™¨
æä¾›å¤šå±‚ç¼“å­˜ç­–ç•¥å’Œæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
"""

import redis
import json
import hashlib
from typing import Any, Optional, Dict, List
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

class CacheLevel(Enum):
    """ç¼“å­˜çº§åˆ«æšä¸¾"""
    L1_MEMORY = "l1_memory"
    L2_DISTRIBUTED = "l2_distributed"
    L3_DATABASE = "l3_database"
    L4_VECTOR = "l4_vector"

@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®ç±»"""
    ttl: int  # ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
    max_size: int  # æœ€å¤§ç¼“å­˜å¤§å°
    eviction_policy: str  # æ·˜æ±°ç­–ç•¥
    compression: bool = False  # æ˜¯å¦å‹ç¼©
    serialization: str = "json"  # åºåˆ—åŒ–æ–¹å¼

class CacheManager:
    """å¤šå±‚ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_cluster_nodes: List[Dict[str, Any]]):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            redis_cluster_nodes: Redisé›†ç¾¤èŠ‚ç‚¹é…ç½®
        """
        self.redis_cluster = redis.RedisCluster(
            startup_nodes=redis_cluster_nodes,
            decode_responses=True,
            skip_full_coverage_check=True,
            health_check_interval=30
        )
        
        # ç¼“å­˜é…ç½®
        self.cache_configs = {
            "document_vectors": CacheConfig(
                ttl=3600,  # 1å°æ—¶
                max_size=10000,
                eviction_policy="lru",
                compression=True
            ),
            "search_results": CacheConfig(
                ttl=1800,  # 30åˆ†é’Ÿ
                max_size=5000,
                eviction_policy="lru"
            ),
            "user_sessions": CacheConfig(
                ttl=7200,  # 2å°æ—¶
                max_size=1000,
                eviction_policy="ttl"
            ),
            "knowledge_graph": CacheConfig(
                ttl=86400,  # 24å°æ—¶
                max_size=50000,
                eviction_policy="lfu",
                compression=True
            )
        }
    
    def _generate_cache_key(self, namespace: str, key: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{namespace}:{hashlib.md5(key.encode()).hexdigest()}"
    
    def get(self, namespace: str, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜æ•°æ®
        
        Args:
            namespace: å‘½åç©ºé—´
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜çš„æ•°æ®æˆ–None
        """
        cache_key = self._generate_cache_key(namespace, key)
        
        try:
            # å°è¯•ä»Redisè·å–
            cached_data = self.redis_cluster.get(cache_key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            print(f"Cache get error: {e}")
        
        return None
    
    def set(self, namespace: str, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """
        è®¾ç½®ç¼“å­˜æ•°æ®
        
        Args:
            namespace: å‘½åç©ºé—´
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        cache_key = self._generate_cache_key(namespace, key)
        config = self.cache_configs.get(namespace)
        
        if not config:
            return False
        
        try:
            # åºåˆ—åŒ–æ•°æ®
            serialized_data = json.dumps(value, ensure_ascii=False)
            
            # è®¾ç½®TTL
            cache_ttl = ttl or config.ttl
            
            # å­˜å‚¨åˆ°Redis
            return self.redis_cluster.setex(
                cache_key, 
                cache_ttl, 
                serialized_data
            )
        except Exception as e:
            print(f"Cache set error: {e}")
            return False
    
    def delete(self, namespace: str, key: str) -> bool:
        """
        åˆ é™¤ç¼“å­˜æ•°æ®
        
        Args:
            namespace: å‘½åç©ºé—´
            key: ç¼“å­˜é”®
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        cache_key = self._generate_cache_key(namespace, key)
        
        try:
            return bool(self.redis_cluster.delete(cache_key))
        except Exception as e:
            print(f"Cache delete error: {e}")
            return False
    
    def invalidate_pattern(self, pattern: str) -> int:
        """
        æŒ‰æ¨¡å¼æ‰¹é‡åˆ é™¤ç¼“å­˜
        
        Args:
            pattern: åŒ¹é…æ¨¡å¼
            
        Returns:
            åˆ é™¤çš„é”®æ•°é‡
        """
        try:
            keys = self.redis_cluster.keys(pattern)
            if keys:
                return self.redis_cluster.delete(*keys)
            return 0
        except Exception as e:
            print(f"Cache invalidate error: {e}")
            return 0
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç¼“å­˜ç»Ÿè®¡æ•°æ®
        """
        try:
            info = self.redis_cluster.info()
            return {
                "memory_usage": info.get("used_memory_human"),
                "connected_clients": info.get("connected_clients"),
                "total_commands_processed": info.get("total_commands_processed"),
                "keyspace_hits": info.get("keyspace_hits"),
                "keyspace_misses": info.get("keyspace_misses"),
                "hit_rate": (
                    info.get("keyspace_hits", 0) / 
                    (info.get("keyspace_hits", 0) + info.get("keyspace_misses", 1))
                ) * 100
            }
        except Exception as e:
            print(f"Cache stats error: {e}")
            return {}
```

### 8.3 æ•°æ®åº“ä¼˜åŒ–

#### PostgreSQLæ€§èƒ½è°ƒä¼˜

**æ•°æ®åº“é…ç½®ä¼˜åŒ–**
```sql
-- postgresql.conf ä¼˜åŒ–é…ç½®

-- å†…å­˜é…ç½®
shared_buffers = '4GB'                    -- å…±äº«ç¼“å†²åŒº
effective_cache_size = '12GB'             -- æœ‰æ•ˆç¼“å­˜å¤§å°
work_mem = '256MB'                        -- å·¥ä½œå†…å­˜
maintenance_work_mem = '1GB'              -- ç»´æŠ¤å·¥ä½œå†…å­˜

-- è¿æ¥é…ç½®
max_connections = 200                     -- æœ€å¤§è¿æ¥æ•°
max_prepared_transactions = 100           -- æœ€å¤§é¢„å¤„ç†äº‹åŠ¡

-- æ£€æŸ¥ç‚¹é…ç½®
checkpoint_completion_target = 0.9        -- æ£€æŸ¥ç‚¹å®Œæˆç›®æ ‡
wal_buffers = '64MB'                      -- WALç¼“å†²åŒº
max_wal_size = '4GB'                      -- æœ€å¤§WALå¤§å°
min_wal_size = '1GB'                      -- æœ€å°WALå¤§å°

-- æŸ¥è¯¢ä¼˜åŒ–
random_page_cost = 1.1                   -- éšæœºé¡µé¢æˆæœ¬
effective_io_concurrency = 200            -- æœ‰æ•ˆIOå¹¶å‘

-- æ—¥å¿—é…ç½®
log_min_duration_statement = 1000         -- è®°å½•æ…¢æŸ¥è¯¢ï¼ˆ1ç§’ï¼‰
log_checkpoints = on                      -- è®°å½•æ£€æŸ¥ç‚¹
log_connections = on                      -- è®°å½•è¿æ¥
log_disconnections = on                   -- è®°å½•æ–­å¼€è¿æ¥
log_lock_waits = on                       -- è®°å½•é”ç­‰å¾…
```

**ç´¢å¼•ä¼˜åŒ–ç­–ç•¥**
```sql
-- åˆ›å»ºå¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½

-- æ–‡æ¡£è¡¨ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_documents_workspace_status 
    ON documents(workspace_id, status) 
    WHERE status IN ('active', 'processing');

CREATE INDEX CONCURRENTLY idx_documents_created_at_desc 
    ON documents(created_at DESC);

CREATE INDEX CONCURRENTLY idx_documents_content_search 
    ON documents USING gin(to_tsvector('english', title || ' ' || content));

-- å‘é‡è¡¨ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_vectors_document_chunk 
    ON document_vectors(document_id, chunk_index);

CREATE INDEX CONCURRENTLY idx_vectors_embedding_cosine 
    ON document_vectors USING ivfflat (embedding vector_cosine_ops) 
    WITH (lists = 1000);

-- çŸ¥è¯†å›¾è°±ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_entities_type_name 
    ON entities(entity_type, name);

CREATE INDEX CONCURRENTLY idx_relationships_source_target 
    ON relationships(source_entity_id, target_entity_id);

-- ç”¨æˆ·ä¼šè¯ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_user_sessions_user_active 
    ON user_sessions(user_id, is_active) 
    WHERE is_active = true;
```

**æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹**
```sql
-- ä¼˜åŒ–å‰ï¼šæ…¢æŸ¥è¯¢
SELECT d.*, dv.embedding 
FROM documents d 
JOIN document_vectors dv ON d.id = dv.document_id 
WHERE d.workspace_id = $1 
AND d.status = 'active' 
ORDER BY d.created_at DESC 
LIMIT 50;

-- ä¼˜åŒ–åï¼šä½¿ç”¨ç´¢å¼•å’Œåˆ†é¡µ
WITH recent_docs AS (
    SELECT id, title, content, created_at
    FROM documents 
    WHERE workspace_id = $1 
    AND status = 'active'
    AND created_at > $2  -- ä½¿ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
    ORDER BY created_at DESC 
    LIMIT 50
)
SELECT rd.*, dv.embedding 
FROM recent_docs rd
LEFT JOIN document_vectors dv ON rd.id = dv.document_id
ORDER BY rd.created_at DESC;
```

#### å‘é‡æ•°æ®åº“ä¼˜åŒ–

**Weaviateæ€§èƒ½é…ç½®**
```yaml
# weaviate-performance.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: weaviate-config
  namespace: knowledge-rag-prod
data:
  weaviate.conf: |
    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    QUERY_DEFAULTS_LIMIT: "100"
    QUERY_MAXIMUM_RESULTS: "10000"
    
    # å‘é‡ç´¢å¼•é…ç½®
    DEFAULT_VECTORIZER_MODULE: "none"
    ENABLE_MODULES: "backup-filesystem,text2vec-openai"
    
    # å†…å­˜é…ç½®
    GOGC: "100"
    GOMEMLIMIT: "8GiB"
    
    # å¹¶å‘é…ç½®
    ASYNC_INDEXING: "true"
    MAX_IMPORT_GOROUTINE_FACTOR: "1.5"
    
    # æŒä¹…åŒ–é…ç½®
    PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
    BACKUP_FILESYSTEM_PATH: "/var/lib/weaviate/backups"
    
    # é›†ç¾¤é…ç½®
    CLUSTER_HOSTNAME: "weaviate"
    CLUSTER_GOSSIP_BIND_PORT: "7946"
    CLUSTER_DATA_BIND_PORT: "7947"
```

### 8.4 å¾®æœåŠ¡æ€§èƒ½ä¼˜åŒ–

#### è¿æ¥æ± ä¼˜åŒ–

```python
# connection_pool.py
"""
æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–é…ç½®
æä¾›é«˜æ€§èƒ½çš„æ•°æ®åº“è¿æ¥ç®¡ç†
"""

import asyncio
import asyncpg
from typing import Optional, Dict, Any
from contextlib import asynccontextmanager

class DatabasePool:
    """å¼‚æ­¥æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨"""
    
    def __init__(self, database_url: str, **pool_kwargs):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± 
        
        Args:
            database_url: æ•°æ®åº“è¿æ¥URL
            **pool_kwargs: è¿æ¥æ± å‚æ•°
        """
        self.database_url = database_url
        self.pool_kwargs = {
            'min_size': 10,          # æœ€å°è¿æ¥æ•°
            'max_size': 50,          # æœ€å¤§è¿æ¥æ•°
            'max_queries': 50000,    # æ¯ä¸ªè¿æ¥æœ€å¤§æŸ¥è¯¢æ•°
            'max_inactive_connection_lifetime': 300,  # è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
            'command_timeout': 30,   # å‘½ä»¤è¶…æ—¶æ—¶é—´
            **pool_kwargs
        }
        self.pool: Optional[asyncpg.Pool] = None
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        self.pool = await asyncpg.create_pool(
            self.database_url,
            **self.pool_kwargs
        )
    
    async def close(self):
        """å…³é—­è¿æ¥æ± """
        if self.pool:
            await self.pool.close()
    
    @asynccontextmanager
    async def acquire(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not self.pool:
            raise RuntimeError("Database pool not initialized")
        
        async with self.pool.acquire() as connection:
            yield connection
    
    async def execute(self, query: str, *args) -> str:
        """æ‰§è¡ŒSQLå‘½ä»¤"""
        async with self.acquire() as conn:
            return await conn.execute(query, *args)
    
    async def fetch(self, query: str, *args) -> list:
        """æŸ¥è¯¢å¤šè¡Œæ•°æ®"""
        async with self.acquire() as conn:
            return await conn.fetch(query, *args)
    
    async def fetchrow(self, query: str, *args) -> Optional[Dict[str, Any]]:
        """æŸ¥è¯¢å•è¡Œæ•°æ®"""
        async with self.acquire() as conn:
            row = await conn.fetchrow(query, *args)
            return dict(row) if row else None
    
    async def get_pool_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯"""
        if not self.pool:
            return {}
        
        return {
            'size': self.pool.get_size(),
            'min_size': self.pool.get_min_size(),
            'max_size': self.pool.get_max_size(),
            'idle_size': self.pool.get_idle_size()
        }
```

#### å¼‚æ­¥å¤„ç†ä¼˜åŒ–

```python
# async_processor.py
"""
å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨
æä¾›é«˜æ€§èƒ½çš„å¼‚æ­¥ä»»åŠ¡å¤„ç†å’Œé˜Ÿåˆ—ç®¡ç†
"""

import asyncio
import aioredis
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from enum import Enum
import json
import time
from concurrent.futures import ThreadPoolExecutor

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class Task:
    """å¼‚æ­¥ä»»åŠ¡æ•°æ®ç±»"""
    id: str
    type: str
    payload: Dict[str, Any]
    priority: TaskPriority = TaskPriority.NORMAL
    retry_count: int = 0
    max_retries: int = 3
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()

class AsyncTaskProcessor:
    """å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨"""
    
    def __init__(self, redis_url: str, max_workers: int = 10):
        """
        åˆå§‹åŒ–å¼‚æ­¥ä»»åŠ¡å¤„ç†å™¨
        
        Args:
            redis_url: Redisè¿æ¥URL
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        """
        self.redis_url = redis_url
        self.max_workers = max_workers
        self.redis: Optional[aioredis.Redis] = None
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.task_handlers: Dict[str, Callable] = {}
        self.running = False
        
        # é˜Ÿåˆ—åç§°
        self.queues = {
            TaskPriority.CRITICAL: "tasks:critical",
            TaskPriority.HIGH: "tasks:high",
            TaskPriority.NORMAL: "tasks:normal",
            TaskPriority.LOW: "tasks:low"
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        self.redis = aioredis.from_url(self.redis_url)
    
    async def close(self):
        """å…³é—­è¿æ¥å’Œçº¿ç¨‹æ± """
        self.running = False
        if self.redis:
            await self.redis.close()
        self.executor.shutdown(wait=True)
    
    def register_handler(self, task_type: str, handler: Callable):
        """æ³¨å†Œä»»åŠ¡å¤„ç†å™¨"""
        self.task_handlers[task_type] = handler
    
    async def enqueue_task(self, task: Task) -> bool:
        """
        å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
        
        Args:
            task: è¦å¤„ç†çš„ä»»åŠ¡
            
        Returns:
            æ˜¯å¦æˆåŠŸåŠ å…¥é˜Ÿåˆ—
        """
        if not self.redis:
            return False
        
        try:
            queue_name = self.queues[task.priority]
            task_data = json.dumps({
                'id': task.id,
                'type': task.type,
                'payload': task.payload,
                'priority': task.priority.value,
                'retry_count': task.retry_count,
                'max_retries': task.max_retries,
                'created_at': task.created_at
            })
            
            await self.redis.lpush(queue_name, task_data)
            return True
        except Exception as e:
            print(f"Enqueue task error: {e}")
            return False
    
    async def dequeue_task(self) -> Optional[Task]:
        """
        ä»é˜Ÿåˆ—ä¸­å–å‡ºä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        
        Returns:
            ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„ä»»åŠ¡æˆ–None
        """
        if not self.redis:
            return None
        
        try:
            # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é˜Ÿåˆ—
            for priority in [TaskPriority.CRITICAL, TaskPriority.HIGH, 
                           TaskPriority.NORMAL, TaskPriority.LOW]:
                queue_name = self.queues[priority]
                task_data = await self.redis.brpop(queue_name, timeout=1)
                
                if task_data:
                    _, data = task_data
                    task_dict = json.loads(data)
                    return Task(
                        id=task_dict['id'],
                        type=task_dict['type'],
                        payload=task_dict['payload'],
                        priority=TaskPriority(task_dict['priority']),
                        retry_count=task_dict['retry_count'],
                        max_retries=task_dict['max_retries'],
                        created_at=task_dict['created_at']
                    )
        except Exception as e:
            print(f"Dequeue task error: {e}")
        
        return None
    
    async def process_task(self, task: Task) -> bool:
        """
        å¤„ç†å•ä¸ªä»»åŠ¡
        
        Args:
            task: è¦å¤„ç†çš„ä»»åŠ¡
            
        Returns:
            æ˜¯å¦å¤„ç†æˆåŠŸ
        """
        handler = self.task_handlers.get(task.type)
        if not handler:
            print(f"No handler for task type: {task.type}")
            return False
        
        try:
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
            if asyncio.iscoroutinefunction(handler):
                await handler(task.payload)
            else:
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(self.executor, handler, task.payload)
            
            return True
        except Exception as e:
            print(f"Task processing error: {e}")
            
            # é‡è¯•é€»è¾‘
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                await self.enqueue_task(task)
            
            return False
    
    async def start_processing(self):
        """å¼€å§‹å¤„ç†ä»»åŠ¡"""
        self.running = True
        
        # åˆ›å»ºå¤šä¸ªå·¥ä½œåç¨‹
        workers = [
            asyncio.create_task(self._worker(f"worker-{i}"))
            for i in range(self.max_workers)
        ]
        
        try:
            await asyncio.gather(*workers)
        except Exception as e:
            print(f"Task processing stopped: {e}")
        finally:
            self.running = False
    
    async def _worker(self, worker_name: str):
        """å·¥ä½œåç¨‹"""
        print(f"Worker {worker_name} started")
        
        while self.running:
            try:
                task = await self.dequeue_task()
                if task:
                    print(f"Worker {worker_name} processing task {task.id}")
                    success = await self.process_task(task)
                    if success:
                        print(f"Task {task.id} completed successfully")
                    else:
                        print(f"Task {task.id} failed")
            except Exception as e:
                print(f"Worker {worker_name} error: {e}")
                await asyncio.sleep(1)
        
        print(f"Worker {worker_name} stopped")
    
    async def get_queue_stats(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        if not self.redis:
            return {}
        
        stats = {}
        for priority, queue_name in self.queues.items():
            try:
                length = await self.redis.llen(queue_name)
                stats[priority.name.lower()] = length
            except Exception:
                stats[priority.name.lower()] = 0
        
        return stats
```

### 8.5 è´Ÿè½½å‡è¡¡å’Œæ‰©å±•

#### æ°´å¹³æ‰©å±•ç­–ç•¥

**Kubernetes HPAé…ç½®**
```yaml
# hpa-config.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: knowledge-rag-hpa
  namespace: knowledge-rag-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: query-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Max
```

**è´Ÿè½½å‡è¡¡é…ç½®**
```yaml
# nginx-lb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-lb-config
  namespace: knowledge-rag-prod
data:
  nginx.conf: |
    upstream query_service {
        least_conn;
        server query-service-1:8000 max_fails=3 fail_timeout=30s;
        server query-service-2:8000 max_fails=3 fail_timeout=30s;
        server query-service-3:8000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    upstream vector_service {
        ip_hash;  # ä¼šè¯ç²˜æ€§
        server vector-service-1:8000 max_fails=3 fail_timeout=30s;
        server vector-service-2:8000 max_fails=3 fail_timeout=30s;
        keepalive 16;
    }
    
    server {
        listen 80;
        server_name api.knowledge-rag.com;
        
        # è¿æ¥è¶…æ—¶é…ç½®
        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
        
        # ç¼“å†²åŒºé…ç½®
        proxy_buffering on;
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
        
        # å‹ç¼©é…ç½®
        gzip on;
        gzip_vary on;
        gzip_min_length 1000;
        gzip_types text/plain application/json application/xml;
        
        # APIè·¯ç”±
        location /api/v1/query {
            proxy_pass http://query_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # é™æµé…ç½®
            limit_req zone=api burst=20 nodelay;
        }
        
        location /api/v1/vectors {
            proxy_pass http://vector_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # å¤§æ–‡ä»¶ä¸Šä¼ é…ç½®
            client_max_body_size 100M;
            proxy_request_buffering off;
        }
    }
    
    # é™æµé…ç½®
    http {
        limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    }
```

### 8.6 æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜

#### æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "Knowledge RAG Performance Dashboard",
    "panels": [
      {
        "title": "API Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=\"api-gateway\"}[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{job=\"api-gateway\"}[5m]))",
            "legendFormat": "50th percentile"
          }
        ],
        "yAxes": [{
          "unit": "s",
          "max": 5
        }]
      },
      {
        "title": "Database Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(pg_stat_database_tup_fetched[5m])",
            "legendFormat": "Rows fetched/sec"
          },
          {
            "expr": "rate(pg_stat_database_tup_inserted[5m])",
            "legendFormat": "Rows inserted/sec"
          },
          {
            "expr": "pg_stat_activity_count",
            "legendFormat": "Active connections"
          }
        ]
      },
      {
        "title": "Cache Hit Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "(rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))) * 100",
            "legendFormat": "Cache Hit Rate %"
          }
        ],
        "thresholds": {
          "steps": [
            {"color": "red", "value": 0},
            {"color": "yellow", "value": 80},
            {"color": "green", "value": 95}
          ]
        }
      },
      {
        "title": "Vector Search Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(weaviate_query_duration_seconds_bucket[5m]))",
            "legendFormat": "Vector search P95"
          },
          {
            "expr": "rate(weaviate_queries_total[5m])",
            "legendFormat": "Queries/sec"
          }
        ]
      },
      {
        "title": "Resource Utilization",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{pod=~\"knowledge-rag-.*\"}[5m]) * 100",
            "legendFormat": "CPU % - {{pod}}"
          },
          {
            "expr": "(container_memory_working_set_bytes{pod=~\"knowledge-rag-.*\"} / container_spec_memory_limit_bytes{pod=~\"knowledge-rag-.*\"}) * 100",
            "legendFormat": "Memory % - {{pod}}"
          }
        ]
      }
    ]
  }
}
```

### 8.7 æ€§èƒ½ä¼˜åŒ–æ€»ç»“

#### ä¼˜åŒ–æ•ˆæœé¢„æœŸ

**å“åº”æ—¶é—´ä¼˜åŒ–**
- APIç½‘å…³å“åº”æ—¶é—´ï¼šä»200msé™è‡³50msï¼ˆP95ï¼‰
- å‘é‡æœç´¢å“åº”æ—¶é—´ï¼šä»2sé™è‡³300msï¼ˆP95ï¼‰
- é—®ç­”ç”Ÿæˆå“åº”æ—¶é—´ï¼šä»8sé™è‡³2sï¼ˆP95ï¼‰
- æ–‡æ¡£ä¸Šä¼ å¤„ç†æ—¶é—´ï¼šä»30sé™è‡³5sï¼ˆP95ï¼‰

**ååé‡æå‡**
- å¹¶å‘ç”¨æˆ·æ•°ï¼šä»100æå‡è‡³1000+
- æŸ¥è¯¢å¤„ç†èƒ½åŠ›ï¼šä»10 QPSæå‡è‡³100+ QPS
- æ–‡æ¡£å¤„ç†èƒ½åŠ›ï¼šä»100/å°æ—¶æå‡è‡³10000+/å°æ—¶
- å‘é‡æ“ä½œèƒ½åŠ›ï¼šä»100 OPSæå‡è‡³1000+ OPS

**èµ„æºåˆ©ç”¨ç‡ä¼˜åŒ–**
- CPUåˆ©ç”¨ç‡ï¼šä¿æŒåœ¨70%ä»¥ä¸‹
- å†…å­˜åˆ©ç”¨ç‡ï¼šä¿æŒåœ¨80%ä»¥ä¸‹
- ç¼“å­˜å‘½ä¸­ç‡ï¼šæå‡è‡³95%ä»¥ä¸Š
- æ•°æ®åº“è¿æ¥åˆ©ç”¨ç‡ï¼šä¿æŒåœ¨80%ä»¥ä¸‹

#### æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•

**åº”ç”¨å±‚ä¼˜åŒ–**
- [ ] å®æ–½å¤šå±‚ç¼“å­˜ç­–ç•¥
- [ ] ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç´¢å¼•
- [ ] é…ç½®è¿æ¥æ± å’Œå¼‚æ­¥å¤„ç†
- [ ] å®ç°è´Ÿè½½å‡è¡¡å’Œæ°´å¹³æ‰©å±•
- [ ] ä¼˜åŒ–APIå“åº”æ ¼å¼å’Œå‹ç¼©

**æ•°æ®å±‚ä¼˜åŒ–**
- [ ] PostgreSQLæ€§èƒ½è°ƒä¼˜
- [ ] Weaviateå‘é‡ç´¢å¼•ä¼˜åŒ–
- [ ] Redisé›†ç¾¤é…ç½®ä¼˜åŒ–
- [ ] Neo4jå›¾æ•°æ®åº“è°ƒä¼˜
- [ ] æ•°æ®åˆ†ç‰‡å’Œåˆ†åŒºç­–ç•¥

**åŸºç¡€è®¾æ–½ä¼˜åŒ–**
- [ ] Kubernetesèµ„æºé…ç½®ä¼˜åŒ–
- [ ] å­˜å‚¨I/Oæ€§èƒ½ä¼˜åŒ–
- [ ] ç½‘ç»œå»¶è¿Ÿä¼˜åŒ–
- [ ] å®¹å™¨é•œåƒä¼˜åŒ–
- [ ] ç›‘æ§å’Œå‘Šè­¦é…ç½®

**ä»£ç å±‚ä¼˜åŒ–**
- [ ] å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼
- [ ] å†…å­˜ç®¡ç†ä¼˜åŒ–
- [ ] ç®—æ³•å¤æ‚åº¦ä¼˜åŒ–
- [ ] å¹¶å‘å¤„ç†ä¼˜åŒ–
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

---

---

## 9. é”™è¯¯å¤„ç†æœºåˆ¶

æœ¬èŠ‚è¯¦ç»†é˜è¿°Knowledge RAGç³»ç»Ÿçš„ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ•…éšœæ¢å¤æœºåˆ¶ï¼ŒåŒ…æ‹¬é”™è¯¯åˆ†ç±»ã€å¼‚å¸¸å¤„ç†ç­–ç•¥ã€æ•…éšœæ¢å¤æ–¹æ¡ˆå’Œç›‘æ§å‘Šè­¦ç­‰å…³é”®æŠ€æœ¯ã€‚

### 9.1 é”™è¯¯åˆ†ç±»å’Œå¤„ç†ç­–ç•¥

#### é”™è¯¯åˆ†ç±»ä½“ç³»

**ç³»ç»Ÿçº§é”™è¯¯**
- **åŸºç¡€è®¾æ–½æ•…éšœ**ï¼šæœåŠ¡å™¨å®•æœºã€ç½‘ç»œä¸­æ–­ã€å­˜å‚¨æ•…éšœ
- **æœåŠ¡ä¸å¯ç”¨**ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥ã€å¤–éƒ¨APIè¶…æ—¶ã€å†…å­˜æº¢å‡º
- **èµ„æºè€—å°½**ï¼šCPUè¿‡è½½ã€å†…å­˜ä¸è¶³ã€ç£ç›˜ç©ºé—´æ»¡
- **é…ç½®é”™è¯¯**ï¼šç¯å¢ƒå˜é‡ç¼ºå¤±ã€é…ç½®æ–‡ä»¶é”™è¯¯ã€æƒé™é—®é¢˜

**ä¸šåŠ¡çº§é”™è¯¯**
- **æ•°æ®éªŒè¯é”™è¯¯**ï¼šè¾“å…¥å‚æ•°æ— æ•ˆã€æ•°æ®æ ¼å¼é”™è¯¯ã€ä¸šåŠ¡è§„åˆ™è¿å
- **æƒé™é”™è¯¯**ï¼šè®¤è¯å¤±è´¥ã€æˆæƒä¸è¶³ã€è®¿é—®è¢«æ‹’ç»
- **ä¸šåŠ¡é€»è¾‘é”™è¯¯**ï¼šå·¥ä½œæµå¼‚å¸¸ã€çŠ¶æ€è½¬æ¢é”™è¯¯ã€ä¾èµ–æœåŠ¡å¤±è´¥
- **æ•°æ®ä¸€è‡´æ€§é”™è¯¯**ï¼šå¹¶å‘å†²çªã€äº‹åŠ¡å›æ»šã€æ•°æ®ä¸ä¸€è‡´

**ç”¨æˆ·çº§é”™è¯¯**
- **è¯·æ±‚é”™è¯¯**ï¼šå‚æ•°ç¼ºå¤±ã€æ ¼å¼é”™è¯¯ã€è¯·æ±‚è¿‡å¤§
- **æ“ä½œé”™è¯¯**ï¼šé‡å¤æ“ä½œã€éæ³•æ“ä½œã€è¶…å‡ºé™åˆ¶
- **ä¼šè¯é”™è¯¯**ï¼šä¼šè¯è¿‡æœŸã€ä»¤ç‰Œæ— æ•ˆã€çŠ¶æ€ä¸¢å¤±

#### é”™è¯¯ç æ ‡å‡†åŒ–

```yaml
# é”™è¯¯ç è§„èŒƒ
error_codes:
  # ç³»ç»Ÿçº§é”™è¯¯ (1000-1999)
  system_errors:
    1001: "æœåŠ¡ä¸å¯ç”¨"
    1002: "æ•°æ®åº“è¿æ¥å¤±è´¥"
    1003: "å¤–éƒ¨æœåŠ¡è¶…æ—¶"
    1004: "å†…å­˜ä¸è¶³"
    1005: "ç£ç›˜ç©ºé—´ä¸è¶³"
    1006: "ç½‘ç»œè¿æ¥å¼‚å¸¸"
    1007: "é…ç½®é”™è¯¯"
    1008: "æœåŠ¡å¯åŠ¨å¤±è´¥"
  
  # ä¸šåŠ¡çº§é”™è¯¯ (2000-2999)
  business_errors:
    2001: "æ•°æ®éªŒè¯å¤±è´¥"
    2002: "ä¸šåŠ¡è§„åˆ™è¿å"
    2003: "å·¥ä½œæµå¼‚å¸¸"
    2004: "æ•°æ®ä¸ä¸€è‡´"
    2005: "å¹¶å‘å†²çª"
    2006: "ä¾èµ–æœåŠ¡å¤±è´¥"
    2007: "çŠ¶æ€è½¬æ¢é”™è¯¯"
    2008: "èµ„æºå·²å­˜åœ¨"
  
  # ç”¨æˆ·çº§é”™è¯¯ (3000-3999)
  user_errors:
    3001: "å‚æ•°ç¼ºå¤±"
    3002: "å‚æ•°æ ¼å¼é”™è¯¯"
    3003: "è®¤è¯å¤±è´¥"
    3004: "æƒé™ä¸è¶³"
    3005: "ä¼šè¯è¿‡æœŸ"
    3006: "è¯·æ±‚è¿‡å¤§"
    3007: "æ“ä½œé¢‘ç‡è¿‡é«˜"
    3008: "èµ„æºä¸å­˜åœ¨"
  
  # å¤–éƒ¨æœåŠ¡é”™è¯¯ (4000-4999)
  external_errors:
    4001: "LLMæœåŠ¡å¼‚å¸¸"
    4002: "å‘é‡æ•°æ®åº“é”™è¯¯"
    4003: "æ–‡ä»¶å­˜å‚¨æœåŠ¡å¼‚å¸¸"
    4004: "æ¶ˆæ¯é˜Ÿåˆ—å¼‚å¸¸"
    4005: "ç¼“å­˜æœåŠ¡å¼‚å¸¸"
    4006: "ç¬¬ä¸‰æ–¹APIå¼‚å¸¸"
    4007: "ç½‘ç»œæœåŠ¡å¼‚å¸¸"
    4008: "è®¤è¯æœåŠ¡å¼‚å¸¸"
```

### 9.2 ç»Ÿä¸€å¼‚å¸¸å¤„ç†æ¡†æ¶

#### å¼‚å¸¸å¤„ç†ä¸­é—´ä»¶

```python
# error_handler.py
"""
Knowledge RAGç³»ç»Ÿç»Ÿä¸€å¼‚å¸¸å¤„ç†æ¡†æ¶
æä¾›æ ‡å‡†åŒ–çš„é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•å’Œæ•…éšœæ¢å¤åŠŸèƒ½
"""

import traceback
import logging
import json
from typing import Dict, Any, Optional, Callable
from datetime import datetime
from enum import Enum
from dataclasses import dataclass, asdict
from fastapi import Request, Response
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware

class ErrorSeverity(Enum):
    """é”™è¯¯ä¸¥é‡ç¨‹åº¦æšä¸¾"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class ErrorCategory(Enum):
    """é”™è¯¯ç±»åˆ«æšä¸¾"""
    SYSTEM = "system"
    BUSINESS = "business"
    USER = "user"
    EXTERNAL = "external"

@dataclass
class ErrorContext:
    """é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    request_id: str
    user_id: Optional[str]
    service_name: str
    endpoint: str
    method: str
    timestamp: datetime
    client_ip: str
    user_agent: str
    additional_data: Dict[str, Any] = None

@dataclass
class StandardError:
    """æ ‡å‡†åŒ–é”™è¯¯å¯¹è±¡"""
    code: int
    message: str
    category: ErrorCategory
    severity: ErrorSeverity
    context: ErrorContext
    details: Optional[Dict[str, Any]] = None
    stack_trace: Optional[str] = None
    correlation_id: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "error": {
                "code": self.code,
                "message": self.message,
                "category": self.category.value,
                "severity": self.severity.value,
                "timestamp": self.context.timestamp.isoformat(),
                "request_id": self.context.request_id,
                "correlation_id": self.correlation_id,
                "details": self.details or {}
            }
        }
    
    def to_user_response(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„å“åº”æ ¼å¼"""
        # è¿‡æ»¤æ•æ„Ÿä¿¡æ¯ï¼Œåªè¿”å›ç”¨æˆ·éœ€è¦çš„é”™è¯¯ä¿¡æ¯
        user_message = self.message
        if self.category == ErrorCategory.SYSTEM:
            user_message = "ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
        
        return {
            "success": False,
            "error": {
                "code": self.code,
                "message": user_message,
                "request_id": self.context.request_id
            }
        }

class KnowledgeRAGException(Exception):
    """Knowledge RAGç³»ç»Ÿè‡ªå®šä¹‰å¼‚å¸¸åŸºç±»"""
    
    def __init__(self, code: int, message: str, category: ErrorCategory, 
                 severity: ErrorSeverity = ErrorSeverity.MEDIUM, 
                 details: Optional[Dict[str, Any]] = None):
        self.code = code
        self.message = message
        self.category = category
        self.severity = severity
        self.details = details or {}
        super().__init__(self.message)

class SystemException(KnowledgeRAGException):
    """ç³»ç»Ÿçº§å¼‚å¸¸"""
    def __init__(self, code: int, message: str, 
                 severity: ErrorSeverity = ErrorSeverity.HIGH, 
                 details: Optional[Dict[str, Any]] = None):
        super().__init__(code, message, ErrorCategory.SYSTEM, severity, details)

class BusinessException(KnowledgeRAGException):
    """ä¸šåŠ¡çº§å¼‚å¸¸"""
    def __init__(self, code: int, message: str, 
                 severity: ErrorSeverity = ErrorSeverity.MEDIUM, 
                 details: Optional[Dict[str, Any]] = None):
        super().__init__(code, message, ErrorCategory.BUSINESS, severity, details)

class UserException(KnowledgeRAGException):
    """ç”¨æˆ·çº§å¼‚å¸¸"""
    def __init__(self, code: int, message: str, 
                 severity: ErrorSeverity = ErrorSeverity.LOW, 
                 details: Optional[Dict[str, Any]] = None):
        super().__init__(code, message, ErrorCategory.USER, severity, details)

class ExternalException(KnowledgeRAGException):
    """å¤–éƒ¨æœåŠ¡å¼‚å¸¸"""
    def __init__(self, code: int, message: str, 
                 severity: ErrorSeverity = ErrorSeverity.MEDIUM, 
                 details: Optional[Dict[str, Any]] = None):
        super().__init__(code, message, ErrorCategory.EXTERNAL, severity, details)

class ErrorHandler:
    """ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self, service_name: str, logger: logging.Logger):
        self.service_name = service_name
        self.logger = logger
        self.error_callbacks: Dict[ErrorCategory, List[Callable]] = {
            ErrorCategory.SYSTEM: [],
            ErrorCategory.BUSINESS: [],
            ErrorCategory.USER: [],
            ErrorCategory.EXTERNAL: []
        }
    
    def register_callback(self, category: ErrorCategory, callback: Callable):
        """æ³¨å†Œé”™è¯¯å¤„ç†å›è°ƒå‡½æ•°"""
        self.error_callbacks[category].append(callback)
    
    def create_error_context(self, request: Request) -> ErrorContext:
        """åˆ›å»ºé”™è¯¯ä¸Šä¸‹æ–‡"""
        return ErrorContext(
            request_id=getattr(request.state, 'request_id', 'unknown'),
            user_id=getattr(request.state, 'user_id', None),
            service_name=self.service_name,
            endpoint=str(request.url.path),
            method=request.method,
            timestamp=datetime.utcnow(),
            client_ip=request.client.host if request.client else 'unknown',
            user_agent=request.headers.get('user-agent', 'unknown')
        )
    
    def handle_exception(self, exception: Exception, context: ErrorContext) -> StandardError:
        """å¤„ç†å¼‚å¸¸å¹¶è¿”å›æ ‡å‡†åŒ–é”™è¯¯å¯¹è±¡"""
        if isinstance(exception, KnowledgeRAGException):
            # å¤„ç†è‡ªå®šä¹‰å¼‚å¸¸
            error = StandardError(
                code=exception.code,
                message=exception.message,
                category=exception.category,
                severity=exception.severity,
                context=context,
                details=exception.details,
                correlation_id=context.request_id
            )
        else:
            # å¤„ç†æœªçŸ¥å¼‚å¸¸
            error = StandardError(
                code=1001,
                message="ç³»ç»Ÿå†…éƒ¨é”™è¯¯",
                category=ErrorCategory.SYSTEM,
                severity=ErrorSeverity.HIGH,
                context=context,
                stack_trace=traceback.format_exc(),
                correlation_id=context.request_id
            )
        
        # è®°å½•é”™è¯¯æ—¥å¿—
        self._log_error(error)
        
        # æ‰§è¡Œé”™è¯¯å¤„ç†å›è°ƒ
        self._execute_callbacks(error)
        
        return error
    
    def _log_error(self, error: StandardError):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        log_data = {
            "error_code": error.code,
            "error_message": error.message,
            "category": error.category.value,
            "severity": error.severity.value,
            "service": error.context.service_name,
            "endpoint": error.context.endpoint,
            "method": error.context.method,
            "request_id": error.context.request_id,
            "user_id": error.context.user_id,
            "timestamp": error.context.timestamp.isoformat(),
            "details": error.details
        }
        
        if error.severity in [ErrorSeverity.HIGH, ErrorSeverity.CRITICAL]:
            self.logger.error(f"Error occurred: {json.dumps(log_data, ensure_ascii=False)}")
            if error.stack_trace:
                self.logger.error(f"Stack trace: {error.stack_trace}")
        elif error.severity == ErrorSeverity.MEDIUM:
            self.logger.warning(f"Warning: {json.dumps(log_data, ensure_ascii=False)}")
        else:
            self.logger.info(f"Info: {json.dumps(log_data, ensure_ascii=False)}")
    
    def _execute_callbacks(self, error: StandardError):
        """æ‰§è¡Œé”™è¯¯å¤„ç†å›è°ƒå‡½æ•°"""
        callbacks = self.error_callbacks.get(error.category, [])
        for callback in callbacks:
            try:
                callback(error)
            except Exception as e:
                self.logger.error(f"Error callback execution failed: {e}")

class ErrorHandlingMiddleware(BaseHTTPMiddleware):
    """é”™è¯¯å¤„ç†ä¸­é—´ä»¶"""
    
    def __init__(self, app, service_name: str, logger: logging.Logger):
        super().__init__(app)
        self.error_handler = ErrorHandler(service_name, logger)
    
    async def dispatch(self, request: Request, call_next):
        """å¤„ç†è¯·æ±‚å¹¶æ•è·å¼‚å¸¸"""
        try:
            response = await call_next(request)
            return response
        except Exception as exception:
            # åˆ›å»ºé”™è¯¯ä¸Šä¸‹æ–‡
            context = self.error_handler.create_error_context(request)
            
            # å¤„ç†å¼‚å¸¸
            error = self.error_handler.handle_exception(exception, context)
            
            # è¿”å›æ ‡å‡†åŒ–é”™è¯¯å“åº”
            status_code = self._get_http_status_code(error)
            return JSONResponse(
                status_code=status_code,
                content=error.to_user_response()
            )
    
    def _get_http_status_code(self, error: StandardError) -> int:
        """æ ¹æ®é”™è¯¯ç±»å‹è¿”å›HTTPçŠ¶æ€ç """
        if error.category == ErrorCategory.USER:
            if error.code in [3003, 3004]:  # è®¤è¯/æˆæƒé”™è¯¯
                return 401
            elif error.code in [3001, 3002, 3006]:  # å‚æ•°é”™è¯¯
                return 400
            elif error.code == 3008:  # èµ„æºä¸å­˜åœ¨
                return 404
            else:
                return 400
        elif error.category == ErrorCategory.BUSINESS:
            return 422  # ä¸šåŠ¡é€»è¾‘é”™è¯¯
        elif error.category in [ErrorCategory.SYSTEM, ErrorCategory.EXTERNAL]:
            return 500  # æœåŠ¡å™¨é”™è¯¯
        else:
            return 500
```

### 9.3 æ•…éšœæ¢å¤æœºåˆ¶

#### é‡è¯•ç­–ç•¥

```python
# retry_mechanism.py
"""
æ•…éšœæ¢å¤å’Œé‡è¯•æœºåˆ¶
æä¾›æ™ºèƒ½é‡è¯•ã€ç†”æ–­å™¨å’Œé™çº§ç­–ç•¥
"""

import asyncio
import random
import time
from typing import Any, Callable, Optional, Dict, List
from dataclasses import dataclass
from enum import Enum
import logging
from functools import wraps

class RetryStrategy(Enum):
    """é‡è¯•ç­–ç•¥æšä¸¾"""
    FIXED = "fixed"
    EXPONENTIAL = "exponential"
    LINEAR = "linear"
    RANDOM = "random"

@dataclass
class RetryConfig:
    """é‡è¯•é…ç½®"""
    max_attempts: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    strategy: RetryStrategy = RetryStrategy.EXPONENTIAL
    backoff_multiplier: float = 2.0
    jitter: bool = True
    retryable_exceptions: List[type] = None

class CircuitBreakerState(Enum):
    """ç†”æ–­å™¨çŠ¶æ€æšä¸¾"""
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

@dataclass
class CircuitBreakerConfig:
    """ç†”æ–­å™¨é…ç½®"""
    failure_threshold: int = 5
    recovery_timeout: float = 60.0
    expected_exception: type = Exception
    success_threshold: int = 3

class CircuitBreaker:
    """ç†”æ–­å™¨å®ç°"""
    
    def __init__(self, config: CircuitBreakerConfig, name: str = "default"):
        self.config = config
        self.name = name
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.logger = logging.getLogger(f"circuit_breaker.{name}")
    
    def __call__(self, func: Callable) -> Callable:
        """è£…é¥°å™¨æ¨¡å¼ä½¿ç”¨ç†”æ–­å™¨"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            return await self.call(func, *args, **kwargs)
        return wrapper
    
    async def call(self, func: Callable, *args, **kwargs) -> Any:
        """æ‰§è¡Œå‡½æ•°è°ƒç”¨å¹¶åº”ç”¨ç†”æ–­å™¨é€»è¾‘"""
        if self.state == CircuitBreakerState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitBreakerState.HALF_OPEN
                self.logger.info(f"Circuit breaker {self.name} moved to HALF_OPEN")
            else:
                raise SystemException(
                    code=1001,
                    message=f"Circuit breaker {self.name} is OPEN",
                    details={"circuit_breaker": self.name, "state": self.state.value}
                )
        
        try:
            result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
            self._on_success()
            return result
        except self.config.expected_exception as e:
            self._on_failure()
            raise e
    
    def _should_attempt_reset(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å°è¯•é‡ç½®ç†”æ–­å™¨"""
        return (
            self.last_failure_time and 
            time.time() - self.last_failure_time >= self.config.recovery_timeout
        )
    
    def _on_success(self):
        """æˆåŠŸè°ƒç”¨å¤„ç†"""
        self.failure_count = 0
        
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.success_count += 1
            if self.success_count >= self.config.success_threshold:
                self.state = CircuitBreakerState.CLOSED
                self.success_count = 0
                self.logger.info(f"Circuit breaker {self.name} moved to CLOSED")
    
    def _on_failure(self):
        """å¤±è´¥è°ƒç”¨å¤„ç†"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.state = CircuitBreakerState.OPEN
            self.success_count = 0
            self.logger.warning(f"Circuit breaker {self.name} moved to OPEN (half-open failure)")
        elif self.failure_count >= self.config.failure_threshold:
            self.state = CircuitBreakerState.OPEN
            self.logger.warning(f"Circuit breaker {self.name} moved to OPEN (threshold reached)")

class RetryManager:
    """é‡è¯•ç®¡ç†å™¨"""
    
    def __init__(self, config: RetryConfig):
        self.config = config
        self.logger = logging.getLogger("retry_manager")
    
    def __call__(self, func: Callable) -> Callable:
        """è£…é¥°å™¨æ¨¡å¼ä½¿ç”¨é‡è¯•æœºåˆ¶"""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            return await self.execute_with_retry(func, *args, **kwargs)
        return wrapper
    
    async def execute_with_retry(self, func: Callable, *args, **kwargs) -> Any:
        """æ‰§è¡Œå‡½æ•°å¹¶åº”ç”¨é‡è¯•é€»è¾‘"""
        last_exception = None
        
        for attempt in range(self.config.max_attempts):
            try:
                if asyncio.iscoroutinefunction(func):
                    return await func(*args, **kwargs)
                else:
                    return func(*args, **kwargs)
            except Exception as e:
                last_exception = e
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¯é‡è¯•å¼‚å¸¸
                if self.config.retryable_exceptions and not any(
                    isinstance(e, exc_type) for exc_type in self.config.retryable_exceptions
                ):
                    self.logger.info(f"Non-retryable exception: {type(e).__name__}")
                    raise e
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                if attempt == self.config.max_attempts - 1:
                    self.logger.error(f"All retry attempts failed. Last exception: {e}")
                    raise e
                
                # è®¡ç®—å»¶è¿Ÿæ—¶é—´
                delay = self._calculate_delay(attempt)
                self.logger.warning(
                    f"Attempt {attempt + 1} failed: {e}. Retrying in {delay:.2f} seconds..."
                )
                
                await asyncio.sleep(delay)
        
        # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†ç±»å‹å®‰å…¨
        raise last_exception
    
    def _calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        if self.config.strategy == RetryStrategy.FIXED:
            delay = self.config.base_delay
        elif self.config.strategy == RetryStrategy.EXPONENTIAL:
            delay = self.config.base_delay * (self.config.backoff_multiplier ** attempt)
        elif self.config.strategy == RetryStrategy.LINEAR:
            delay = self.config.base_delay * (attempt + 1)
        elif self.config.strategy == RetryStrategy.RANDOM:
            delay = random.uniform(self.config.base_delay, self.config.max_delay)
        else:
            delay = self.config.base_delay
        
        # åº”ç”¨æœ€å¤§å»¶è¿Ÿé™åˆ¶
        delay = min(delay, self.config.max_delay)
        
        # æ·»åŠ æŠ–åŠ¨
        if self.config.jitter:
            jitter_range = delay * 0.1
            delay += random.uniform(-jitter_range, jitter_range)
        
        return max(0, delay)

class FallbackManager:
    """é™çº§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.fallback_handlers: Dict[str, Callable] = {}
        self.logger = logging.getLogger("fallback_manager")
    
    def register_fallback(self, service_name: str, handler: Callable):
        """æ³¨å†Œé™çº§å¤„ç†å™¨"""
        self.fallback_handlers[service_name] = handler
        self.logger.info(f"Registered fallback handler for service: {service_name}")
    
    async def execute_with_fallback(self, service_name: str, primary_func: Callable, 
                                  *args, **kwargs) -> Any:
        """æ‰§è¡Œä¸»è¦åŠŸèƒ½ï¼Œå¤±è´¥æ—¶ä½¿ç”¨é™çº§æ–¹æ¡ˆ"""
        try:
            if asyncio.iscoroutinefunction(primary_func):
                return await primary_func(*args, **kwargs)
            else:
                return primary_func(*args, **kwargs)
        except Exception as e:
            self.logger.warning(f"Primary function failed for {service_name}: {e}")
            
            fallback_handler = self.fallback_handlers.get(service_name)
            if fallback_handler:
                self.logger.info(f"Executing fallback for service: {service_name}")
                try:
                    if asyncio.iscoroutinefunction(fallback_handler):
                        return await fallback_handler(*args, **kwargs)
                    else:
                        return fallback_handler(*args, **kwargs)
                except Exception as fallback_error:
                    self.logger.error(f"Fallback also failed for {service_name}: {fallback_error}")
                    raise e  # æŠ›å‡ºåŸå§‹å¼‚å¸¸
            else:
                self.logger.error(f"No fallback handler registered for service: {service_name}")
                raise e
```

### 9.4 å¥åº·æ£€æŸ¥å’Œç›‘æ§

#### æœåŠ¡å¥åº·æ£€æŸ¥

```python
# health_check.py
"""
æœåŠ¡å¥åº·æ£€æŸ¥å’Œç›‘æ§ç³»ç»Ÿ
æä¾›å…¨é¢çš„æœåŠ¡çŠ¶æ€ç›‘æ§å’Œå¥åº·è¯„ä¼°åŠŸèƒ½
"""

import asyncio
import time
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import json
from datetime import datetime, timedelta

class HealthStatus(Enum):
    """å¥åº·çŠ¶æ€æšä¸¾"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"

@dataclass
class HealthCheckResult:
    """å¥åº·æ£€æŸ¥ç»“æœ"""
    name: str
    status: HealthStatus
    message: str
    duration_ms: float
    timestamp: datetime
    details: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "name": self.name,
            "status": self.status.value,
            "message": self.message,
            "duration_ms": self.duration_ms,
            "timestamp": self.timestamp.isoformat(),
            "details": self.details or {}
        }

@dataclass
class SystemHealthReport:
    """ç³»ç»Ÿå¥åº·æŠ¥å‘Š"""
    overall_status: HealthStatus
    timestamp: datetime
    checks: List[HealthCheckResult]
    summary: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "overall_status": self.overall_status.value,
            "timestamp": self.timestamp.isoformat(),
            "checks": [check.to_dict() for check in self.checks],
            "summary": self.summary
        }

class HealthChecker:
    """å¥åº·æ£€æŸ¥å™¨åŸºç±»"""
    
    def __init__(self, name: str, timeout: float = 5.0):
        self.name = name
        self.timeout = timeout
        self.logger = logging.getLogger(f"health_check.{name}")
    
    async def check(self) -> HealthCheckResult:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        start_time = time.time()
        
        try:
            # ä½¿ç”¨è¶…æ—¶æ§åˆ¶
            result = await asyncio.wait_for(
                self._perform_check(),
                timeout=self.timeout
            )
            
            duration_ms = (time.time() - start_time) * 1000
            
            return HealthCheckResult(
                name=self.name,
                status=result.get("status", HealthStatus.UNKNOWN),
                message=result.get("message", "Health check completed"),
                duration_ms=duration_ms,
                timestamp=datetime.utcnow(),
                details=result.get("details")
            )
        
        except asyncio.TimeoutError:
            duration_ms = (time.time() - start_time) * 1000
            return HealthCheckResult(
                name=self.name,
                status=HealthStatus.UNHEALTHY,
                message=f"Health check timed out after {self.timeout}s",
                duration_ms=duration_ms,
                timestamp=datetime.utcnow()
            )
        
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            return HealthCheckResult(
                name=self.name,
                status=HealthStatus.UNHEALTHY,
                message=f"Health check failed: {str(e)}",
                duration_ms=duration_ms,
                timestamp=datetime.utcnow(),
                details={"error": str(e)}
            )
    
    async def _perform_check(self) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“çš„å¥åº·æ£€æŸ¥é€»è¾‘ï¼ˆå­ç±»å®ç°ï¼‰"""
        raise NotImplementedError

class DatabaseHealthChecker(HealthChecker):
    """æ•°æ®åº“å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, name: str, database_pool, timeout: float = 5.0):
        super().__init__(name, timeout)
        self.database_pool = database_pool
    
    async def _perform_check(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥å’ŒåŸºæœ¬æŸ¥è¯¢"""
        try:
            async with self.database_pool.acquire() as conn:
                # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
                result = await conn.fetchval("SELECT 1")
                
                if result == 1:
                    # è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
                    pool_stats = await self.database_pool.get_pool_stats()
                    
                    return {
                        "status": HealthStatus.HEALTHY,
                        "message": "Database connection is healthy",
                        "details": {
                            "pool_size": pool_stats.get("size", 0),
                            "idle_connections": pool_stats.get("idle_size", 0)
                        }
                    }
                else:
                    return {
                        "status": HealthStatus.UNHEALTHY,
                        "message": "Database query returned unexpected result"
                    }
        
        except Exception as e:
            return {
                "status": HealthStatus.UNHEALTHY,
                "message": f"Database connection failed: {str(e)}"
            }

class RedisHealthChecker(HealthChecker):
    """Rediså¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, name: str, redis_client, timeout: float = 5.0):
        super().__init__(name, timeout)
        self.redis_client = redis_client
    
    async def _perform_check(self) -> Dict[str, Any]:
        """æ£€æŸ¥Redisè¿æ¥å’ŒåŸºæœ¬æ“ä½œ"""
        try:
            # æ‰§è¡ŒPINGå‘½ä»¤
            pong = await self.redis_client.ping()
            
            if pong:
                # è·å–Redisä¿¡æ¯
                info = await self.redis_client.info()
                
                return {
                    "status": HealthStatus.HEALTHY,
                    "message": "Redis connection is healthy",
                    "details": {
                        "connected_clients": info.get("connected_clients", 0),
                        "used_memory_human": info.get("used_memory_human", "unknown")
                    }
                }
            else:
                return {
                    "status": HealthStatus.UNHEALTHY,
                    "message": "Redis PING failed"
                }
        
        except Exception as e:
            return {
                "status": HealthStatus.UNHEALTHY,
                "message": f"Redis connection failed: {str(e)}"
            }

class ExternalServiceHealthChecker(HealthChecker):
    """å¤–éƒ¨æœåŠ¡å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, name: str, service_url: str, timeout: float = 10.0):
        super().__init__(name, timeout)
        self.service_url = service_url
    
    async def _perform_check(self) -> Dict[str, Any]:
        """æ£€æŸ¥å¤–éƒ¨æœåŠ¡å¯ç”¨æ€§"""
        import aiohttp
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
                async with session.get(f"{self.service_url}/health") as response:
                    if response.status == 200:
                        return {
                            "status": HealthStatus.HEALTHY,
                            "message": "External service is healthy",
                            "details": {
                                "status_code": response.status,
                                "response_time_ms": response.headers.get("X-Response-Time")
                            }
                        }
                    else:
                        return {
                            "status": HealthStatus.DEGRADED,
                            "message": f"External service returned status {response.status}",
                            "details": {"status_code": response.status}
                        }
        
        except Exception as e:
            return {
                "status": HealthStatus.UNHEALTHY,
                "message": f"External service check failed: {str(e)}"
            }

class HealthMonitor:
    """å¥åº·ç›‘æ§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.checkers: List[HealthChecker] = []
        self.logger = logging.getLogger("health_monitor")
        self.last_report: Optional[SystemHealthReport] = None
    
    def register_checker(self, checker: HealthChecker):
        """æ³¨å†Œå¥åº·æ£€æŸ¥å™¨"""
        self.checkers.append(checker)
        self.logger.info(f"Registered health checker: {checker.name}")
    
    async def check_all(self) -> SystemHealthReport:
        """æ‰§è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥"""
        self.logger.info("Starting comprehensive health check")
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å¥åº·æ£€æŸ¥
        check_tasks = [checker.check() for checker in self.checkers]
        results = await asyncio.gather(*check_tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        check_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # å¤„ç†æ£€æŸ¥å™¨æœ¬èº«çš„å¼‚å¸¸
                check_results.append(HealthCheckResult(
                    name=self.checkers[i].name,
                    status=HealthStatus.UNHEALTHY,
                    message=f"Health checker failed: {str(result)}",
                    duration_ms=0,
                    timestamp=datetime.utcnow()
                ))
            else:
                check_results.append(result)
        
        # è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€
        overall_status = self._calculate_overall_status(check_results)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(check_results)
        
        # åˆ›å»ºå¥åº·æŠ¥å‘Š
        report = SystemHealthReport(
            overall_status=overall_status,
            timestamp=datetime.utcnow(),
            checks=check_results,
            summary=summary
        )
        
        self.last_report = report
        self.logger.info(f"Health check completed. Overall status: {overall_status.value}")
        
        return report
    
    def _calculate_overall_status(self, results: List[HealthCheckResult]) -> HealthStatus:
        """è®¡ç®—æ•´ä½“å¥åº·çŠ¶æ€"""
        if not results:
            return HealthStatus.UNKNOWN
        
        status_counts = {
            HealthStatus.HEALTHY: 0,
            HealthStatus.DEGRADED: 0,
            HealthStatus.UNHEALTHY: 0,
            HealthStatus.UNKNOWN: 0
        }
        
        for result in results:
            status_counts[result.status] += 1
        
        total_checks = len(results)
        
        # å¦‚æœæœ‰ä»»ä½•ä¸å¥åº·çš„æœåŠ¡ï¼Œæ•´ä½“çŠ¶æ€ä¸ºä¸å¥åº·
        if status_counts[HealthStatus.UNHEALTHY] > 0:
            return HealthStatus.UNHEALTHY
        
        # å¦‚æœæœ‰é™çº§æœåŠ¡ï¼Œæ•´ä½“çŠ¶æ€ä¸ºé™çº§
        if status_counts[HealthStatus.DEGRADED] > 0:
            return HealthStatus.DEGRADED
        
        # å¦‚æœæ‰€æœ‰æœåŠ¡éƒ½å¥åº·ï¼Œæ•´ä½“çŠ¶æ€ä¸ºå¥åº·
        if status_counts[HealthStatus.HEALTHY] == total_checks:
            return HealthStatus.HEALTHY
        
        # å…¶ä»–æƒ…å†µä¸ºæœªçŸ¥
        return HealthStatus.UNKNOWN
    
    def _generate_summary(self, results: List[HealthCheckResult]) -> Dict[str, Any]:
        """ç”Ÿæˆå¥åº·æ£€æŸ¥æ‘˜è¦"""
        total_checks = len(results)
        status_counts = {
            "healthy": sum(1 for r in results if r.status == HealthStatus.HEALTHY),
            "degraded": sum(1 for r in results if r.status == HealthStatus.DEGRADED),
            "unhealthy": sum(1 for r in results if r.status == HealthStatus.UNHEALTHY),
            "unknown": sum(1 for r in results if r.status == HealthStatus.UNKNOWN)
        }
        
        avg_duration = sum(r.duration_ms for r in results) / total_checks if total_checks > 0 else 0
        
        return {
            "total_checks": total_checks,
            "status_distribution": status_counts,
            "average_duration_ms": round(avg_duration, 2),
            "failed_checks": [r.name for r in results if r.status == HealthStatus.UNHEALTHY]
        }
    
    def get_last_report(self) -> Optional[SystemHealthReport]:
        """è·å–æœ€åä¸€æ¬¡å¥åº·æ£€æŸ¥æŠ¥å‘Š"""
        return self.last_report
```

### 9.5 å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶

#### å‘Šè­¦é…ç½®

```yaml
# alerting-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: knowledge-rag-alerts
  namespace: knowledge-rag-prod
  labels:
    app: knowledge-rag
    role: alert-rules
spec:
  groups:
  - name: knowledge-rag.system
    rules:
    # ç³»ç»Ÿçº§å‘Šè­¦
    - alert: ServiceDown
      expr: up{job=~"knowledge-rag-.*"} == 0
      for: 1m
      labels:
        severity: critical
        category: system
      annotations:
        summary: "Knowledge RAG service is down"
        description: "Service {{ $labels.job }} has been down for more than 1 minute."
    
    - alert: HighErrorRate
      expr: |
        (
          rate(http_requests_total{job=~"knowledge-rag-.*",code=~"5.."}[5m]) /
          rate(http_requests_total{job=~"knowledge-rag-.*"}[5m])
        ) > 0.1
      for: 5m
      labels:
        severity: warning
        category: business
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }} for service {{ $labels.job }}."
    
    - alert: HighResponseTime
      expr: |
        histogram_quantile(0.95, 
          rate(http_request_duration_seconds_bucket{job=~"knowledge-rag-.*"}[5m])
        ) > 5
      for: 10m
      labels:
        severity: warning
        category: performance
      annotations:
        summary: "High response time detected"
        description: "95th percentile response time is {{ $value }}s for service {{ $labels.job }}."
    
    - alert: DatabaseConnectionFailure
      expr: pg_up == 0
      for: 1m
      labels:
        severity: critical
        category: system
      annotations:
        summary: "Database connection failure"
        description: "PostgreSQL database is not accessible."
    
    - alert: RedisConnectionFailure
      expr: redis_up == 0
      for: 1m
      labels:
        severity: high
        category: system
      annotations:
        summary: "Redis connection failure"
        description: "Redis cache is not accessible."
    
    - alert: HighMemoryUsage
      expr: |
        (
          container_memory_working_set_bytes{pod=~"knowledge-rag-.*"} /
          container_spec_memory_limit_bytes{pod=~"knowledge-rag-.*"}
        ) > 0.9
      for: 5m
      labels:
        severity: warning
        category: resource
      annotations:
        summary: "High memory usage"
        description: "Memory usage is {{ $value | humanizePercentage }} for pod {{ $labels.pod }}."
    
    - alert: HighCPUUsage
      expr: |
        rate(container_cpu_usage_seconds_total{pod=~"knowledge-rag-.*"}[5m]) > 0.8
      for: 10m
      labels:
        severity: warning
        category: resource
      annotations:
        summary: "High CPU usage"
        description: "CPU usage is {{ $value | humanizePercentage }} for pod {{ $labels.pod }}."
    
    - alert: LowCacheHitRate
      expr: |
        (
          rate(redis_keyspace_hits_total[5m]) /
          (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
        ) < 0.8
      for: 15m
      labels:
        severity: warning
        category: performance
      annotations:
        summary: "Low cache hit rate"
        description: "Cache hit rate is {{ $value | humanizePercentage }}."
    
    - alert: VectorSearchSlowdown
      expr: |
        histogram_quantile(0.95,
          rate(weaviate_query_duration_seconds_bucket[5m])
        ) > 2
      for: 10m
      labels:
        severity: warning
        category: performance
      annotations:
        summary: "Vector search performance degradation"
        description: "95th percentile vector search time is {{ $value }}s."
    
    - alert: DiskSpaceRunningOut
      expr: |
        (
          node_filesystem_avail_bytes{mountpoint="/"} /
          node_filesystem_size_bytes{mountpoint="/"}
        ) < 0.1
      for: 5m
      labels:
        severity: critical
        category: resource
      annotations:
        summary: "Disk space running out"
        description: "Available disk space is {{ $value | humanizePercentage }}."
```

### 9.6 é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

#### é”™è¯¯å¤„ç†æ£€æŸ¥æ¸…å•

**è®¾è®¡åŸåˆ™**
- [ ] å®æ–½ç»Ÿä¸€çš„é”™è¯¯åˆ†ç±»å’Œç¼–ç æ ‡å‡†
- [ ] å»ºç«‹æ ‡å‡†åŒ–çš„å¼‚å¸¸å¤„ç†æ¡†æ¶
- [ ] è®¾è®¡åˆç†çš„é‡è¯•å’Œç†”æ–­æœºåˆ¶
- [ ] å®ç°å…¨é¢çš„å¥åº·æ£€æŸ¥å’Œç›‘æ§
- [ ] é…ç½®åŠæ—¶çš„å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶

**å®ç°è¦æ±‚**
- [ ] æ‰€æœ‰APIéƒ½è¿”å›æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”æ ¼å¼
- [ ] å…³é”®æœåŠ¡éƒ½é…ç½®äº†ç†”æ–­å™¨ä¿æŠ¤
- [ ] å¤–éƒ¨ä¾èµ–éƒ½å®ç°äº†é‡è¯•å’Œé™çº§ç­–ç•¥
- [ ] ç³»ç»Ÿç»„ä»¶éƒ½æœ‰å¥åº·æ£€æŸ¥ç«¯ç‚¹
- [ ] é”™è¯¯æ—¥å¿—åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯

**ç›‘æ§å’Œå‘Šè­¦**
- [ ] é…ç½®äº†ç³»ç»Ÿçº§ã€ä¸šåŠ¡çº§å’Œæ€§èƒ½çº§å‘Šè­¦è§„åˆ™
- [ ] å»ºç«‹äº†å¤šæ¸ é“çš„å‘Šè­¦é€šçŸ¥æœºåˆ¶
- [ ] å®ç°äº†å‘Šè­¦çš„è‡ªåŠ¨å‡çº§å’Œé™çº§
- [ ] é…ç½®äº†å‘Šè­¦çš„æŠ‘åˆ¶å’Œé™é»˜è§„åˆ™
- [ ] å»ºç«‹äº†æ•…éšœå¤„ç†çš„æ ‡å‡†æ“ä½œç¨‹åº

**æ•…éšœæ¢å¤**
- [ ] å…³é”®æ•°æ®éƒ½æœ‰å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
- [ ] æœåŠ¡æ”¯æŒä¼˜é›…å¯åŠ¨å’Œå…³é—­
- [ ] å®ç°äº†è‡ªåŠ¨æ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡
- [ ] é…ç½®äº†æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œä¿®å¤
- [ ] å»ºç«‹äº†ç¾éš¾æ¢å¤è®¡åˆ’å’Œæ¼”ç»ƒæœºåˆ¶

---

## å¼€å‘å·¥ä½œæµç¨‹

### æ¦‚è¿°

Knowledge RAGç³»ç»Ÿé‡‡ç”¨ç°ä»£åŒ–çš„DevOpså¼€å‘å·¥ä½œæµç¨‹ï¼Œç¡®ä¿ä»£ç è´¨é‡ã€å¿«é€Ÿäº¤ä»˜å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚æœ¬ç« èŠ‚è¯¦ç»†æè¿°äº†ä»ä»£ç å¼€å‘åˆ°ç”Ÿäº§éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚

### å¼€å‘ç¯å¢ƒè®¾ç½®

#### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# ç¯å¢ƒè¦æ±‚
- Python 3.11+
- Node.js 18+
- Docker Desktop
- Kubernetes (minikube/kind)
- Git

# é¡¹ç›®åˆå§‹åŒ–
git clone <repository-url>
cd knowledge-rag

# åç«¯ç¯å¢ƒè®¾ç½®
cd backend
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync --prerelease=allow

# æ•°æ®åº“åˆå§‹åŒ–
docker-compose up -d postgres redis
alembic upgrade head

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

#### å¼€å‘å·¥å…·é…ç½®

```yaml
# .vscode/settings.json
{
  "python.defaultInterpreterPath": "./backend/venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.formatting.provider": "black",
  "python.testing.pytestEnabled": true,
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.organizeImports": true
  }
}
```

### Gitå·¥ä½œæµç¨‹

#### åˆ†æ”¯ç­–ç•¥

```
main (ç”Ÿäº§åˆ†æ”¯)
â”œâ”€â”€ develop (å¼€å‘åˆ†æ”¯)
â”‚   â”œâ”€â”€ feature/user-auth (åŠŸèƒ½åˆ†æ”¯)
â”‚   â”œâ”€â”€ feature/document-parsing (åŠŸèƒ½åˆ†æ”¯)
â”‚   â””â”€â”€ feature/rag-engine (åŠŸèƒ½åˆ†æ”¯)
â”œâ”€â”€ release/v1.0.0 (å‘å¸ƒåˆ†æ”¯)
â””â”€â”€ hotfix/critical-bug (çƒ­ä¿®å¤åˆ†æ”¯)
```

#### æäº¤è§„èŒƒ

```bash
# æäº¤æ¶ˆæ¯æ ¼å¼
<type>(<scope>): <subject>

<body>

<footer>

# ç¤ºä¾‹
feat(auth): add JWT token validation middleware

- Implement JWT token validation
- Add token expiration check
- Handle invalid token scenarios

Closes #123
```

#### ä»£ç å®¡æŸ¥æµç¨‹

```yaml
# .github/pull_request_template.md
## å˜æ›´æè¿°
- [ ] åŠŸèƒ½å®ç°
- [ ] Bugä¿®å¤
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] æ–‡æ¡£æ›´æ–°

## æµ‹è¯•æ¸…å•
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] æ‰‹åŠ¨æµ‹è¯•å®Œæˆ
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡

## éƒ¨ç½²æ¸…å•
- [ ] æ•°æ®åº“è¿ç§»è„šæœ¬
- [ ] é…ç½®æ–‡ä»¶æ›´æ–°
- [ ] ç¯å¢ƒå˜é‡å˜æ›´
- [ ] ä¾èµ–åŒ…æ›´æ–°
```

### ä»£ç è´¨é‡ä¿è¯

#### é™æ€ä»£ç åˆ†æ

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: ["--max-line-length=88"]

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.3.0
    hooks:
      - id: mypy
        additional_dependencies: [types-requests]
```

#### ä»£ç è¦†ç›–ç‡è¦æ±‚

```python
# pytest.ini
[tool:pytest]
addopts = 
    --cov=src
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
    --strict-markers
    --disable-warnings

markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    slow: Slow running tests
```

### æµ‹è¯•ç­–ç•¥

#### æµ‹è¯•é‡‘å­—å¡”

```
        E2E Tests (10%)
       /              \
    Integration Tests (20%)
   /                      \
  Unit Tests (70%)
```

#### å•å…ƒæµ‹è¯•

```python
# tests/unit/test_document_service.py
import pytest
from unittest.mock import Mock, patch
from src.services.document_service import DocumentService

class TestDocumentService:
    """æ–‡æ¡£æœåŠ¡å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def document_service(self):
        """åˆ›å»ºæ–‡æ¡£æœåŠ¡å®ä¾‹"""
        return DocumentService()
    
    @patch('src.services.document_service.extract_text')
    def test_parse_pdf_document(self, mock_extract, document_service):
        """æµ‹è¯•PDFæ–‡æ¡£è§£æ"""
        # Arrange
        mock_extract.return_value = "Test content"
        file_path = "/path/to/test.pdf"
        
        # Act
        result = document_service.parse_document(file_path)
        
        # Assert
        assert result.content == "Test content"
        assert result.file_type == "pdf"
        mock_extract.assert_called_once_with(file_path)
```

#### é›†æˆæµ‹è¯•

```python
# tests/integration/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient
from src.main import app

class TestDocumentAPI:
    """æ–‡æ¡£APIé›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def client(self):
        """åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯"""
        return TestClient(app)
    
    def test_upload_document_success(self, client):
        """æµ‹è¯•æ–‡æ¡£ä¸Šä¼ æˆåŠŸåœºæ™¯"""
        with open("tests/fixtures/sample.pdf", "rb") as f:
            response = client.post(
                "/api/v1/documents/upload",
                files={"file": ("sample.pdf", f, "application/pdf")}
            )
        
        assert response.status_code == 201
        assert "document_id" in response.json()
```

#### E2Eæµ‹è¯•

```python
# tests/e2e/test_rag_workflow.py
import pytest
from playwright.sync_api import sync_playwright

class TestRAGWorkflow:
    """RAGå·¥ä½œæµç¨‹ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def test_complete_rag_workflow(self):
        """æµ‹è¯•å®Œæ•´çš„RAGå·¥ä½œæµç¨‹"""
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            
            # 1. ä¸Šä¼ æ–‡æ¡£
            page.goto("http://localhost:3000/upload")
            page.set_input_files("input[type=file]", "tests/fixtures/sample.pdf")
            page.click("button[type=submit]")
            
            # 2. ç­‰å¾…å¤„ç†å®Œæˆ
            page.wait_for_selector(".upload-success")
            
            # 3. æ‰§è¡ŒæŸ¥è¯¢
            page.goto("http://localhost:3000/chat")
            page.fill("textarea[name=question]", "What is the main topic?")
            page.click("button[type=submit]")
            
            # 4. éªŒè¯ç»“æœ
            response = page.wait_for_selector(".chat-response")
            assert len(response.text_content()) > 0
            
            browser.close()
```

### CI/CDæµæ°´çº¿

#### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        cd backend
        uv sync --prerelease=allow
    
    - name: Run linting
      run: |
        flake8 backend/src
        black --check backend/src
        isort --check-only backend/src
    
    - name: Run type checking
      run: mypy backend/src
    
    - name: Run tests
      run: |
        cd backend
        pytest tests/ -v --cov=src --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t knowledge-rag:${{ github.sha }} .
        docker tag knowledge-rag:${{ github.sha }} knowledge-rag:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push knowledge-rag:${{ github.sha }}
        docker push knowledge-rag:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to staging
      run: |
        kubectl set image deployment/knowledge-rag knowledge-rag=knowledge-rag:${{ github.sha }}
        kubectl rollout status deployment/knowledge-rag
```

### å‘å¸ƒç®¡ç†

#### ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥

```bash
# è¯­ä¹‰åŒ–ç‰ˆæœ¬æ§åˆ¶
MAJOR.MINOR.PATCH

# ç¤ºä¾‹
v1.0.0 - åˆå§‹å‘å¸ƒ
v1.0.1 - è¡¥ä¸ç‰ˆæœ¬ï¼ˆBugä¿®å¤ï¼‰
v1.1.0 - æ¬¡è¦ç‰ˆæœ¬ï¼ˆæ–°åŠŸèƒ½ï¼‰
v2.0.0 - ä¸»è¦ç‰ˆæœ¬ï¼ˆç ´åæ€§å˜æ›´ï¼‰
```

#### å‘å¸ƒæµç¨‹

```yaml
# .github/workflows/release.yml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  release:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Create Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false
    
    - name: Deploy to production
      run: |
        helm upgrade --install knowledge-rag ./helm/knowledge-rag \
          --namespace production \
          --set image.tag=${{ github.ref_name }} \
          --set environment=production
```

### ç¯å¢ƒç®¡ç†

#### ç¯å¢ƒé…ç½®

```yaml
# environments/development.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: development
data:
  DATABASE_URL: "postgresql://user:pass@postgres:5432/knowledge_rag_dev"
  REDIS_URL: "redis://redis:6379/0"
  LOG_LEVEL: "DEBUG"
  ENVIRONMENT: "development"

---
# environments/staging.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: staging
data:
  DATABASE_URL: "postgresql://user:pass@postgres:5432/knowledge_rag_staging"
  REDIS_URL: "redis://redis:6379/1"
  LOG_LEVEL: "INFO"
  ENVIRONMENT: "staging"

---
# environments/production.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
data:
  DATABASE_URL: "postgresql://user:pass@postgres:5432/knowledge_rag_prod"
  REDIS_URL: "redis://redis:6379/2"
  LOG_LEVEL: "WARNING"
  ENVIRONMENT: "production"
```

### æ•°æ®åº“è¿ç§»ç®¡ç†

#### Alembicé…ç½®

```python
# alembic/versions/001_initial_schema.py
"""Initial schema

Revision ID: 001
Revises: 
Create Date: 2024-01-01 10:00:00.000000

"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    """åˆ›å»ºåˆå§‹æ•°æ®åº“æ¶æ„"""
    op.create_table(
        'documents',
        sa.Column('id', sa.UUID(), nullable=False),
        sa.Column('title', sa.String(255), nullable=False),
        sa.Column('content', sa.Text(), nullable=True),
        sa.Column('file_path', sa.String(500), nullable=False),
        sa.Column('file_type', sa.String(50), nullable=False),
        sa.Column('file_size', sa.BigInteger(), nullable=False),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint('id')
    )
    
    op.create_index('idx_documents_created_at', 'documents', ['created_at'])
    op.create_index('idx_documents_file_type', 'documents', ['file_type'])

def downgrade():
    """å›æ»šæ•°æ®åº“æ¶æ„"""
    op.drop_index('idx_documents_file_type')
    op.drop_index('idx_documents_created_at')
    op.drop_table('documents')
```

#### è¿ç§»è„šæœ¬

```bash
#!/bin/bash
# scripts/migrate.sh

set -e

ENVIRONMENT=${1:-development}

echo "Running database migrations for $ENVIRONMENT environment..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export ENVIRONMENT=$ENVIRONMENT

# è¿è¡Œè¿ç§»
alembic upgrade head

echo "Database migration completed successfully!"
```

### ç›‘æ§å’Œæ—¥å¿—

#### åº”ç”¨ç›‘æ§

```python
# src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time
from functools import wraps

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

ACTIVE_CONNECTIONS = Gauge(
    'active_connections',
    'Active database connections'
)

def monitor_endpoint(func):
    """ç«¯ç‚¹ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            REQUEST_COUNT.labels(
                method='POST',
                endpoint=func.__name__,
                status='success'
            ).inc()
            return result
        except Exception as e:
            REQUEST_COUNT.labels(
                method='POST',
                endpoint=func.__name__,
                status='error'
            ).inc()
            raise
        finally:
            REQUEST_DURATION.labels(
                method='POST',
                endpoint=func.__name__
            ).observe(time.time() - start_time)
    
    return wrapper
```

### å¼€å‘å·¥ä½œæµç¨‹æœ€ä½³å®è·µ

#### ä»£ç å¼€å‘è§„èŒƒ

1. **åŠŸèƒ½å¼€å‘æµç¨‹**
   - ä»developåˆ†æ”¯åˆ›å»ºfeatureåˆ†æ”¯
   - éµå¾ªTDDï¼ˆæµ‹è¯•é©±åŠ¨å¼€å‘ï¼‰åŸåˆ™
   - ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
   - ä»£ç å®¡æŸ¥é€šè¿‡ååˆå¹¶åˆ°develop

2. **Bugä¿®å¤æµç¨‹**
   - åˆ›å»ºbugå¤ç°æµ‹è¯•ç”¨ä¾‹
   - ä¿®å¤bugå¹¶ç¡®ä¿æµ‹è¯•é€šè¿‡
   - æ›´æ–°ç›¸å…³æ–‡æ¡£
   - é€šè¿‡ä»£ç å®¡æŸ¥ååˆå¹¶

3. **å‘å¸ƒå‡†å¤‡æµç¨‹**
   - ä»developåˆ›å»ºreleaseåˆ†æ”¯
   - æ‰§è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
   - æ›´æ–°ç‰ˆæœ¬å·å’Œå˜æ›´æ—¥å¿—
   - éƒ¨ç½²åˆ°stagingç¯å¢ƒéªŒè¯
   - åˆå¹¶åˆ°mainåˆ†æ”¯å¹¶æ‰“æ ‡ç­¾

#### è´¨é‡ä¿è¯æ£€æŸ¥æ¸…å•

- [ ] **ä»£ç è´¨é‡**
  - [ ] é™æ€ä»£ç åˆ†æé€šè¿‡
  - [ ] ä»£ç è¦†ç›–ç‡è¾¾åˆ°80%ä»¥ä¸Š
  - [ ] æ— å®‰å…¨æ¼æ´
  - [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡

- [ ] **æµ‹è¯•å®Œæ•´æ€§**
  - [ ] å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒé€»è¾‘
  - [ ] é›†æˆæµ‹è¯•è¦†ç›–APIç«¯ç‚¹
  - [ ] E2Eæµ‹è¯•è¦†ç›–å…³é”®ç”¨æˆ·æµç¨‹
  - [ ] è´Ÿè½½æµ‹è¯•éªŒè¯æ€§èƒ½æŒ‡æ ‡

- [ ] **éƒ¨ç½²å‡†å¤‡**
  - [ ] æ•°æ®åº“è¿ç§»è„šæœ¬å‡†å¤‡
  - [ ] é…ç½®æ–‡ä»¶æ›´æ–°
  - [ ] ç›‘æ§å‘Šè­¦é…ç½®
  - [ ] å›æ»šè®¡åˆ’åˆ¶å®š

- [ ] **æ–‡æ¡£æ›´æ–°**
  - [ ] APIæ–‡æ¡£æ›´æ–°
  - [ ] éƒ¨ç½²æ–‡æ¡£æ›´æ–°
  - [ ] ç”¨æˆ·æ‰‹å†Œæ›´æ–°
  - [ ] å˜æ›´æ—¥å¿—è®°å½•

---

## å¤šç¯å¢ƒç®¡ç†

### æ¦‚è¿°

Knowledge RAGç³»ç»Ÿé‡‡ç”¨å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥ï¼Œç¡®ä¿å¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒçš„éš”ç¦»æ€§å’Œä¸€è‡´æ€§ã€‚æœ¬ç« èŠ‚è¯¦ç»†æè¿°äº†å¤šç¯å¢ƒé…ç½®ç®¡ç†ã€éƒ¨ç½²ç­–ç•¥å’Œç¯å¢ƒé—´çš„æ•°æ®åŒæ­¥æœºåˆ¶ã€‚

### ç¯å¢ƒæ¶æ„è®¾è®¡

#### ç¯å¢ƒåˆ†å±‚ç­–ç•¥

```
ç”Ÿäº§ç¯å¢ƒ (Production)
    â†‘ å‘å¸ƒéƒ¨ç½²
é¢„ç”Ÿäº§ç¯å¢ƒ (Staging)
    â†‘ é›†æˆæµ‹è¯•
æµ‹è¯•ç¯å¢ƒ (Testing)
    â†‘ åŠŸèƒ½æµ‹è¯•
å¼€å‘ç¯å¢ƒ (Development)
    â†‘ æ—¥å¸¸å¼€å‘
æœ¬åœ°ç¯å¢ƒ (Local)
```

#### ç¯å¢ƒç‰¹æ€§å¯¹æ¯”

| ç¯å¢ƒç±»å‹ | ç”¨é€” | æ•°æ®æ¥æº | è®¿é—®æƒé™ | ç›‘æ§çº§åˆ« | å¤‡ä»½ç­–ç•¥ |
|---------|------|----------|----------|----------|----------|
| Local | æœ¬åœ°å¼€å‘ | æ¨¡æ‹Ÿæ•°æ® | å¼€å‘è€… | åŸºç¡€ | æ—  |
| Development | åŠŸèƒ½å¼€å‘ | æµ‹è¯•æ•°æ® | å¼€å‘å›¢é˜Ÿ | æ ‡å‡† | æ¯æ—¥ |
| Testing | é›†æˆæµ‹è¯• | æµ‹è¯•æ•°æ® | QAå›¢é˜Ÿ | æ ‡å‡† | æ¯æ—¥ |
| Staging | é¢„ç”Ÿäº§éªŒè¯ | ç”Ÿäº§å‰¯æœ¬ | æ ¸å¿ƒå›¢é˜Ÿ | å®Œæ•´ | å®æ—¶ |
| Production | ç”Ÿäº§æœåŠ¡ | çœŸå®æ•°æ® | è¿ç»´å›¢é˜Ÿ | å®Œæ•´ | å®æ—¶+å½’æ¡£ |

### ç¯å¢ƒé…ç½®ç®¡ç†

#### Kuberneteså‘½åç©ºé—´è®¾è®¡

```yaml
# namespaces/environments.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-local
  labels:
    environment: local
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-dev
  labels:
    environment: development
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-test
  labels:
    environment: testing
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-staging
  labels:
    environment: staging
    project: knowledge-rag
---
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-rag-prod
  labels:
    environment: production
    project: knowledge-rag
```

#### ç¯å¢ƒé…ç½®æ–‡ä»¶

```yaml
# config/environments/local.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: knowledge-rag-local
data:
  # åº”ç”¨é…ç½®
  APP_NAME: "Knowledge RAG Local"
  APP_VERSION: "dev"
  DEBUG: "true"
  LOG_LEVEL: "DEBUG"
  
  # æ•°æ®åº“é…ç½®
  DATABASE_URL: "postgresql://postgres:password@localhost:5432/knowledge_rag_local"
  DATABASE_POOL_SIZE: "5"
  DATABASE_MAX_OVERFLOW: "10"
  
  # Redisé…ç½®
  REDIS_URL: "redis://localhost:6379/0"
  REDIS_MAX_CONNECTIONS: "10"
  
  # å‘é‡æ•°æ®åº“é…ç½®
  WEAVIATE_URL: "http://localhost:8080"
  WEAVIATE_API_KEY: "local-dev-key"
  
  # LLMé…ç½®
  OPENAI_API_KEY: "sk-local-test-key"
  OPENAI_MODEL: "gpt-3.5-turbo"
  OPENAI_MAX_TOKENS: "1000"
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®
  STORAGE_TYPE: "local"
  STORAGE_PATH: "/tmp/knowledge-rag/uploads"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "false"
  TRACING_ENABLED: "false"

---
# config/environments/development.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: knowledge-rag-dev
data:
  # åº”ç”¨é…ç½®
  APP_NAME: "Knowledge RAG Development"
  APP_VERSION: "dev"
  DEBUG: "true"
  LOG_LEVEL: "DEBUG"
  
  # æ•°æ®åº“é…ç½®
  DATABASE_URL: "postgresql://dev_user:dev_pass@postgres-dev:5432/knowledge_rag_dev"
  DATABASE_POOL_SIZE: "10"
  DATABASE_MAX_OVERFLOW: "20"
  
  # Redisé…ç½®
  REDIS_URL: "redis://redis-dev:6379/0"
  REDIS_MAX_CONNECTIONS: "20"
  
  # å‘é‡æ•°æ®åº“é…ç½®
  WEAVIATE_URL: "http://weaviate-dev:8080"
  WEAVIATE_API_KEY: "dev-environment-key"
  
  # LLMé…ç½®
  OPENAI_API_KEY: "sk-dev-test-key"
  OPENAI_MODEL: "gpt-3.5-turbo"
  OPENAI_MAX_TOKENS: "2000"
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®
  STORAGE_TYPE: "minio"
  MINIO_ENDPOINT: "minio-dev:9000"
  MINIO_BUCKET: "knowledge-rag-dev"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "true"
  TRACING_ENABLED: "true"
  JAEGER_ENDPOINT: "http://jaeger-dev:14268"

---
# config/environments/testing.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: knowledge-rag-test
data:
  # åº”ç”¨é…ç½®
  APP_NAME: "Knowledge RAG Testing"
  APP_VERSION: "test"
  DEBUG: "false"
  LOG_LEVEL: "INFO"
  
  # æ•°æ®åº“é…ç½®
  DATABASE_URL: "postgresql://test_user:test_pass@postgres-test:5432/knowledge_rag_test"
  DATABASE_POOL_SIZE: "15"
  DATABASE_MAX_OVERFLOW: "30"
  
  # Redisé…ç½®
  REDIS_URL: "redis://redis-test:6379/0"
  REDIS_MAX_CONNECTIONS: "30"
  
  # å‘é‡æ•°æ®åº“é…ç½®
  WEAVIATE_URL: "http://weaviate-test:8080"
  WEAVIATE_API_KEY: "test-environment-key"
  
  # LLMé…ç½®
  OPENAI_API_KEY: "sk-test-environment-key"
  OPENAI_MODEL: "gpt-4"
  OPENAI_MAX_TOKENS: "3000"
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®
  STORAGE_TYPE: "minio"
  MINIO_ENDPOINT: "minio-test:9000"
  MINIO_BUCKET: "knowledge-rag-test"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "true"
  TRACING_ENABLED: "true"
  JAEGER_ENDPOINT: "http://jaeger-test:14268"

---
# config/environments/staging.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: knowledge-rag-staging
data:
  # åº”ç”¨é…ç½®
  APP_NAME: "Knowledge RAG Staging"
  APP_VERSION: "staging"
  DEBUG: "false"
  LOG_LEVEL: "INFO"
  
  # æ•°æ®åº“é…ç½®
  DATABASE_URL: "postgresql://staging_user:staging_pass@postgres-staging:5432/knowledge_rag_staging"
  DATABASE_POOL_SIZE: "20"
  DATABASE_MAX_OVERFLOW: "40"
  
  # Redisé…ç½®
  REDIS_URL: "redis://redis-staging:6379/0"
  REDIS_MAX_CONNECTIONS: "40"
  
  # å‘é‡æ•°æ®åº“é…ç½®
  WEAVIATE_URL: "http://weaviate-staging:8080"
  WEAVIATE_API_KEY: "staging-environment-key"
  
  # LLMé…ç½®
  OPENAI_API_KEY: "sk-staging-environment-key"
  OPENAI_MODEL: "gpt-4"
  OPENAI_MAX_TOKENS: "4000"
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®
  STORAGE_TYPE: "s3"
  AWS_S3_BUCKET: "knowledge-rag-staging"
  AWS_REGION: "us-west-2"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "true"
  TRACING_ENABLED: "true"
  JAEGER_ENDPOINT: "http://jaeger-staging:14268"

---
# config/environments/production.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: knowledge-rag-prod
data:
  # åº”ç”¨é…ç½®
  APP_NAME: "Knowledge RAG Production"
  APP_VERSION: "v1.0.0"
  DEBUG: "false"
  LOG_LEVEL: "WARNING"
  
  # æ•°æ®åº“é…ç½®
  DATABASE_URL: "postgresql://prod_user:prod_pass@postgres-prod:5432/knowledge_rag_prod"
  DATABASE_POOL_SIZE: "50"
  DATABASE_MAX_OVERFLOW: "100"
  
  # Redisé…ç½®
  REDIS_URL: "redis://redis-prod:6379/0"
  REDIS_MAX_CONNECTIONS: "100"
  
  # å‘é‡æ•°æ®åº“é…ç½®
  WEAVIATE_URL: "http://weaviate-prod:8080"
  WEAVIATE_API_KEY: "production-environment-key"
  
  # LLMé…ç½®
  OPENAI_API_KEY: "sk-production-environment-key"
  OPENAI_MODEL: "gpt-4"
  OPENAI_MAX_TOKENS: "4000"
  
  # æ–‡ä»¶å­˜å‚¨é…ç½®
  STORAGE_TYPE: "s3"
  AWS_S3_BUCKET: "knowledge-rag-production"
  AWS_REGION: "us-west-2"
  
  # ç›‘æ§é…ç½®
  METRICS_ENABLED: "true"
  TRACING_ENABLED: "true"
  JAEGER_ENDPOINT: "http://jaeger-prod:14268"
```

### å¯†é’¥ç®¡ç†

#### Kubernetes Secrets

```yaml
# secrets/database-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: database-secrets
  namespace: knowledge-rag-dev
type: Opaque
data:
  username: ZGV2X3VzZXI=  # base64 encoded
  password: ZGV2X3Bhc3M=  # base64 encoded

---
apiVersion: v1
kind: Secret
metadata:
  name: database-secrets
  namespace: knowledge-rag-prod
type: Opaque
data:
  username: cHJvZF91c2Vy  # base64 encoded
  password: cHJvZF9wYXNz  # base64 encoded

---
# secrets/api-keys.yaml
apiVersion: v1
kind: Secret
metadata:
  name: api-keys
  namespace: knowledge-rag-dev
type: Opaque
data:
  openai-api-key: c2stZGV2LXRlc3Qta2V5  # base64 encoded
  weaviate-api-key: ZGV2LWVudmlyb25tZW50LWtleQ==  # base64 encoded

---
apiVersion: v1
kind: Secret
metadata:
  name: api-keys
  namespace: knowledge-rag-prod
type: Opaque
data:
  openai-api-key: c2stcHJvZHVjdGlvbi1lbnZpcm9ubWVudC1rZXk=  # base64 encoded
  weaviate-api-key: cHJvZHVjdGlvbi1lbnZpcm9ubWVudC1rZXk=  # base64 encoded
```

#### å¤–éƒ¨å¯†é’¥ç®¡ç†é›†æˆ

```yaml
# external-secrets/vault-integration.yaml
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: vault-backend
  namespace: knowledge-rag-prod
spec:
  provider:
    vault:
      server: "https://vault.company.com"
      path: "secret"
      version: "v2"
      auth:
        kubernetes:
          mountPath: "kubernetes"
          role: "knowledge-rag-prod"

---
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: database-credentials
  namespace: knowledge-rag-prod
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: vault-backend
    kind: SecretStore
  target:
    name: database-secrets
    creationPolicy: Owner
  data:
  - secretKey: username
    remoteRef:
      key: knowledge-rag/database
      property: username
  - secretKey: password
    remoteRef:
      key: knowledge-rag/database
      property: password
```

### éƒ¨ç½²é…ç½®

#### Helm Valuesæ–‡ä»¶

```yaml
# helm/values-dev.yaml
replicaCount: 1

image:
  repository: knowledge-rag
  tag: "dev"
  pullPolicy: Always

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  hosts:
    - host: knowledge-rag-dev.company.com
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 250m
    memory: 512Mi

autoscaling:
  enabled: false

environment: development

database:
  host: postgres-dev
  port: 5432
  name: knowledge_rag_dev

redis:
  host: redis-dev
  port: 6379

weaviate:
  host: weaviate-dev
  port: 8080

monitoring:
  enabled: true
  serviceMonitor:
    enabled: true

---
# helm/values-staging.yaml
replicaCount: 2

image:
  repository: knowledge-rag
  tag: "staging"
  pullPolicy: Always

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: knowledge-rag-staging.company.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: knowledge-rag-staging-tls
      hosts:
        - knowledge-rag-staging.company.com

resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70

environment: staging

database:
  host: postgres-staging
  port: 5432
  name: knowledge_rag_staging

redis:
  host: redis-staging
  port: 6379

weaviate:
  host: weaviate-staging
  port: 8080

monitoring:
  enabled: true
  serviceMonitor:
    enabled: true

---
# helm/values-prod.yaml
replicaCount: 3

image:
  repository: knowledge-rag
  tag: "v1.0.0"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/rate-limit: "100"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: api.knowledge-rag.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: knowledge-rag-prod-tls
      hosts:
        - api.knowledge-rag.com

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 1000m
    memory: 2Gi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 60
  targetMemoryUtilizationPercentage: 70

environment: production

database:
  host: postgres-prod
  port: 5432
  name: knowledge_rag_prod

redis:
  host: redis-prod
  port: 6379

weaviate:
  host: weaviate-prod
  port: 8080

monitoring:
  enabled: true
  serviceMonitor:
    enabled: true

security:
  podSecurityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 2000
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
      - ALL
```

### ç¯å¢ƒéƒ¨ç½²æµæ°´çº¿

#### GitLab CI/CDé…ç½®

```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - deploy-dev
  - deploy-test
  - deploy-staging
  - deploy-prod

variables:
  DOCKER_REGISTRY: registry.company.com
  PROJECT_NAME: knowledge-rag

build:
  stage: build
  script:
    - docker build -t $DOCKER_REGISTRY/$PROJECT_NAME:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/$PROJECT_NAME:$CI_COMMIT_SHA
  only:
    - develop
    - main

test:
  stage: test
  script:
    - pytest tests/ --cov=src --cov-report=xml
    - sonar-scanner
  coverage: '/TOTAL.+ ([0-9]{1,3}%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

deploy-dev:
  stage: deploy-dev
  script:
    - helm upgrade --install knowledge-rag-dev ./helm/knowledge-rag \
        --namespace knowledge-rag-dev \
        --values helm/values-dev.yaml \
        --set image.tag=$CI_COMMIT_SHA
  environment:
    name: development
    url: https://knowledge-rag-dev.company.com
  only:
    - develop

deploy-test:
  stage: deploy-test
  script:
    - helm upgrade --install knowledge-rag-test ./helm/knowledge-rag \
        --namespace knowledge-rag-test \
        --values helm/values-test.yaml \
        --set image.tag=$CI_COMMIT_SHA
  environment:
    name: testing
    url: https://knowledge-rag-test.company.com
  when: manual
  only:
    - develop

deploy-staging:
  stage: deploy-staging
  script:
    - helm upgrade --install knowledge-rag-staging ./helm/knowledge-rag \
        --namespace knowledge-rag-staging \
        --values helm/values-staging.yaml \
        --set image.tag=$CI_COMMIT_SHA
  environment:
    name: staging
    url: https://knowledge-rag-staging.company.com
  when: manual
  only:
    - main

deploy-prod:
  stage: deploy-prod
  script:
    - helm upgrade --install knowledge-rag-prod ./helm/knowledge-rag \
        --namespace knowledge-rag-prod \
        --values helm/values-prod.yaml \
        --set image.tag=$CI_COMMIT_TAG
  environment:
    name: production
    url: https://api.knowledge-rag.com
  when: manual
  only:
    - tags
```

### æ•°æ®ç®¡ç†ç­–ç•¥

#### æ•°æ®åŒæ­¥è„šæœ¬

```python
#!/usr/bin/env python3
# scripts/data_sync.py
"""
å¤šç¯å¢ƒæ•°æ®åŒæ­¥è„šæœ¬
ç”¨äºåœ¨ä¸åŒç¯å¢ƒé—´åŒæ­¥æµ‹è¯•æ•°æ®å’Œé…ç½®
"""

import os
import sys
import argparse
import subprocess
from typing import Dict, List
from datetime import datetime

class EnvironmentDataSync:
    """ç¯å¢ƒæ•°æ®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®åŒæ­¥ç®¡ç†å™¨"""
        self.environments = {
            'local': {
                'db_host': 'localhost',
                'db_port': '5432',
                'db_name': 'knowledge_rag_local',
                'namespace': 'knowledge-rag-local'
            },
            'dev': {
                'db_host': 'postgres-dev',
                'db_port': '5432',
                'db_name': 'knowledge_rag_dev',
                'namespace': 'knowledge-rag-dev'
            },
            'test': {
                'db_host': 'postgres-test',
                'db_port': '5432',
                'db_name': 'knowledge_rag_test',
                'namespace': 'knowledge-rag-test'
            },
            'staging': {
                'db_host': 'postgres-staging',
                'db_port': '5432',
                'db_name': 'knowledge_rag_staging',
                'namespace': 'knowledge-rag-staging'
            }
        }
    
    def sync_database_schema(self, source_env: str, target_env: str) -> bool:
        """åŒæ­¥æ•°æ®åº“æ¶æ„"""
        try:
            print(f"Syncing database schema from {source_env} to {target_env}...")
            
            source_config = self.environments[source_env]
            target_config = self.environments[target_env]
            
            # å¯¼å‡ºæºç¯å¢ƒæ¶æ„
            dump_cmd = [
                'pg_dump',
                '-h', source_config['db_host'],
                '-p', source_config['db_port'],
                '-d', source_config['db_name'],
                '--schema-only',
                '-f', f'/tmp/{source_env}_schema.sql'
            ]
            
            subprocess.run(dump_cmd, check=True)
            
            # å¯¼å…¥åˆ°ç›®æ ‡ç¯å¢ƒ
            restore_cmd = [
                'psql',
                '-h', target_config['db_host'],
                '-p', target_config['db_port'],
                '-d', target_config['db_name'],
                '-f', f'/tmp/{source_env}_schema.sql'
            ]
            
            subprocess.run(restore_cmd, check=True)
            
            print(f"Schema sync completed: {source_env} -> {target_env}")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"Error syncing schema: {e}")
            return False
    
    def sync_test_data(self, source_env: str, target_env: str, tables: List[str] = None) -> bool:
        """åŒæ­¥æµ‹è¯•æ•°æ®"""
        try:
            print(f"Syncing test data from {source_env} to {target_env}...")
            
            source_config = self.environments[source_env]
            target_config = self.environments[target_env]
            
            # é»˜è®¤åŒæ­¥çš„è¡¨
            if tables is None:
                tables = ['users', 'documents', 'knowledge_graphs']
            
            for table in tables:
                print(f"Syncing table: {table}")
                
                # å¯¼å‡ºè¡¨æ•°æ®
                dump_cmd = [
                    'pg_dump',
                    '-h', source_config['db_host'],
                    '-p', source_config['db_port'],
                    '-d', source_config['db_name'],
                    '--data-only',
                    '--table', table,
                    '-f', f'/tmp/{table}_data.sql'
                ]
                
                subprocess.run(dump_cmd, check=True)
                
                # æ¸…ç©ºç›®æ ‡è¡¨
                truncate_cmd = [
                    'psql',
                    '-h', target_config['db_host'],
                    '-p', target_config['db_port'],
                    '-d', target_config['db_name'],
                    '-c', f'TRUNCATE TABLE {table} CASCADE;'
                ]
                
                subprocess.run(truncate_cmd, check=True)
                
                # å¯¼å…¥æ•°æ®
                restore_cmd = [
                    'psql',
                    '-h', target_config['db_host'],
                    '-p', target_config['db_port'],
                    '-d', target_config['db_name'],
                    '-f', f'/tmp/{table}_data.sql'
                ]
                
                subprocess.run(restore_cmd, check=True)
            
            print(f"Data sync completed: {source_env} -> {target_env}")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"Error syncing data: {e}")
            return False
    
    def sync_config_maps(self, source_env: str, target_env: str) -> bool:
        """åŒæ­¥Kubernetes ConfigMaps"""
        try:
            print(f"Syncing ConfigMaps from {source_env} to {target_env}...")
            
            source_namespace = self.environments[source_env]['namespace']
            target_namespace = self.environments[target_env]['namespace']
            
            # å¯¼å‡ºConfigMap
            export_cmd = [
                'kubectl', 'get', 'configmap', 'app-config',
                '-n', source_namespace,
                '-o', 'yaml',
                '--export'
            ]
            
            result = subprocess.run(export_cmd, capture_output=True, text=True, check=True)
            
            # ä¿®æ”¹namespace
            config_yaml = result.stdout.replace(
                f'namespace: {source_namespace}',
                f'namespace: {target_namespace}'
            )
            
            # åº”ç”¨åˆ°ç›®æ ‡ç¯å¢ƒ
            apply_cmd = ['kubectl', 'apply', '-f', '-']
            subprocess.run(apply_cmd, input=config_yaml, text=True, check=True)
            
            print(f"ConfigMap sync completed: {source_env} -> {target_env}")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"Error syncing ConfigMaps: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Environment Data Sync Tool')
    parser.add_argument('--source', required=True, choices=['local', 'dev', 'test', 'staging'],
                       help='Source environment')
    parser.add_argument('--target', required=True, choices=['local', 'dev', 'test', 'staging'],
                       help='Target environment')
    parser.add_argument('--sync-type', choices=['schema', 'data', 'config', 'all'], default='all',
                       help='Type of sync to perform')
    parser.add_argument('--tables', nargs='*', help='Specific tables to sync (for data sync)')
    
    args = parser.parse_args()
    
    if args.source == args.target:
        print("Error: Source and target environments cannot be the same")
        sys.exit(1)
    
    sync_manager = EnvironmentDataSync()
    
    success = True
    
    if args.sync_type in ['schema', 'all']:
        success &= sync_manager.sync_database_schema(args.source, args.target)
    
    if args.sync_type in ['data', 'all']:
        success &= sync_manager.sync_test_data(args.source, args.target, args.tables)
    
    if args.sync_type in ['config', 'all']:
        success &= sync_manager.sync_config_maps(args.source, args.target)
    
    if success:
        print("\nSync completed successfully!")
        sys.exit(0)
    else:
        print("\nSync failed!")
        sys.exit(1)

if __name__ == '__main__':
    main()
```

### ç¯å¢ƒç›‘æ§å’Œå‘Šè­¦

#### ç¯å¢ƒç‰¹å®šç›‘æ§é…ç½®

```yaml
# monitoring/environment-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: environment-specific-alerts
  namespace: knowledge-rag-prod
spec:
  groups:
  - name: production.rules
    rules:
    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
        environment: production
      annotations:
        summary: "High error rate in production"
        description: "Error rate is {{ $value }} errors per second"
    
    - alert: HighMemoryUsage
      expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.8
      for: 10m
      labels:
        severity: warning
        environment: production
      annotations:
        summary: "High memory usage in production"
        description: "Memory usage is {{ $value | humanizePercentage }}"

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: environment-specific-alerts
  namespace: knowledge-rag-dev
spec:
  groups:
  - name: development.rules
    rules:
    - alert: ServiceDown
      expr: up == 0
      for: 15m
      labels:
        severity: warning
        environment: development
      annotations:
        summary: "Service down in development"
        description: "Service {{ $labels.instance }} has been down for more than 15 minutes"
```

### ç¯å¢ƒç®¡ç†æœ€ä½³å®è·µ

#### ç¯å¢ƒä¸€è‡´æ€§æ£€æŸ¥

```bash
#!/bin/bash
# scripts/environment_check.sh

# ç¯å¢ƒä¸€è‡´æ€§æ£€æŸ¥è„šæœ¬
# éªŒè¯ä¸åŒç¯å¢ƒé—´çš„é…ç½®ä¸€è‡´æ€§

set -e

ENVIRONMENTS=("dev" "test" "staging" "prod")
CHECK_ITEMS=("configmaps" "secrets" "deployments" "services")

echo "Starting environment consistency check..."

for item in "${CHECK_ITEMS[@]}"; do
    echo "\nChecking $item across environments:"
    
    for env in "${ENVIRONMENTS[@]}"; do
        namespace="knowledge-rag-$env"
        
        case $item in
            "configmaps")
                kubectl get configmap app-config -n $namespace -o yaml > /tmp/${env}_configmap.yaml
                ;;
            "secrets")
                kubectl get secret database-secrets -n $namespace -o yaml > /tmp/${env}_secrets.yaml
                ;;
            "deployments")
                kubectl get deployment knowledge-rag -n $namespace -o yaml > /tmp/${env}_deployment.yaml
                ;;
            "services")
                kubectl get service knowledge-rag -n $namespace -o yaml > /tmp/${env}_service.yaml
                ;;
        esac
        
        echo "  âœ“ Exported $item from $env environment"
    done
    
    # æ¯”è¾ƒé…ç½®å·®å¼‚
    echo "  Comparing configurations..."
    for i in "${!ENVIRONMENTS[@]}"; do
        for j in "${!ENVIRONMENTS[@]}"; do
            if [ $i -lt $j ]; then
                env1=${ENVIRONMENTS[$i]}
                env2=${ENVIRONMENTS[$j]}
                
                diff_output=$(diff /tmp/${env1}_${item}.yaml /tmp/${env2}_${item}.yaml || true)
                
                if [ -n "$diff_output" ]; then
                    echo "    âš ï¸  Differences found between $env1 and $env2:"
                    echo "$diff_output" | head -20
                else
                    echo "    âœ“ $env1 and $env2 configurations match"
                fi
            fi
        done
    done
done

echo "\nEnvironment consistency check completed!"
```

#### ç¯å¢ƒç®¡ç†æ£€æŸ¥æ¸…å•

- [ ] **é…ç½®ç®¡ç†**
  - [ ] æ‰€æœ‰ç¯å¢ƒä½¿ç”¨ç»Ÿä¸€çš„é…ç½®æ¨¡æ¿
  - [ ] æ•æ„Ÿä¿¡æ¯é€šè¿‡Secretsç®¡ç†
  - [ ] ç¯å¢ƒç‰¹å®šé…ç½®æ­£ç¡®è®¾ç½®
  - [ ] é…ç½®ç‰ˆæœ¬æ§åˆ¶å’Œå®¡è®¡

- [ ] **éƒ¨ç½²ä¸€è‡´æ€§**
  - [ ] ä½¿ç”¨ç›¸åŒçš„å®¹å™¨é•œåƒæ„å»ºæµç¨‹
  - [ ] Helm Chartæ¨¡æ¿åŒ–éƒ¨ç½²
  - [ ] ç¯å¢ƒé—´èµ„æºé…ç½®åˆç†
  - [ ] è‡ªåŠ¨åŒ–éƒ¨ç½²æµæ°´çº¿

- [ ] **æ•°æ®ç®¡ç†**
  - [ ] æµ‹è¯•æ•°æ®å®šæœŸåŒæ­¥
  - [ ] ç”Ÿäº§æ•°æ®è„±æ•å¤„ç†
  - [ ] æ•°æ®å¤‡ä»½å’Œæ¢å¤ç­–ç•¥
  - [ ] æ•°æ®è¿ç§»è„šæœ¬æµ‹è¯•

- [ ] **ç›‘æ§å’Œå‘Šè­¦**
  - [ ] ç¯å¢ƒç‰¹å®šç›‘æ§æŒ‡æ ‡
  - [ ] å‘Šè­¦è§„åˆ™ç¯å¢ƒå·®å¼‚åŒ–
  - [ ] æ—¥å¿—èšåˆå’Œåˆ†æ
  - [ ] æ€§èƒ½åŸºçº¿å»ºç«‹

- [ ] **å®‰å…¨å’Œåˆè§„**
  - [ ] ç½‘ç»œéš”ç¦»å’Œè®¿é—®æ§åˆ¶
  - [ ] å¯†é’¥è½®æ¢ç­–ç•¥
  - [ ] å®‰å…¨æ‰«æå’Œæ¼æ´ç®¡ç†
  - [ ] åˆè§„æ€§æ£€æŸ¥å’Œå®¡è®¡

---

## APIæ–‡æ¡£ç”Ÿæˆ

### æ¦‚è¿°

Knowledge RAGç³»ç»Ÿé‡‡ç”¨è‡ªåŠ¨åŒ–APIæ–‡æ¡£ç”Ÿæˆç­–ç•¥ï¼Œç¡®ä¿APIæ–‡æ¡£ä¸ä»£ç å®ç°ä¿æŒåŒæ­¥ï¼Œæä¾›å®Œæ•´ã€å‡†ç¡®ã€æ˜“ç”¨çš„APIæ¥å£è§„èŒƒã€‚æœ¬ç« èŠ‚è¯¦ç»†æè¿°äº†APIæ–‡æ¡£ç”Ÿæˆå·¥å…·é“¾ã€æ–‡æ¡£è§„èŒƒå’Œè‡ªåŠ¨åŒ–æµç¨‹ã€‚

### APIæ–‡æ¡£æ¶æ„è®¾è®¡

#### æ–‡æ¡£ç”Ÿæˆç­–ç•¥

```
APIä»£ç æ³¨é‡Š â†’ OpenAPIè§„èŒƒ â†’ å¤šæ ¼å¼æ–‡æ¡£ â†’ åœ¨çº¿æ–‡æ¡£å¹³å°
     â†“              â†“              â†“              â†“
  ä»£ç æ³¨è§£      Swagger/OAS     HTML/PDF      æ–‡æ¡£ç½‘ç«™
  ç±»å‹å®šä¹‰      JSON Schema     Markdown      äº¤äº’å¼API
  ç¤ºä¾‹ä»£ç       APIæµ‹è¯•         å¤šè¯­è¨€SDK     ç‰ˆæœ¬ç®¡ç†
```

#### æ–‡æ¡£ç”Ÿæˆå·¥å…·é“¾

| å·¥å…·ç±»å‹ | å·¥å…·åç§° | ç”¨é€” | è¾“å‡ºæ ¼å¼ | é›†æˆæ–¹å¼ |
|---------|---------|------|----------|----------|
| ä»£ç æ³¨é‡Š | Pydantic | æ•°æ®æ¨¡å‹å®šä¹‰ | JSON Schema | è£…é¥°å™¨ |
| APIè§„èŒƒ | FastAPI | OpenAPIç”Ÿæˆ | JSON/YAML | è‡ªåŠ¨ç”Ÿæˆ |
| æ–‡æ¡£æ¸²æŸ“ | Swagger UI | äº¤äº’å¼æ–‡æ¡£ | HTML | å†…åµŒæœåŠ¡ |
| æ–‡æ¡£ç”Ÿæˆ | Redoc | ç¾è§‚æ–‡æ¡£ | HTML | é™æ€ç”Ÿæˆ |
| SDKç”Ÿæˆ | OpenAPI Generator | å¤šè¯­è¨€SDK | å¤šè¯­è¨€ | CI/CD |
| æ–‡æ¡£æ‰˜ç®¡ | GitBook | åœ¨çº¿æ–‡æ¡£ | Web | Gité›†æˆ |

### APIæ–‡æ¡£è§„èŒƒ

#### OpenAPIè§„èŒƒé…ç½®

```python
# src/api/main.py
"""
Knowledge RAG APIä¸»åº”ç”¨
æä¾›å®Œæ•´çš„RESTful APIæ¥å£å’Œè‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ
"""

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html
from fastapi.openapi.utils import get_openapi
from fastapi.staticfiles import StaticFiles
from typing import Dict, List, Optional, Any
import uvicorn

# APIå…ƒæ•°æ®é…ç½®
API_METADATA = {
    "title": "Knowledge RAG API",
    "description": """
    Knowledge RAGç³»ç»Ÿæä¾›æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œé—®ç­”æœåŠ¡çš„RESTful APIæ¥å£ã€‚
    
    ## ä¸»è¦åŠŸèƒ½
    
    * **æ–‡æ¡£ç®¡ç†** - æ–‡æ¡£ä¸Šä¼ ã€è§£æã€å­˜å‚¨å’Œæ£€ç´¢
    * **çŸ¥è¯†å›¾è°±** - å®ä½“æå–ã€å…³ç³»æ„å»ºå’Œå›¾è°±æŸ¥è¯¢
    * **æ™ºèƒ½é—®ç­”** - åŸºäºRAGçš„æ™ºèƒ½é—®ç­”å’Œä¸Šä¸‹æ–‡ç®¡ç†
    * **å‘é‡æœç´¢** - è¯­ä¹‰æœç´¢å’Œç›¸ä¼¼åº¦åŒ¹é…
    * **ç”¨æˆ·ç®¡ç†** - ç”¨æˆ·è®¤è¯ã€æˆæƒå’Œæƒé™æ§åˆ¶
    
    ## è®¤è¯æ–¹å¼
    
    APIä½¿ç”¨JWT Bearer Tokenè¿›è¡Œè®¤è¯ï¼š
    ```
    Authorization: Bearer <your-jwt-token>
    ```
    
    ## é”™è¯¯å¤„ç†
    
    APIéµå¾ªæ ‡å‡†HTTPçŠ¶æ€ç ï¼Œé”™è¯¯å“åº”æ ¼å¼ï¼š
    ```json
    {
        "error": {
            "code": "ERROR_CODE",
            "message": "Error description",
            "details": {}
        }
    }
    ```
    
    ## ç‰ˆæœ¬æ§åˆ¶
    
    APIç‰ˆæœ¬é€šè¿‡URLè·¯å¾„è¿›è¡Œç®¡ç†ï¼š`/api/v1/`
    """,
    "version": "1.0.0",
    "contact": {
        "name": "Knowledge RAG Team",
        "email": "support@knowledge-rag.com",
        "url": "https://knowledge-rag.com"
    },
    "license": {
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT"
    },
    "servers": [
        {
            "url": "https://api.knowledge-rag.com",
            "description": "Production server"
        },
        {
            "url": "https://staging-api.knowledge-rag.com",
            "description": "Staging server"
        },
        {
            "url": "http://localhost:8000",
            "description": "Development server"
        }
    ]
}

# åˆ›å»ºFastAPIåº”ç”¨å®ä¾‹
app = FastAPI(
    title=API_METADATA["title"],
    description=API_METADATA["description"],
    version=API_METADATA["version"],
    contact=API_METADATA["contact"],
    license_info=API_METADATA["license"],
    docs_url=None,  # ç¦ç”¨é»˜è®¤æ–‡æ¡£
    redoc_url=None,  # ç¦ç”¨é»˜è®¤Redoc
    openapi_url="/api/v1/openapi.json"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è‡ªå®šä¹‰OpenAPIé…ç½®
def custom_openapi() -> Dict[str, Any]:
    """
    ç”Ÿæˆè‡ªå®šä¹‰OpenAPIè§„èŒƒ
    
    Returns:
        Dict[str, Any]: OpenAPIè§„èŒƒå­—å…¸
    """
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title=API_METADATA["title"],
        version=API_METADATA["version"],
        description=API_METADATA["description"],
        routes=app.routes,
        servers=API_METADATA["servers"]
    )
    
    # æ·»åŠ å®‰å…¨å®šä¹‰
    openapi_schema["components"]["securitySchemes"] = {
        "BearerAuth": {
            "type": "http",
            "scheme": "bearer",
            "bearerFormat": "JWT",
            "description": "JWT Bearer Tokenè®¤è¯"
        }
    }
    
    # æ·»åŠ å…¨å±€å®‰å…¨è¦æ±‚
    openapi_schema["security"] = [{"BearerAuth": []}]
    
    # æ·»åŠ æ ‡ç­¾åˆ†ç»„
    openapi_schema["tags"] = [
        {
            "name": "Authentication",
            "description": "ç”¨æˆ·è®¤è¯å’Œæˆæƒç›¸å…³æ¥å£"
        },
        {
            "name": "Documents",
            "description": "æ–‡æ¡£ç®¡ç†ç›¸å…³æ¥å£"
        },
        {
            "name": "Knowledge Graph",
            "description": "çŸ¥è¯†å›¾è°±ç›¸å…³æ¥å£"
        },
        {
            "name": "Question Answering",
            "description": "æ™ºèƒ½é—®ç­”ç›¸å…³æ¥å£"
        },
        {
            "name": "Search",
            "description": "æœç´¢å’Œæ£€ç´¢ç›¸å…³æ¥å£"
        },
        {
            "name": "Analytics",
            "description": "åˆ†æå’Œç›‘æ§ç›¸å…³æ¥å£"
        }
    ]
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi

# è‡ªå®šä¹‰æ–‡æ¡£è·¯ç”±
@app.get("/docs", include_in_schema=False)
async def custom_swagger_ui_html():
    """
    è‡ªå®šä¹‰Swagger UIæ–‡æ¡£é¡µé¢
    
    Returns:
        HTMLResponse: Swagger UI HTMLé¡µé¢
    """
    return get_swagger_ui_html(
        openapi_url=app.openapi_url,
        title=f"{API_METADATA['title']} - Swagger UI",
        swagger_js_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@4.15.5/swagger-ui-bundle.js",
        swagger_css_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@4.15.5/swagger-ui.css",
        swagger_favicon_url="https://fastapi.tiangolo.com/img/favicon.png"
    )

@app.get("/redoc", include_in_schema=False)
async def redoc_html():
    """
    è‡ªå®šä¹‰Redocæ–‡æ¡£é¡µé¢
    
    Returns:
        HTMLResponse: Redoc HTMLé¡µé¢
    """
    return get_redoc_html(
        openapi_url=app.openapi_url,
        title=f"{API_METADATA['title']} - ReDoc",
        redoc_js_url="https://cdn.jsdelivr.net/npm/redoc@2.0.0/bundles/redoc.standalone.js",
        redoc_favicon_url="https://fastapi.tiangolo.com/img/favicon.png"
    )
```

#### æ•°æ®æ¨¡å‹å®šä¹‰

```python
# src/api/models/schemas.py
"""
APIæ•°æ®æ¨¡å‹å’ŒSchemaå®šä¹‰
æä¾›å®Œæ•´çš„è¯·æ±‚/å“åº”æ•°æ®ç»“æ„å’ŒéªŒè¯è§„åˆ™
"""

from pydantic import BaseModel, Field, validator, EmailStr
from typing import List, Optional, Dict, Any, Union
from datetime import datetime
from enum import Enum

class DocumentStatus(str, Enum):
    """
    æ–‡æ¡£çŠ¶æ€æšä¸¾
    
    Attributes:
        PENDING: å¾…å¤„ç†
        PROCESSING: å¤„ç†ä¸­
        COMPLETED: å¤„ç†å®Œæˆ
        FAILED: å¤„ç†å¤±è´¥
    """
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class QuestionType(str, Enum):
    """
    é—®é¢˜ç±»å‹æšä¸¾
    
    Attributes:
        FACTUAL: äº‹å®æ€§é—®é¢˜
        ANALYTICAL: åˆ†ææ€§é—®é¢˜
        COMPARATIVE: æ¯”è¾ƒæ€§é—®é¢˜
        SUMMARIZATION: æ€»ç»“æ€§é—®é¢˜
    """
    FACTUAL = "factual"
    ANALYTICAL = "analytical"
    COMPARATIVE = "comparative"
    SUMMARIZATION = "summarization"

# åŸºç¡€å“åº”æ¨¡å‹
class BaseResponse(BaseModel):
    """
    APIåŸºç¡€å“åº”æ¨¡å‹
    
    Attributes:
        success: è¯·æ±‚æ˜¯å¦æˆåŠŸ
        message: å“åº”æ¶ˆæ¯
        timestamp: å“åº”æ—¶é—´æˆ³
    """
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="å“åº”æ—¶é—´æˆ³")
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

class ErrorResponse(BaseModel):
    """
    APIé”™è¯¯å“åº”æ¨¡å‹
    
    Attributes:
        error: é”™è¯¯ä¿¡æ¯å¯¹è±¡
    """
    error: Dict[str, Any] = Field(
        ...,
        description="é”™è¯¯ä¿¡æ¯",
        example={
            "code": "VALIDATION_ERROR",
            "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            "details": {
                "field": "email",
                "issue": "æ ¼å¼ä¸æ­£ç¡®"
            }
        }
    )

# ç”¨æˆ·ç›¸å…³æ¨¡å‹
class UserCreate(BaseModel):
    """
    ç”¨æˆ·åˆ›å»ºè¯·æ±‚æ¨¡å‹
    
    Attributes:
        username: ç”¨æˆ·å
        email: é‚®ç®±åœ°å€
        password: å¯†ç 
        full_name: å…¨å
    """
    username: str = Field(
        ...,
        min_length=3,
        max_length=50,
        regex=r"^[a-zA-Z0-9_]+$",
        description="ç”¨æˆ·åï¼Œ3-50ä¸ªå­—ç¬¦ï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿",
        example="john_doe"
    )
    email: EmailStr = Field(
        ...,
        description="é‚®ç®±åœ°å€",
        example="john.doe@example.com"
    )
    password: str = Field(
        ...,
        min_length=8,
        max_length=128,
        description="å¯†ç ï¼Œè‡³å°‘8ä¸ªå­—ç¬¦",
        example="SecurePassword123!"
    )
    full_name: Optional[str] = Field(
        None,
        max_length=100,
        description="ç”¨æˆ·å…¨å",
        example="John Doe"
    )
    
    @validator('password')
    def validate_password(cls, v):
        """
        å¯†ç å¼ºåº¦éªŒè¯
        
        Args:
            v: å¯†ç å€¼
            
        Returns:
            str: éªŒè¯é€šè¿‡çš„å¯†ç 
            
        Raises:
            ValueError: å¯†ç ä¸ç¬¦åˆè¦æ±‚
        """
        if not any(c.isupper() for c in v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå¤§å†™å­—æ¯')
        if not any(c.islower() for c in v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå°å†™å­—æ¯')
        if not any(c.isdigit() for c in v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªæ•°å­—')
        return v

class UserResponse(BaseResponse):
    """
    ç”¨æˆ·ä¿¡æ¯å“åº”æ¨¡å‹
    
    Attributes:
        data: ç”¨æˆ·æ•°æ®
    """
    data: Dict[str, Any] = Field(
        ...,
        description="ç”¨æˆ·æ•°æ®",
        example={
            "id": "123e4567-e89b-12d3-a456-426614174000",
            "username": "john_doe",
            "email": "john.doe@example.com",
            "full_name": "John Doe",
            "is_active": True,
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-01T00:00:00Z"
        }
    )

# æ–‡æ¡£ç›¸å…³æ¨¡å‹
class DocumentUpload(BaseModel):
    """
    æ–‡æ¡£ä¸Šä¼ è¯·æ±‚æ¨¡å‹
    
    Attributes:
        title: æ–‡æ¡£æ ‡é¢˜
        description: æ–‡æ¡£æè¿°
        tags: æ–‡æ¡£æ ‡ç­¾
        category: æ–‡æ¡£åˆ†ç±»
    """
    title: str = Field(
        ...,
        min_length=1,
        max_length=200,
        description="æ–‡æ¡£æ ‡é¢˜",
        example="Knowledge RAGç³»ç»Ÿæ¶æ„è®¾è®¡"
    )
    description: Optional[str] = Field(
        None,
        max_length=1000,
        description="æ–‡æ¡£æè¿°",
        example="è¯¦ç»†æè¿°Knowledge RAGç³»ç»Ÿçš„æ¶æ„è®¾è®¡å’Œå®ç°æ–¹æ¡ˆ"
    )
    tags: Optional[List[str]] = Field(
        None,
        description="æ–‡æ¡£æ ‡ç­¾åˆ—è¡¨",
        example=["æ¶æ„", "è®¾è®¡", "RAG"]
    )
    category: Optional[str] = Field(
        None,
        max_length=50,
        description="æ–‡æ¡£åˆ†ç±»",
        example="æŠ€æœ¯æ–‡æ¡£"
    )

class DocumentResponse(BaseResponse):
    """
    æ–‡æ¡£ä¿¡æ¯å“åº”æ¨¡å‹
    
    Attributes:
        data: æ–‡æ¡£æ•°æ®
    """
    data: Dict[str, Any] = Field(
        ...,
        description="æ–‡æ¡£æ•°æ®",
        example={
            "id": "doc_123e4567-e89b-12d3-a456-426614174000",
            "title": "Knowledge RAGç³»ç»Ÿæ¶æ„è®¾è®¡",
            "description": "è¯¦ç»†æè¿°Knowledge RAGç³»ç»Ÿçš„æ¶æ„è®¾è®¡å’Œå®ç°æ–¹æ¡ˆ",
            "status": "completed",
            "file_size": 1024000,
            "file_type": "application/pdf",
            "tags": ["æ¶æ„", "è®¾è®¡", "RAG"],
            "category": "æŠ€æœ¯æ–‡æ¡£",
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-01T00:00:00Z",
            "processing_stats": {
                "pages": 25,
                "chunks": 150,
                "entities": 45,
                "relationships": 78
            }
        }
    )

# é—®ç­”ç›¸å…³æ¨¡å‹
class QuestionRequest(BaseModel):
    """
    é—®ç­”è¯·æ±‚æ¨¡å‹
    
    Attributes:
        question: ç”¨æˆ·é—®é¢˜
        context_ids: ä¸Šä¸‹æ–‡æ–‡æ¡£IDåˆ—è¡¨
        question_type: é—®é¢˜ç±»å‹
        max_tokens: æœ€å¤§å›ç­”é•¿åº¦
        temperature: ç”Ÿæˆæ¸©åº¦
    """
    question: str = Field(
        ...,
        min_length=1,
        max_length=1000,
        description="ç”¨æˆ·é—®é¢˜",
        example="Knowledge RAGç³»ç»Ÿçš„æ ¸å¿ƒæ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ"
    )
    context_ids: Optional[List[str]] = Field(
        None,
        description="ç›¸å…³æ–‡æ¡£IDåˆ—è¡¨ï¼Œç”¨äºé™å®šæœç´¢èŒƒå›´",
        example=["doc_123", "doc_456"]
    )
    question_type: Optional[QuestionType] = Field(
        QuestionType.FACTUAL,
        description="é—®é¢˜ç±»å‹"
    )
    max_tokens: Optional[int] = Field(
        500,
        ge=50,
        le=2000,
        description="æœ€å¤§å›ç­”é•¿åº¦ï¼ˆtokenæ•°ï¼‰"
    )
    temperature: Optional[float] = Field(
        0.7,
        ge=0.0,
        le=2.0,
        description="ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶å›ç­”çš„åˆ›é€ æ€§"
    )

class AnswerResponse(BaseResponse):
    """
    é—®ç­”å“åº”æ¨¡å‹
    
    Attributes:
        data: å›ç­”æ•°æ®
    """
    data: Dict[str, Any] = Field(
        ...,
        description="å›ç­”æ•°æ®",
        example={
            "answer": "Knowledge RAGç³»ç»Ÿé‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼ŒåŒ…å«æ–‡æ¡£å¤„ç†ã€å‘é‡å­˜å‚¨ã€çŸ¥è¯†å›¾è°±å’Œé—®ç­”å¼•æ“å››ä¸ªæ ¸å¿ƒæ¨¡å—...",
            "confidence_score": 0.92,
            "sources": [
                {
                    "document_id": "doc_123",
                    "title": "ç³»ç»Ÿæ¶æ„æ–‡æ¡£",
                    "relevance_score": 0.95,
                    "excerpt": "ç³»ç»Ÿé‡‡ç”¨å¾®æœåŠ¡æ¶æ„è®¾è®¡..."
                }
            ],
            "related_entities": [
                {
                    "name": "å¾®æœåŠ¡æ¶æ„",
                    "type": "concept",
                    "confidence": 0.88
                }
            ],
            "processing_time": 1.23,
            "token_usage": {
                "prompt_tokens": 1500,
                "completion_tokens": 300,
                "total_tokens": 1800
            }
        }
    )
```

### è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆ

#### CI/CDé›†æˆé…ç½®

```yaml
# .github/workflows/api-docs.yml
name: API Documentation Generation

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'src/api/**'
      - 'docs/api/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'src/api/**'
      - 'docs/api/**'

jobs:
  generate-docs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        uv sync --prerelease=allow
        uv tool install openapi-generator-cli
        
    - name: Generate OpenAPI spec
      run: |
        python scripts/generate_openapi.py
        
    - name: Validate OpenAPI spec
      run: |
        npx @apidevtools/swagger-parser validate docs/api/openapi.json
        
    - name: Generate API documentation
      run: |
        # ç”ŸæˆHTMLæ–‡æ¡£
        npx redoc-cli build docs/api/openapi.json --output docs/api/index.html
        
        # ç”ŸæˆMarkdownæ–‡æ¡£
        npx widdershins docs/api/openapi.json -o docs/api/README.md
        
        # ç”ŸæˆPostmané›†åˆ
        openapi-generator generate -i docs/api/openapi.json -g postman-collection -o docs/api/postman/
        
    - name: Generate SDK
      run: |
        # ç”ŸæˆPython SDK
        openapi-generator generate \
          -i docs/api/openapi.json \
          -g python \
          -o sdks/python \
          --additional-properties=packageName=knowledge_rag_client,projectName=knowledge-rag-python-client
          
        # ç”ŸæˆJavaScript SDK
        openapi-generator generate \
          -i docs/api/openapi.json \
          -g javascript \
          -o sdks/javascript \
          --additional-properties=projectName=knowledge-rag-js-client
          
        # ç”ŸæˆTypeScript SDK
        openapi-generator generate \
          -i docs/api/openapi.json \
          -g typescript-axios \
          -o sdks/typescript \
          --additional-properties=npmName=@knowledge-rag/client
          
    - name: Run API tests
      run: |
        # å¯åŠ¨APIæœåŠ¡
        python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 &
        sleep 10
        
        # è¿è¡ŒAPIæµ‹è¯•
        pytest tests/api/ -v
        
        # è¿è¡Œæ–‡æ¡£æµ‹è¯•
        python scripts/test_api_examples.py
        
    - name: Deploy documentation
      if: github.ref == 'refs/heads/main'
      run: |
        # éƒ¨ç½²åˆ°GitHub Pages
        cp -r docs/api/* gh-pages/
        
        # éƒ¨ç½²åˆ°GitBook
        curl -X POST "$GITBOOK_WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d '{"ref": "main"}'
      env:
        GITBOOK_WEBHOOK_URL: ${{ secrets.GITBOOK_WEBHOOK_URL }}
        
    - name: Create release artifacts
      if: github.ref == 'refs/heads/main'
      run: |
        # åˆ›å»ºæ–‡æ¡£å‹ç¼©åŒ…
        tar -czf api-docs-${{ github.sha }}.tar.gz docs/api/
        tar -czf api-sdks-${{ github.sha }}.tar.gz sdks/
        
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: api-documentation
        path: |
          docs/api/
          sdks/
          *.tar.gz
```

#### æ–‡æ¡£ç”Ÿæˆè„šæœ¬

```python
#!/usr/bin/env python3
# scripts/generate_openapi.py
"""
OpenAPIè§„èŒƒç”Ÿæˆè„šæœ¬
è‡ªåŠ¨ä»FastAPIåº”ç”¨ç”ŸæˆOpenAPIè§„èŒƒæ–‡ä»¶
"""

import json
import yaml
import os
from pathlib import Path
from typing import Dict, Any

# å¯¼å…¥FastAPIåº”ç”¨
sys.path.append(str(Path(__file__).parent.parent))
from src.api.main import app

def generate_openapi_spec() -> Dict[str, Any]:
    """
    ç”ŸæˆOpenAPIè§„èŒƒ
    
    Returns:
        Dict[str, Any]: OpenAPIè§„èŒƒå­—å…¸
    """
    return app.openapi()

def save_openapi_spec(spec: Dict[str, Any], output_dir: str = "docs/api") -> None:
    """
    ä¿å­˜OpenAPIè§„èŒƒåˆ°æ–‡ä»¶
    
    Args:
        spec: OpenAPIè§„èŒƒå­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜JSONæ ¼å¼
    json_path = Path(output_dir) / "openapi.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(spec, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜YAMLæ ¼å¼
    yaml_path = Path(output_dir) / "openapi.yaml"
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(spec, f, default_flow_style=False, allow_unicode=True)
    
    print(f"OpenAPIè§„èŒƒå·²ç”Ÿæˆï¼š")
    print(f"  JSON: {json_path}")
    print(f"  YAML: {yaml_path}")

def generate_api_examples() -> None:
    """
    ç”ŸæˆAPIä½¿ç”¨ç¤ºä¾‹
    """
    examples = {
        "authentication": {
            "login": {
                "request": {
                    "method": "POST",
                    "url": "/api/v1/auth/login",
                    "headers": {
                        "Content-Type": "application/json"
                    },
                    "body": {
                        "username": "john_doe",
                        "password": "SecurePassword123!"
                    }
                },
                "response": {
                    "status": 200,
                    "body": {
                        "success": True,
                        "message": "ç™»å½•æˆåŠŸ",
                        "data": {
                            "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
                            "token_type": "bearer",
                            "expires_in": 3600
                        }
                    }
                }
            }
        },
        "documents": {
            "upload": {
                "request": {
                    "method": "POST",
                    "url": "/api/v1/documents/upload",
                    "headers": {
                        "Authorization": "Bearer <token>",
                        "Content-Type": "multipart/form-data"
                    },
                    "body": {
                        "file": "<binary-data>",
                        "title": "ç³»ç»Ÿæ¶æ„æ–‡æ¡£",
                        "description": "Knowledge RAGç³»ç»Ÿæ¶æ„è®¾è®¡",
                        "tags": ["æ¶æ„", "è®¾è®¡"]
                    }
                },
                "response": {
                    "status": 201,
                    "body": {
                        "success": True,
                        "message": "æ–‡æ¡£ä¸Šä¼ æˆåŠŸ",
                        "data": {
                            "id": "doc_123e4567-e89b-12d3-a456-426614174000",
                            "title": "ç³»ç»Ÿæ¶æ„æ–‡æ¡£",
                            "status": "processing",
                            "upload_url": "https://api.knowledge-rag.com/api/v1/documents/doc_123e4567-e89b-12d3-a456-426614174000"
                        }
                    }
                }
            }
        },
        "question_answering": {
            "ask": {
                "request": {
                    "method": "POST",
                    "url": "/api/v1/qa/ask",
                    "headers": {
                        "Authorization": "Bearer <token>",
                        "Content-Type": "application/json"
                    },
                    "body": {
                        "question": "Knowledge RAGç³»ç»Ÿçš„æ ¸å¿ƒæ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ",
                        "context_ids": ["doc_123"],
                        "max_tokens": 500,
                        "temperature": 0.7
                    }
                },
                "response": {
                    "status": 200,
                    "body": {
                        "success": True,
                        "message": "é—®ç­”å®Œæˆ",
                        "data": {
                            "answer": "Knowledge RAGç³»ç»Ÿé‡‡ç”¨å¾®æœåŠ¡æ¶æ„...",
                            "confidence_score": 0.92,
                            "sources": [
                                {
                                    "document_id": "doc_123",
                                    "title": "ç³»ç»Ÿæ¶æ„æ–‡æ¡£",
                                    "relevance_score": 0.95
                                }
                            ]
                        }
                    }
                }
            }
        }
    }
    
    # ä¿å­˜ç¤ºä¾‹æ–‡ä»¶
    examples_path = Path("docs/api") / "examples.json"
    with open(examples_path, 'w', encoding='utf-8') as f:
        json.dump(examples, f, indent=2, ensure_ascii=False)
    
    print(f"APIç¤ºä¾‹å·²ç”Ÿæˆï¼š{examples_path}")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("å¼€å§‹ç”ŸæˆAPIæ–‡æ¡£...")
    
    # ç”ŸæˆOpenAPIè§„èŒƒ
    spec = generate_openapi_spec()
    save_openapi_spec(spec)
    
    # ç”ŸæˆAPIç¤ºä¾‹
    generate_api_examples()
    
    print("APIæ–‡æ¡£ç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    main()
```

### æ–‡æ¡£éƒ¨ç½²å’Œæ‰˜ç®¡

#### DockeråŒ–æ–‡æ¡£æœåŠ¡

```dockerfile
# docs/Dockerfile
FROM nginx:alpine

# å®‰è£…Node.jsç”¨äºæ„å»ºæ–‡æ¡£
RUN apk add --no-cache nodejs npm

# å¤åˆ¶æ–‡æ¡£æºæ–‡ä»¶
COPY api/ /usr/share/nginx/html/api/
COPY static/ /usr/share/nginx/html/static/

# å®‰è£…æ–‡æ¡£ç”Ÿæˆå·¥å…·
RUN npm install -g redoc-cli swagger-ui-dist

# ç”Ÿæˆé™æ€æ–‡æ¡£
RUN redoc-cli build /usr/share/nginx/html/api/openapi.json \
    --output /usr/share/nginx/html/index.html

# å¤åˆ¶Nginxé…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# æš´éœ²ç«¯å£
EXPOSE 80

# å¯åŠ¨Nginx
CMD ["nginx", "-g", "daemon off;"]
```

```nginx
# docs/nginx.conf
events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    
    # å¯ç”¨gzipå‹ç¼©
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
    
    server {
        listen 80;
        server_name localhost;
        
        # æ–‡æ¡£æ ¹ç›®å½•
        root /usr/share/nginx/html;
        index index.html;
        
        # APIæ–‡æ¡£ä¸»é¡µ
        location / {
            try_files $uri $uri/ /index.html;
        }
        
        # OpenAPIè§„èŒƒæ–‡ä»¶
        location /api/openapi.json {
            add_header Access-Control-Allow-Origin *;
            add_header Content-Type application/json;
        }
        
        # Swagger UI
        location /swagger/ {
            alias /usr/share/nginx/html/swagger-ui/;
            try_files $uri $uri/ /swagger-ui/index.html;
        }
        
        # APIç¤ºä¾‹
        location /examples {
            add_header Content-Type application/json;
            try_files $uri $uri.json =404;
        }
        
        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

#### Kuberneteséƒ¨ç½²é…ç½®

```yaml
# k8s/api-docs-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-docs
  namespace: knowledge-rag-prod
  labels:
    app: api-docs
    component: documentation
spec:
  replicas: 2
  selector:
    matchLabels:
      app: api-docs
  template:
    metadata:
      labels:
        app: api-docs
        component: documentation
    spec:
      containers:
      - name: api-docs
        image: knowledge-rag/api-docs:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: api-docs-service
  namespace: knowledge-rag-prod
spec:
  selector:
    app: api-docs
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-docs-ingress
  namespace: knowledge-rag-prod
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - docs.knowledge-rag.com
    secretName: api-docs-tls
  rules:
  - host: docs.knowledge-rag.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-docs-service
            port:
              number: 80
```

### æ–‡æ¡£è´¨é‡ä¿è¯

#### æ–‡æ¡£æµ‹è¯•è„šæœ¬

```python
#!/usr/bin/env python3
# scripts/test_api_examples.py
"""
APIæ–‡æ¡£ç¤ºä¾‹æµ‹è¯•è„šæœ¬
éªŒè¯APIæ–‡æ¡£ä¸­çš„ç¤ºä¾‹æ˜¯å¦æ­£ç¡®
"""

import json
import requests
import pytest
from typing import Dict, Any
from pathlib import Path

class APIDocumentationTester:
    """
    APIæ–‡æ¡£æµ‹è¯•å™¨
    
    Attributes:
        base_url: APIåŸºç¡€URL
        examples: APIç¤ºä¾‹æ•°æ®
    """
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            base_url: APIåŸºç¡€URL
        """
        self.base_url = base_url
        self.examples = self._load_examples()
        self.session = requests.Session()
    
    def _load_examples(self) -> Dict[str, Any]:
        """
        åŠ è½½APIç¤ºä¾‹æ•°æ®
        
        Returns:
            Dict[str, Any]: ç¤ºä¾‹æ•°æ®å­—å…¸
        """
        examples_path = Path("docs/api/examples.json")
        if not examples_path.exists():
            raise FileNotFoundError(f"ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {examples_path}")
        
        with open(examples_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def test_openapi_spec_validity(self):
        """
        æµ‹è¯•OpenAPIè§„èŒƒæœ‰æ•ˆæ€§
        """
        response = self.session.get(f"{self.base_url}/api/v1/openapi.json")
        assert response.status_code == 200
        
        spec = response.json()
        assert "openapi" in spec
        assert "info" in spec
        assert "paths" in spec
        
        print("âœ“ OpenAPIè§„èŒƒæœ‰æ•ˆæ€§æµ‹è¯•é€šè¿‡")
    
    def test_documentation_accessibility(self):
        """
        æµ‹è¯•æ–‡æ¡£å¯è®¿é—®æ€§
        """
        # æµ‹è¯•Swagger UI
        response = self.session.get(f"{self.base_url}/docs")
        assert response.status_code == 200
        assert "swagger" in response.text.lower()
        
        # æµ‹è¯•Redoc
        response = self.session.get(f"{self.base_url}/redoc")
        assert response.status_code == 200
        assert "redoc" in response.text.lower()
        
        print("âœ“ æ–‡æ¡£å¯è®¿é—®æ€§æµ‹è¯•é€šè¿‡")
    
    def test_api_examples(self):
        """
        æµ‹è¯•APIç¤ºä¾‹çš„æ­£ç¡®æ€§
        """
        # æ³¨æ„ï¼šè¿™é‡Œåªæµ‹è¯•è¯·æ±‚æ ¼å¼ï¼Œä¸æ‰§è¡Œå®é™…APIè°ƒç”¨
        # å®é™…æµ‹è¯•éœ€è¦æœ‰æ•ˆçš„è®¤è¯å’Œæµ‹è¯•æ•°æ®
        
        for category, endpoints in self.examples.items():
            for endpoint_name, example in endpoints.items():
                request_example = example.get("request", {})
                response_example = example.get("response", {})
                
                # éªŒè¯è¯·æ±‚ç¤ºä¾‹ç»“æ„
                assert "method" in request_example
                assert "url" in request_example
                assert "headers" in request_example
                
                # éªŒè¯å“åº”ç¤ºä¾‹ç»“æ„
                assert "status" in response_example
                assert "body" in response_example
                
                print(f"âœ“ {category}.{endpoint_name} ç¤ºä¾‹ç»“æ„æ­£ç¡®")
    
    def test_schema_consistency(self):
        """
        æµ‹è¯•Schemaä¸€è‡´æ€§
        """
        # è·å–OpenAPIè§„èŒƒ
        response = self.session.get(f"{self.base_url}/api/v1/openapi.json")
        spec = response.json()
        
        # æ£€æŸ¥æ‰€æœ‰è·¯å¾„éƒ½æœ‰å¯¹åº”çš„Schemaå®šä¹‰
        paths = spec.get("paths", {})
        components = spec.get("components", {}).get("schemas", {})
        
        for path, methods in paths.items():
            for method, details in methods.items():
                # æ£€æŸ¥è¯·æ±‚ä½“Schema
                request_body = details.get("requestBody", {})
                if request_body:
                    content = request_body.get("content", {})
                    for media_type, schema_info in content.items():
                        schema_ref = schema_info.get("schema", {}).get("$ref")
                        if schema_ref:
                            schema_name = schema_ref.split("/")[-1]
                            assert schema_name in components, f"Schema {schema_name} æœªå®šä¹‰"
                
                # æ£€æŸ¥å“åº”Schema
                responses = details.get("responses", {})
                for status_code, response_info in responses.items():
                    content = response_info.get("content", {})
                    for media_type, schema_info in content.items():
                        schema_ref = schema_info.get("schema", {}).get("$ref")
                        if schema_ref:
                            schema_name = schema_ref.split("/")[-1]
                            assert schema_name in components, f"Schema {schema_name} æœªå®šä¹‰"
        
        print("âœ“ Schemaä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def run_all_tests(self):
        """
        è¿è¡Œæ‰€æœ‰æµ‹è¯•
        """
        print("å¼€å§‹APIæ–‡æ¡£æµ‹è¯•...")
        
        try:
            self.test_openapi_spec_validity()
            self.test_documentation_accessibility()
            self.test_api_examples()
            self.test_schema_consistency()
            
            print("\nğŸ‰ æ‰€æœ‰APIæ–‡æ¡£æµ‹è¯•é€šè¿‡ï¼")
            return True
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
            return False

def main():
    """
    ä¸»å‡½æ•°
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="APIæ–‡æ¡£æµ‹è¯•å·¥å…·")
    parser.add_argument(
        "--base-url",
        default="http://localhost:8000",
        help="APIåŸºç¡€URL"
    )
    
    args = parser.parse_args()
    
    tester = APIDocumentationTester(args.base_url)
    success = tester.run_all_tests()
    
    exit(0 if success else 1)

if __name__ == "__main__":
    main()
```

### APIæ–‡æ¡£æœ€ä½³å®è·µ

#### æ–‡æ¡£ç»´æŠ¤æ£€æŸ¥æ¸…å•

- [ ] **ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£åŒæ­¥**
  - [ ] æ‰€æœ‰APIç«¯ç‚¹éƒ½æœ‰å®Œæ•´çš„docstring
  - [ ] æ•°æ®æ¨¡å‹éƒ½æœ‰è¯¦ç»†çš„å­—æ®µè¯´æ˜
  - [ ] ç¤ºä¾‹ä»£ç ä¿æŒæœ€æ–°
  - [ ] é”™è¯¯ç å’Œæ¶ˆæ¯å‡†ç¡®æè¿°

- [ ] **OpenAPIè§„èŒƒè´¨é‡**
  - [ ] è§„èŒƒæ–‡ä»¶è¯­æ³•æ­£ç¡®
  - [ ] æ‰€æœ‰ç«¯ç‚¹éƒ½æœ‰é€‚å½“çš„æ ‡ç­¾åˆ†ç»„
  - [ ] å®‰å…¨å®šä¹‰å®Œæ•´é…ç½®
  - [ ] æœåŠ¡å™¨ä¿¡æ¯å‡†ç¡®è®¾ç½®

- [ ] **æ–‡æ¡£å†…å®¹å®Œæ•´æ€§**
  - [ ] è®¤è¯å’Œæˆæƒè¯´æ˜æ¸…æ™°
  - [ ] é”™è¯¯å¤„ç†æœºåˆ¶è¯¦ç»†æè¿°
  - [ ] é™æµå’Œé…é¢æ”¿ç­–è¯´æ˜
  - [ ] ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥æ˜ç¡®

- [ ] **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**
  - [ ] äº¤äº’å¼æ–‡æ¡£åŠŸèƒ½æ­£å¸¸
  - [ ] ä»£ç ç¤ºä¾‹å¯ç›´æ¥è¿è¡Œ
  - [ ] å¤šè¯­è¨€SDKå¯ç”¨
  - [ ] æœç´¢åŠŸèƒ½æœ‰æ•ˆ

- [ ] **è‡ªåŠ¨åŒ–å’Œé›†æˆ**
  - [ ] CI/CDæµæ°´çº¿åŒ…å«æ–‡æ¡£ç”Ÿæˆ
  - [ ] æ–‡æ¡£æµ‹è¯•è‡ªåŠ¨åŒ–æ‰§è¡Œ
  - [ ] ç‰ˆæœ¬å‘å¸ƒè‡ªåŠ¨æ›´æ–°æ–‡æ¡£
  - [ ] ç›‘æ§æ–‡æ¡£è®¿é—®å’Œä½¿ç”¨æƒ…å†µ

---

**ä¸‹ä¸€æ­¥æ“ä½œé€‰é¡¹ï¼š**

1. **å®Œå–„ç›‘æ§ä½“ç³»** - æ·»åŠ æ›´å¤šç›‘æ§æŒ‡æ ‡å’Œå‘Šè­¦è§„åˆ™
2. **è®¾è®¡å®‰å…¨æ¶æ„** - æ·±å…¥çš„å®‰å…¨ç­–ç•¥å’Œåˆè§„è¦æ±‚
3. **æ·»åŠ è¿ç»´æ‰‹å†Œ** - æ—¥å¸¸è¿ç»´æ“ä½œå’Œæ•…éšœæ’æŸ¥æŒ‡å—
4. **æˆæœ¬ä¼˜åŒ–ç­–ç•¥** - èµ„æºä½¿ç”¨ä¼˜åŒ–å’Œæˆæœ¬æ§åˆ¶
5. **å®¹é‡è§„åˆ’æŒ‡å—** - ç³»ç»Ÿå®¹é‡è¯„ä¼°å’Œæ‰©å±•è§„åˆ’
9. **ç”Ÿæˆå®Œæ•´æ–‡æ¡£** - è¾“å‡ºæœ€ç»ˆçš„å…¨æ ˆæ¶æ„æ–‡æ¡£

è¯·é€‰æ‹©æ‚¨å¸Œæœ›ç»§ç»­çš„æ–¹å‘ï¼ˆè¾“å…¥æ•°å­—1-9ï¼‰ï¼š