#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Knowledge RAG é¡¹ç›® - å…¨æ•…äº‹éªŒè¯å·¥å…·

åŠŸèƒ½ï¼š
- éªŒè¯æ‰€æœ‰ç”¨æˆ·æ•…äº‹çš„è‰ç¨¿è´¨é‡
- åŸºäºæ•…äº‹è‰ç¨¿æ£€æŸ¥æ¸…å•è¿›è¡Œè¯„ä¼°
- ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š
"""

import os
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


class StoryDraftValidator:
    """æ•…äº‹è‰ç¨¿éªŒè¯å™¨ - åŸºäºBMADæ•…äº‹è‰ç¨¿æ£€æŸ¥æ¸…å•"""

    def __init__(self, stories_dir: str):
        self.stories_dir = Path(stories_dir)
        self.validation_criteria = {
            "goal_context_clarity": "ç›®æ ‡å’Œä¸Šä¸‹æ–‡æ¸…æ™°åº¦",
            "technical_guidance": "æŠ€æœ¯å®æ–½æŒ‡å¯¼",
            "reference_effectiveness": "å¼•ç”¨æœ‰æ•ˆæ€§",
            "self_containment": "è‡ªåŒ…å«æ€§è¯„ä¼°",
            "testing_guidance": "æµ‹è¯•æŒ‡å¯¼",
        }

    def validate_story(self, story_path: Path) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªç”¨æˆ·æ•…äº‹"""
        try:
            with open(story_path, "r", encoding="utf-8") as f:
                content = f.read()
        except FileNotFoundError:
            return {"error": f"æ•…äº‹æ–‡ä»¶æœªæ‰¾åˆ°: {story_path}"}

        # éªŒè¯ç»“æœ
        validation_result = {
            "story_path": str(story_path),
            "story_name": story_path.name,
            "validation_details": {},
            "issues": [],
            "overall_status": "READY",
            "clarity_score": 10,
        }

        # 1. ç›®æ ‡å’Œä¸Šä¸‹æ–‡æ¸…æ™°åº¦
        goal_clarity = self._check_goal_context_clarity(content)
        validation_result["validation_details"]["goal_context_clarity"] = goal_clarity

        # 2. æŠ€æœ¯å®æ–½æŒ‡å¯¼
        tech_guidance = self._check_technical_guidance(content)
        validation_result["validation_details"]["technical_guidance"] = tech_guidance

        # 3. å¼•ç”¨æœ‰æ•ˆæ€§
        reference_effectiveness = self._check_reference_effectiveness(content)
        validation_result["validation_details"][
            "reference_effectiveness"
        ] = reference_effectiveness

        # 4. è‡ªåŒ…å«æ€§è¯„ä¼°
        self_containment = self._check_self_containment(content)
        validation_result["validation_details"]["self_containment"] = self_containment

        # 5. æµ‹è¯•æŒ‡å¯¼
        testing_guidance = self._check_testing_guidance(content)
        validation_result["validation_details"]["testing_guidance"] = testing_guidance

        # è®¡ç®—æ€»ä½“è¯„åˆ†å’ŒçŠ¶æ€
        self._calculate_overall_assessment(validation_result)

        return validation_result

    def _check_goal_context_clarity(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥ç›®æ ‡å’Œä¸Šä¸‹æ–‡æ¸…æ™°åº¦"""
        issues = []
        score = 10

        # æ£€æŸ¥æ•…äº‹æ ¼å¼
        if not all(
            phrase in content for phrase in ["**As a**", "**I want**", "**so that**"]
        ):
            issues.append("ç¼ºå°‘æ ‡å‡†çš„ç”¨æˆ·æ•…äº‹æ ¼å¼ (As a... I want... so that...)")
            score -= 3

        # æ£€æŸ¥ä¸šåŠ¡ä»·å€¼è¯´æ˜
        if "so that" in content:
            so_that_section = content.split("so that")[1].split("\n")[0]
            if len(so_that_section.strip()) < 20:
                issues.append("ä¸šåŠ¡ä»·å€¼è¯´æ˜è¿‡äºç®€çŸ­")
                score -= 2

        # æ£€æŸ¥Epicå…³è”
        if "Epic" not in content and "epic" not in content:
            issues.append("æœªæ˜ç¡®è¯´æ˜ä¸Epicçš„å…³è”")
            score -= 1

        # æ£€æŸ¥ä¾èµ–å…³ç³»
        if (
            "ä¾èµ–" not in content
            and "depends" not in content.lower()
            and "requires" not in content.lower()
        ):
            # å¯¹äºéåŸºç¡€æ•…äº‹ï¼Œåº”è¯¥æœ‰ä¾èµ–è¯´æ˜
            story_id = re.search(r"Story (\d+\.\d+)", content)
            if story_id and not story_id.group(1).startswith("1."):
                issues.append("æœªæ˜ç¡®è¯´æ˜å¯¹å…¶ä»–æ•…äº‹çš„ä¾èµ–å…³ç³»")
                score -= 1

        status = "PASS" if score >= 8 else "PARTIAL" if score >= 6 else "FAIL"

        return {"status": status, "score": max(1, score), "issues": issues}

    def _check_technical_guidance(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥æŠ€æœ¯å®æ–½æŒ‡å¯¼"""
        issues = []
        score = 10

        # æ£€æŸ¥æŠ€æœ¯æ ˆè¯´æ˜
        tech_keywords = [
            "Python",
            "FastAPI",
            "Docker",
            "PostgreSQL",
            "Redis",
            "Neo4j",
            "Weaviate",
        ]
        if not any(keyword in content for keyword in tech_keywords):
            issues.append("ç¼ºå°‘å…·ä½“çš„æŠ€æœ¯æ ˆè¯´æ˜")
            score -= 2

        # æ£€æŸ¥æ–‡ä»¶/ç»„ä»¶è¯´æ˜
        if (
            "æ–‡ä»¶" not in content
            and "ç»„ä»¶" not in content
            and "service" not in content.lower()
        ):
            issues.append("æœªè¯´æ˜éœ€è¦åˆ›å»ºæˆ–ä¿®æ”¹çš„å…³é”®æ–‡ä»¶/ç»„ä»¶")
            score -= 2

        # æ£€æŸ¥APIæ¥å£è¯´æ˜
        if "API" in content or "api" in content:
            if "æ¥å£" not in content and "endpoint" not in content.lower():
                issues.append("æåˆ°APIä½†æœªè¯¦ç»†è¯´æ˜æ¥å£è®¾è®¡")
                score -= 1

        # æ£€æŸ¥æ•°æ®æ¨¡å‹
        if "æ•°æ®" in content or "model" in content.lower():
            if "æ¨¡å‹" not in content and "schema" not in content.lower():
                issues.append("æåˆ°æ•°æ®ä½†æœªè¯´æ˜æ•°æ®æ¨¡å‹æˆ–ç»“æ„")
                score -= 1

        # æ£€æŸ¥é…ç½®è¯´æ˜
        if (
            "é…ç½®" not in content
            and "config" not in content.lower()
            and "ç¯å¢ƒå˜é‡" not in content
        ):
            issues.append("ç¼ºå°‘é…ç½®æˆ–ç¯å¢ƒå˜é‡è¯´æ˜")
            score -= 1

        status = "PASS" if score >= 8 else "PARTIAL" if score >= 6 else "FAIL"

        return {"status": status, "score": max(1, score), "issues": issues}

    def _check_reference_effectiveness(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥å¼•ç”¨æœ‰æ•ˆæ€§"""
        issues = []
        score = 10

        # æ£€æŸ¥æ–‡æ¡£å¼•ç”¨
        doc_references = re.findall(r"docs/[\w\-/]+\.md", content)
        if not doc_references:
            issues.append("ç¼ºå°‘å¯¹ç›¸å…³æ–‡æ¡£çš„å¼•ç”¨")
            score -= 2
        else:
            # æ£€æŸ¥å¼•ç”¨æ ¼å¼
            for ref in doc_references:
                if "#" not in ref:
                    issues.append(f"å¼•ç”¨ {ref} æœªæŒ‡å‘å…·ä½“ç« èŠ‚")
                    score -= 1

        # æ£€æŸ¥æ¶æ„æ–‡æ¡£å¼•ç”¨
        if "architecture.md" not in content:
            issues.append("æœªå¼•ç”¨æ¶æ„æ–‡æ¡£")
            score -= 1

        # æ£€æŸ¥å‰ç½®æ•…äº‹å¼•ç”¨
        story_refs = re.findall(r"Story \d+\.\d+", content)
        if len(story_refs) > 1:  # é™¤äº†è‡ªå·±
            # åº”è¯¥æœ‰å¯¹å‰ç½®æ•…äº‹çš„è¯´æ˜
            if "å®Œæˆ" not in content and "å®ç°" not in content:
                issues.append("å¼•ç”¨äº†å…¶ä»–æ•…äº‹ä½†æœªè¯´æ˜ä¾èµ–å…³ç³»")
                score -= 1

        status = "PASS" if score >= 8 else "PARTIAL" if score >= 6 else "FAIL"

        return {"status": status, "score": max(1, score), "issues": issues}

    def _check_self_containment(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥è‡ªåŒ…å«æ€§"""
        issues = []
        score = 10

        # æ£€æŸ¥æ ¸å¿ƒä¿¡æ¯å®Œæ•´æ€§
        required_sections = [
            "## Story",
            "## Acceptance Criteria",
            "## Tasks",
            "## Dev Notes",
        ]
        missing_sections = [
            section for section in required_sections if section not in content
        ]
        if missing_sections:
            issues.append(f"ç¼ºå°‘å¿…éœ€ç« èŠ‚: {', '.join(missing_sections)}")
            score -= len(missing_sections) * 2

        # æ£€æŸ¥éªŒæ”¶æ ‡å‡†æ•°é‡
        ac_lines = [
            line
            for line in content.split("\n")
            if line.strip() and re.match(r"^\d+\.", line.strip())
        ]
        if len(ac_lines) < 3:
            issues.append("éªŒæ”¶æ ‡å‡†æ•°é‡ä¸è¶³ï¼Œå»ºè®®è‡³å°‘3ä¸ª")
            score -= 2

        # æ£€æŸ¥ä»»åŠ¡åˆ†è§£
        task_lines = [
            line for line in content.split("\n") if line.strip().startswith("- [ ]")
        ]
        if len(task_lines) < 3:
            issues.append("ä»»åŠ¡åˆ†è§£ä¸å¤Ÿè¯¦ç»†ï¼Œå»ºè®®è‡³å°‘3ä¸ªä¸»è¦ä»»åŠ¡")
            score -= 1

        # æ£€æŸ¥å¼€å‘æ³¨é‡Š
        if "## Dev Notes" in content:
            dev_notes_section = content.split("## Dev Notes")[1].split("##")[0]
            if len(dev_notes_section.strip()) < 100:
                issues.append("å¼€å‘æ³¨é‡Šè¿‡äºç®€çŸ­ï¼Œç¼ºå°‘æŠ€æœ¯å®æ–½ç»†èŠ‚")
                score -= 1

        # æ£€æŸ¥æœ¯è¯­è§£é‡Š
        technical_terms = ["GraphRAG", "å‘é‡åŒ–", "çŸ¥è¯†å›¾è°±", "å®ä½“æå–", "è¯­ä¹‰æ£€ç´¢"]
        used_terms = [term for term in technical_terms if term in content]
        if used_terms and "è¯´æ˜" not in content and "è§£é‡Š" not in content:
            issues.append("ä½¿ç”¨äº†ä¸“ä¸šæœ¯è¯­ä½†ç¼ºå°‘è§£é‡Šè¯´æ˜")
            score -= 1

        status = "PASS" if score >= 8 else "PARTIAL" if score >= 6 else "FAIL"

        return {"status": status, "score": max(1, score), "issues": issues}

    def _check_testing_guidance(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥æµ‹è¯•æŒ‡å¯¼"""
        issues = []
        score = 10

        # æ£€æŸ¥æµ‹è¯•ç« èŠ‚
        if "Testing" not in content and "æµ‹è¯•" not in content:
            issues.append("ç¼ºå°‘æµ‹è¯•æŒ‡å¯¼ç« èŠ‚")
            score -= 3

        # æ£€æŸ¥æµ‹è¯•ç±»å‹è¯´æ˜
        test_types = [
            "å•å…ƒæµ‹è¯•",
            "é›†æˆæµ‹è¯•",
            "ç«¯åˆ°ç«¯æµ‹è¯•",
            "unit",
            "integration",
            "e2e",
        ]
        if not any(test_type in content.lower() for test_type in test_types):
            issues.append("æœªè¯´æ˜æµ‹è¯•ç±»å‹å’Œç­–ç•¥")
            score -= 2

        # æ£€æŸ¥æµ‹è¯•æ¡†æ¶
        test_frameworks = ["pytest", "unittest", "testcontainers", "locust"]
        if not any(framework in content.lower() for framework in test_frameworks):
            issues.append("æœªæŒ‡å®šæµ‹è¯•æ¡†æ¶")
            score -= 1

        # æ£€æŸ¥æµ‹è¯•åœºæ™¯
        if "åœºæ™¯" not in content and "scenario" not in content.lower():
            issues.append("ç¼ºå°‘å…·ä½“çš„æµ‹è¯•åœºæ™¯è¯´æ˜")
            score -= 1

        # æ£€æŸ¥æˆåŠŸæ ‡å‡†
        if "è¦†ç›–ç‡" not in content and "coverage" not in content.lower():
            issues.append("æœªè¯´æ˜æµ‹è¯•è¦†ç›–ç‡è¦æ±‚")
            score -= 1

        status = "PASS" if score >= 8 else "PARTIAL" if score >= 6 else "FAIL"

        return {"status": status, "score": max(1, score), "issues": issues}

    def _calculate_overall_assessment(self, validation_result: Dict[str, Any]):
        """è®¡ç®—æ€»ä½“è¯„ä¼°"""
        details = validation_result["validation_details"]

        # è®¡ç®—å¹³å‡åˆ†
        total_score = sum(detail["score"] for detail in details.values())
        avg_score = total_score / len(details)

        # æ”¶é›†æ‰€æœ‰é—®é¢˜
        all_issues = []
        for detail in details.values():
            all_issues.extend(detail["issues"])

        # ç¡®å®šçŠ¶æ€
        fail_count = sum(1 for detail in details.values() if detail["status"] == "FAIL")
        partial_count = sum(
            1 for detail in details.values() if detail["status"] == "PARTIAL"
        )

        if fail_count > 0:
            overall_status = "BLOCKED"
        elif partial_count > 2:
            overall_status = "NEEDS REVISION"
        elif len(all_issues) > 5:
            overall_status = "NEEDS REVISION"
        else:
            overall_status = "READY"

        validation_result["overall_status"] = overall_status
        validation_result["clarity_score"] = round(avg_score, 1)
        validation_result["issues"] = all_issues

    def validate_all_stories(self) -> List[Dict[str, Any]]:
        """éªŒè¯æ‰€æœ‰æ•…äº‹"""
        story_files = sorted(self.stories_dir.glob("*.md"))
        results = []

        print(f"\nğŸ“‹ å¼€å§‹éªŒè¯ {len(story_files)} ä¸ªç”¨æˆ·æ•…äº‹...")
        print("=" * 60)

        for story_file in story_files:
            print(f"\nğŸ” éªŒè¯æ•…äº‹: {story_file.name}")
            result = self.validate_story(story_file)
            results.append(result)

            # æ˜¾ç¤ºéªŒè¯ç»“æœ
            if "error" in result:
                print(f"  âŒ é”™è¯¯: {result['error']}")
            else:
                status_icon = {
                    "READY": "âœ…",
                    "NEEDS REVISION": "âš ï¸",
                    "BLOCKED": "ğŸš«",
                }.get(result["overall_status"], "â“")

                print(f"  {status_icon} çŠ¶æ€: {result['overall_status']}")
                print(f"  ğŸ“Š è¯„åˆ†: {result['clarity_score']}/10")

                if result["issues"]:
                    print(f"  âš ï¸  é—®é¢˜æ•°é‡: {len(result['issues'])}")
                    for issue in result["issues"][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                        print(f"     - {issue}")
                    if len(result["issues"]) > 3:
                        print(f"     ... è¿˜æœ‰ {len(result['issues']) - 3} ä¸ªé—®é¢˜")

        return results

    def generate_comprehensive_report(
        self, validation_results: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # ç»Ÿè®¡æ•°æ®
        total_stories = len([r for r in validation_results if "error" not in r])
        ready_count = sum(
            1 for r in validation_results if r.get("overall_status") == "READY"
        )
        needs_revision_count = sum(
            1 for r in validation_results if r.get("overall_status") == "NEEDS REVISION"
        )
        blocked_count = sum(
            1 for r in validation_results if r.get("overall_status") == "BLOCKED"
        )

        avg_score = sum(
            r.get("clarity_score", 0) for r in validation_results if "error" not in r
        ) / max(total_stories, 1)

        report = f"""# Knowledge RAG é¡¹ç›® - å…¨æ•…äº‹è‰ç¨¿éªŒè¯æŠ¥å‘Š

**éªŒè¯æ—¶é—´**: {timestamp}  
**éªŒè¯å·¥å…·**: BMAD æ•…äº‹è‰ç¨¿æ£€æŸ¥æ¸…å•  
**éªŒè¯èŒƒå›´**: å…¨éƒ¨ç”¨æˆ·æ•…äº‹  
**éªŒè¯æ•…äº‹æ•°é‡**: {total_stories}

---

## ğŸ“Š éªŒè¯æ‘˜è¦

### æ€»ä½“çŠ¶æ€åˆ†å¸ƒ
- âœ… **å‡†å¤‡å°±ç»ª**: {ready_count} ({ready_count/max(total_stories,1)*100:.1f}%)
- âš ï¸ **éœ€è¦ä¿®è®¢**: {needs_revision_count} ({needs_revision_count/max(total_stories,1)*100:.1f}%)
- ğŸš« **é˜»å¡çŠ¶æ€**: {blocked_count} ({blocked_count/max(total_stories,1)*100:.1f}%)

### è´¨é‡æŒ‡æ ‡
- **å¹³å‡æ¸…æ™°åº¦è¯„åˆ†**: {avg_score:.1f}/10
- **éªŒè¯é€šè¿‡ç‡**: {ready_count/max(total_stories,1)*100:.1f}%
- **éœ€è¦æ”¹è¿›ç‡**: {(needs_revision_count + blocked_count)/max(total_stories,1)*100:.1f}%

---

## ğŸ“‹ è¯¦ç»†éªŒè¯ç»“æœ

"""

        # æŒ‰Epicåˆ†ç»„æ˜¾ç¤ºç»“æœ
        epics = {}
        for result in validation_results:
            if "error" in result:
                continue

            story_name = result["story_name"]
            epic_id = story_name.split(".")[0]
            if epic_id not in epics:
                epics[epic_id] = []
            epics[epic_id].append(result)

        epic_names = {
            "1": "Epic 1: åŸºç¡€æ¶æ„å’Œæ ¸å¿ƒæœåŠ¡å»ºè®¾",
            "2": "Epic 2: æ™ºèƒ½æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±æ„å»º",
            "3": "Epic 3: GraphRAGå’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
            "4": "Epic 4: APIæ¥å£å’ŒæœåŠ¡é›†æˆ",
            "5": "Epic 5: é«˜çº§åŠŸèƒ½å’Œä¸ªæ€§åŒ–æœåŠ¡",
            "6": "Epic 6: ç¬¬ä¸‰æ–¹é›†æˆå’ŒMCPåè®®å®ç°",
            "7": "Epic 7: æ€§èƒ½ä¼˜åŒ–å’Œç³»ç»Ÿæ‰©å±•",
            "8": "Epic 8: å®‰å…¨åŠ å›ºå’Œåˆè§„è®¤è¯",
        }

        for epic_id in sorted(epics.keys()):
            epic_stories = epics[epic_id]
            epic_name = epic_names.get(epic_id, f"Epic {epic_id}")

            report += f"### {epic_name}\n\n"

            for result in sorted(epic_stories, key=lambda x: x["story_name"]):
                status_icon = {
                    "READY": "âœ…",
                    "NEEDS REVISION": "âš ï¸",
                    "BLOCKED": "ğŸš«",
                }.get(result["overall_status"], "â“")

                report += f"#### {status_icon} {result['story_name']}\n\n"
                report += f"**çŠ¶æ€**: {result['overall_status']}  \n"
                report += f"**æ¸…æ™°åº¦è¯„åˆ†**: {result['clarity_score']}/10  \n"

                # è¯¦ç»†éªŒè¯ç»“æœ
                report += f"\n**éªŒè¯è¯¦æƒ…**:\n"
                for criteria, details in result["validation_details"].items():
                    criteria_name = self.validation_criteria[criteria]
                    status_icon_detail = {
                        "PASS": "âœ…",
                        "PARTIAL": "âš ï¸",
                        "FAIL": "âŒ",
                    }.get(details["status"], "â“")
                    report += f"- {status_icon_detail} {criteria_name}: {details['status']} ({details['score']}/10)\n"

                if result["issues"]:
                    report += f"\n**éœ€è¦æ”¹è¿›çš„é—®é¢˜**:\n"
                    for issue in result["issues"]:
                        report += f"- {issue}\n"

                report += "\n---\n\n"

        # æ·»åŠ æ”¹è¿›å»ºè®®
        report += self._generate_improvement_recommendations(validation_results)

        return report

    def _generate_improvement_recommendations(
        self, validation_results: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        # ç»Ÿè®¡å¸¸è§é—®é¢˜
        issue_counts = {}
        for result in validation_results:
            if "error" in result:
                continue
            for issue in result.get("issues", []):
                issue_counts[issue] = issue_counts.get(issue, 0) + 1

        # è·å–æœ€å¸¸è§çš„é—®é¢˜
        common_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[
            :5
        ]

        recommendations = """## ğŸ¯ æ”¹è¿›å»ºè®®

### å¸¸è§é—®é¢˜åˆ†æ

"""

        for issue, count in common_issues:
            recommendations += f"- **{issue}** (å½±å“ {count} ä¸ªæ•…äº‹)\n"

        recommendations += """

### ä¼˜å…ˆæ”¹è¿›å»ºè®®

1. **åŠ å¼ºæŠ€æœ¯å®æ–½æŒ‡å¯¼**
   - æ˜ç¡®æŒ‡å®šéœ€è¦åˆ›å»ºæˆ–ä¿®æ”¹çš„å…³é”®æ–‡ä»¶å’Œç»„ä»¶
   - è¯¦ç»†è¯´æ˜APIæ¥å£è®¾è®¡å’Œæ•°æ®æ¨¡å‹
   - æä¾›å…·ä½“çš„é…ç½®å’Œç¯å¢ƒå˜é‡è¯´æ˜

2. **å®Œå–„æµ‹è¯•æŒ‡å¯¼**
   - æ˜ç¡®æµ‹è¯•ç±»å‹å’Œç­–ç•¥
   - æŒ‡å®šæµ‹è¯•æ¡†æ¶å’Œå·¥å…·
   - å®šä¹‰æµ‹è¯•è¦†ç›–ç‡è¦æ±‚å’ŒæˆåŠŸæ ‡å‡†

3. **ä¼˜åŒ–å¼•ç”¨æ•ˆæœ**
   - å¼•ç”¨æ–‡æ¡£æ—¶æŒ‡å‘å…·ä½“ç« èŠ‚
   - åœ¨æ•…äº‹ä¸­æ€»ç»“å…³é”®ä¿¡æ¯ï¼Œå‡å°‘å¯¹å¤–éƒ¨æ–‡æ¡£çš„ä¾èµ–
   - æ˜ç¡®è¯´æ˜ä¸å…¶ä»–æ•…äº‹çš„ä¾èµ–å…³ç³»

4. **å¢å¼ºè‡ªåŒ…å«æ€§**
   - ç¡®ä¿æ‰€æœ‰å¿…éœ€ç« èŠ‚å®Œæ•´
   - æä¾›å……åˆ†çš„éªŒæ”¶æ ‡å‡†ï¼ˆå»ºè®®è‡³å°‘3ä¸ªï¼‰
   - è¯¦ç»†çš„ä»»åŠ¡åˆ†è§£å’Œå¼€å‘æ³¨é‡Š

### è´¨é‡ä¿è¯å»ºè®®

- **å»ºç«‹æ•…äº‹å®¡æŸ¥æµç¨‹**: åœ¨å®æ–½å‰è¿›è¡ŒåŒè¡Œè¯„å®¡
- **å®šæœŸè´¨é‡æ£€æŸ¥**: æ¯ä¸ªSprintç»“æŸåå›é¡¾æ•…äº‹è´¨é‡
- **æ¨¡æ¿æ ‡å‡†åŒ–**: åŸºäºé«˜è´¨é‡æ•…äº‹åˆ›å»ºæ ‡å‡†æ¨¡æ¿
- **åŸ¹è®­å’ŒæŒ‡å¯¼**: ä¸ºæ•…äº‹ç¼–å†™è€…æä¾›æœ€ä½³å®è·µåŸ¹è®­

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**éªŒè¯å·¥å…·ç‰ˆæœ¬**: BMAD Story Draft Checklist v1.0  
**ä¸‹æ¬¡å»ºè®®éªŒè¯**: æ•…äº‹æ›´æ–°åæˆ–æ¯å‘¨å®šæœŸéªŒè¯
"""

        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    print("Knowledge RAG é¡¹ç›® - å…¨æ•…äº‹è‰ç¨¿éªŒè¯å·¥å…·")
    print("=" * 50)

    # åˆå§‹åŒ–éªŒè¯å™¨
    stories_dir = "/Users/zhanyuanwei/Desktop/Knowledge_RAG/docs/stories"
    validator = StoryDraftValidator(stories_dir)

    # éªŒè¯æ‰€æœ‰æ•…äº‹
    results = validator.validate_all_stories()

    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š...")
    report = validator.generate_comprehensive_report(results)

    # ä¿å­˜æŠ¥å‘Š
    report_path = "/Users/zhanyuanwei/Desktop/Knowledge_RAG/docs/comprehensive-story-draft-validation-report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nâœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    total_stories = len([r for r in results if "error" not in r])
    ready_count = sum(1 for r in results if r.get("overall_status") == "READY")
    needs_revision_count = sum(
        1 for r in results if r.get("overall_status") == "NEEDS REVISION"
    )
    blocked_count = sum(1 for r in results if r.get("overall_status") == "BLOCKED")

    print("\nğŸ“Š éªŒè¯ç»Ÿè®¡:")
    print(f"   æ€»æ•…äº‹æ•°: {total_stories}")
    print(f"   å‡†å¤‡å°±ç»ª: {ready_count} ({ready_count/max(total_stories,1)*100:.1f}%)")
    print(
        f"   éœ€è¦ä¿®è®¢: {needs_revision_count} ({needs_revision_count/max(total_stories,1)*100:.1f}%)"
    )
    print(
        f"   é˜»å¡çŠ¶æ€: {blocked_count} ({blocked_count/max(total_stories,1)*100:.1f}%)"
    )

    if ready_count == total_stories:
        print("\nğŸ‰ æ‰€æœ‰æ•…äº‹éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹å®æ–½ï¼")
    elif needs_revision_count > 0:
        print(f"\nâš ï¸  æœ‰ {needs_revision_count} ä¸ªæ•…äº‹éœ€è¦ä¿®è®¢")
    if blocked_count > 0:
        print(f"\nğŸš« æœ‰ {blocked_count} ä¸ªæ•…äº‹å¤„äºé˜»å¡çŠ¶æ€ï¼Œéœ€è¦ç«‹å³å¤„ç†")


if __name__ == "__main__":
    main()
