#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Knowledge RAG System - æµ‹è¯•ç¯å¢ƒæ¸…ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæ¸…ç†æµ‹è¯•ç¯å¢ƒï¼ŒåŒ…æ‹¬ï¼š
1. æ¸…ç†æµ‹è¯•æ•°æ®åº“æ•°æ®
2. æ¸…ç†Redisç¼“å­˜
3. æ¸…ç†Elasticsearchç´¢å¼•
4. æ¸…ç†Neo4jå›¾æ•°æ®
5. é‡ç½®æµ‹è¯•ç¯å¢ƒåˆ°åˆå§‹çŠ¶æ€

ä½œè€…: Knowledge RAG Team
åˆ›å»ºæ—¶é—´: 2024-01-20
"""

import asyncio
import logging
import os
import sys
from typing import Optional

import asyncpg
import redis.asyncio as redis
from elasticsearch import AsyncElasticsearch
from neo4j import AsyncGraphDatabase

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/tmp/test_cleanup.log')
    ]
)
logger = logging.getLogger(__name__)


class TestEnvironmentCleaner:
    """
    æµ‹è¯•ç¯å¢ƒæ¸…ç†å™¨
    
    è´Ÿè´£æ¸…ç†æ‰€æœ‰æµ‹è¯•ç¯å¢ƒçš„æ•°æ®å’Œé…ç½®
    """
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®"""
        self.database_url = os.getenv('DATABASE_URL', 'postgresql+asyncpg://testuser:testpass123@postgres-test:5432/knowledge_rag_test')
        self.redis_url = os.getenv('REDIS_URL', 'redis://redis-test:6379/0')
        self.elasticsearch_url = os.getenv('ELASTICSEARCH_URL', 'http://elasticsearch-test:9200')
        self.neo4j_uri = os.getenv('NEO4J_URI', 'bolt://neo4j-test:7687')
        self.neo4j_user = os.getenv('NEO4J_USER', 'neo4j')
        self.neo4j_password = os.getenv('NEO4J_PASSWORD', 'testpass123')
        
        # è¿æ¥å¯¹è±¡
        self.pg_pool: Optional[asyncpg.Pool] = None
        self.redis_client: Optional[redis.Redis] = None
        self.es_client: Optional[AsyncElasticsearch] = None
        self.neo4j_driver = None
    
    async def cleanup_all(self, force: bool = False) -> bool:
        """
        æ¸…ç†æ‰€æœ‰æµ‹è¯•æ•°æ®
        
        Args:
            force: æ˜¯å¦å¼ºåˆ¶æ¸…ç†ï¼ˆè·³è¿‡ç¡®è®¤ï¼‰
        
        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            if not force:
                confirmation = input("âš ï¸  ç¡®å®šè¦æ¸…ç†æ‰€æœ‰æµ‹è¯•æ•°æ®å—ï¼Ÿè¿™ä¸ªæ“ä½œä¸å¯é€†ï¼(y/N): ")
                if confirmation.lower() not in ['y', 'yes']:
                    logger.info("âŒ ç”¨æˆ·å–æ¶ˆæ¸…ç†æ“ä½œ")
                    return False
            
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
            
            # 1. å»ºç«‹æ•°æ®åº“è¿æ¥
            await self._setup_connections()
            
            # 2. æ¸…ç†PostgreSQLæ•°æ®
            await self._cleanup_postgresql()
            
            # 3. æ¸…ç†Redisæ•°æ®
            await self._cleanup_redis()
            
            # 4. æ¸…ç†Elasticsearchæ•°æ®
            await self._cleanup_elasticsearch()
            
            # 5. æ¸…ç†Neo4jæ•°æ®
            await self._cleanup_neo4j()
            
            # 6. éªŒè¯æ¸…ç†ç»“æœ
            await self._verify_cleanup()
            
            logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•ç¯å¢ƒæ¸…ç†å¤±è´¥: {e}")
            return False
        finally:
            await self._cleanup_connections()
    
    async def cleanup_specific(self, components: list) -> bool:
        """
        æ¸…ç†æŒ‡å®šç»„ä»¶çš„æµ‹è¯•æ•°æ®
        
        Args:
            components: è¦æ¸…ç†çš„ç»„ä»¶åˆ—è¡¨ ['postgresql', 'redis', 'elasticsearch', 'neo4j']
        
        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†æŒ‡å®šç»„ä»¶: {', '.join(components)}")
            
            # å»ºç«‹è¿æ¥
            await self._setup_connections()
            
            # æ ¹æ®æŒ‡å®šç»„ä»¶è¿›è¡Œæ¸…ç†
            if 'postgresql' in components:
                await self._cleanup_postgresql()
            
            if 'redis' in components:
                await self._cleanup_redis()
            
            if 'elasticsearch' in components:
                await self._cleanup_elasticsearch()
            
            if 'neo4j' in components:
                await self._cleanup_neo4j()
            
            logger.info("âœ… æŒ‡å®šç»„ä»¶æ¸…ç†å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æŒ‡å®šç»„ä»¶æ¸…ç†å¤±è´¥: {e}")
            return False
        finally:
            await self._cleanup_connections()
    
    async def _setup_connections(self):
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        logger.info("ğŸ“¡ å»ºç«‹æ•°æ®åº“è¿æ¥...")
        
        # PostgreSQLè¿æ¥
        try:
            import urllib.parse
            parsed = urllib.parse.urlparse(self.database_url.replace('postgresql+asyncpg://', 'postgresql://'))
            
            self.pg_pool = await asyncpg.create_pool(
                host=parsed.hostname,
                port=parsed.port or 5432,
                user=parsed.username,
                password=parsed.password,
                database=parsed.path.lstrip('/'),
                min_size=1,
                max_size=5
            )
            logger.info("âœ… PostgreSQLè¿æ¥å»ºç«‹æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ PostgreSQLè¿æ¥å¤±è´¥: {e}")
        
        # Redisè¿æ¥
        try:
            self.redis_client = redis.from_url(self.redis_url)
            await self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥å»ºç«‹æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Redisè¿æ¥å¤±è´¥: {e}")
        
        # Elasticsearchè¿æ¥
        try:
            self.es_client = AsyncElasticsearch([self.elasticsearch_url])
            await self.es_client.info()
            logger.info("âœ… Elasticsearchè¿æ¥å»ºç«‹æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Elasticsearchè¿æ¥å¤±è´¥: {e}")
        
        # Neo4jè¿æ¥
        try:
            self.neo4j_driver = AsyncGraphDatabase.driver(
                self.neo4j_uri,
                auth=(self.neo4j_user, self.neo4j_password)
            )
            # æµ‹è¯•è¿æ¥
            async with self.neo4j_driver.session() as session:
                await session.run("RETURN 1")
            logger.info("âœ… Neo4jè¿æ¥å»ºç«‹æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Neo4jè¿æ¥å¤±è´¥: {e}")
    
    async def _cleanup_postgresql(self):
        """æ¸…ç†PostgreSQLæµ‹è¯•æ•°æ®"""
        if not self.pg_pool:
            logger.warning("âš ï¸ PostgreSQLè¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        logger.info("ğŸ—„ï¸ æ¸…ç†PostgreSQLæµ‹è¯•æ•°æ®...")
        
        async with self.pg_pool.acquire() as conn:
            # è·å–æ¸…ç†å‰çš„æ•°æ®ç»Ÿè®¡
            stats_before = await self._get_postgresql_stats(conn)
            logger.info(f"æ¸…ç†å‰æ•°æ®ç»Ÿè®¡: {stats_before}")
            
            # æ¸…ç†æ•°æ®çš„SQLè¯­å¥ï¼ˆæŒ‰ä¾èµ–å…³ç³»é¡ºåºï¼‰
            cleanup_queries = [
                "DELETE FROM notifications WHERE user_id IN (SELECT id FROM users WHERE email LIKE '%@test.com')",
                "DELETE FROM entity_relationships WHERE source_entity_id IN (SELECT id FROM entities WHERE description LIKE '%æµ‹è¯•%')",
                "DELETE FROM document_entities WHERE entity_id IN (SELECT id FROM entities WHERE description LIKE '%æµ‹è¯•%')",
                "DELETE FROM entities WHERE description LIKE '%æµ‹è¯•%'",
                "DELETE FROM messages WHERE conversation_id IN (SELECT id FROM conversations WHERE title LIKE '%æµ‹è¯•%')",
                "DELETE FROM conversations WHERE title LIKE '%æµ‹è¯•%'",
                "DELETE FROM document_chunks WHERE document_id IN (SELECT id FROM documents WHERE title LIKE '%æµ‹è¯•%')",
                "DELETE FROM documents WHERE title LIKE '%æµ‹è¯•%'",
                "DELETE FROM user_profiles WHERE user_id IN (SELECT id FROM users WHERE email LIKE '%@test.com')",
                "DELETE FROM users WHERE email LIKE '%@test.com'",
                
                # é‡ç½®åºåˆ—
                "SELECT setval('users_id_seq', COALESCE((SELECT MAX(id) FROM users), 1), false)",
                "SELECT setval('documents_id_seq', COALESCE((SELECT MAX(id) FROM documents), 1), false)",
                "SELECT setval('conversations_id_seq', COALESCE((SELECT MAX(id) FROM conversations), 1), false)",
                "SELECT setval('messages_id_seq', COALESCE((SELECT MAX(id) FROM messages), 1), false)",
                "SELECT setval('entities_id_seq', COALESCE((SELECT MAX(id) FROM entities), 1), false)",
                "SELECT setval('notifications_id_seq', COALESCE((SELECT MAX(id) FROM notifications), 1), false)"
            ]
            
            # æ‰§è¡Œæ¸…ç†
            for query in cleanup_queries:
                try:
                    result = await conn.execute(query)
                    if query.startswith('DELETE'):
                        # æå–åˆ é™¤çš„è¡Œæ•°
                        rows_affected = int(result.split()[-1]) if result.split()[-1].isdigit() else 0
                        if rows_affected > 0:
                            logger.info(f"åˆ é™¤äº† {rows_affected} è¡Œ: {query[:50]}...")
                except Exception as e:
                    logger.error(f"æ‰§è¡Œæ¸…ç†æŸ¥è¯¢å¤±è´¥: {query[:50]}... - {e}")
            
            # è·å–æ¸…ç†åçš„æ•°æ®ç»Ÿè®¡
            stats_after = await self._get_postgresql_stats(conn)
            logger.info(f"æ¸…ç†åæ•°æ®ç»Ÿè®¡: {stats_after}")
        
        logger.info("âœ… PostgreSQLæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
    
    async def _get_postgresql_stats(self, conn) -> dict:
        """è·å–PostgreSQLæ•°æ®ç»Ÿè®¡"""
        tables = ['users', 'documents', 'conversations', 'messages', 'entities', 'notifications']
        stats = {}
        
        for table in tables:
            try:
                count = await conn.fetchval(f"SELECT COUNT(*) FROM {table}")
                stats[table] = count
            except Exception as e:
                stats[table] = f"Error: {e}"
        
        return stats
    
    async def _cleanup_redis(self):
        """æ¸…ç†Redisæµ‹è¯•æ•°æ®"""
        if not self.redis_client:
            logger.warning("âš ï¸ Redisè¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        logger.info("ğŸ“¦ æ¸…ç†Redisæµ‹è¯•æ•°æ®...")
        
        try:
            # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
            info_before = await self.redis_client.info('keyspace')
            logger.info(f"æ¸…ç†å‰Redisç»Ÿè®¡: {info_before}")
            
            # æ¸…ç†æµ‹è¯•ç›¸å…³çš„é”®
            test_patterns = [
                "session:test_*",
                "document:*test*",
                "rate_limit:user:*test*",
                "cache:*test*",
                "temp:*test*"
            ]
            
            total_deleted = 0
            for pattern in test_patterns:
                keys = await self.redis_client.keys(pattern)
                if keys:
                    deleted = await self.redis_client.delete(*keys)
                    total_deleted += deleted
                    logger.info(f"åˆ é™¤äº† {deleted} ä¸ªé”®ï¼Œæ¨¡å¼: {pattern}")
            
            # ä¹Ÿå¯ä»¥é€‰æ‹©æ¸…ç©ºæ•´ä¸ªæµ‹è¯•æ•°æ®åº“
            # await self.redis_client.flushdb()
            
            # è·å–æ¸…ç†åçš„ç»Ÿè®¡
            info_after = await self.redis_client.info('keyspace')
            logger.info(f"æ¸…ç†åRedisç»Ÿè®¡: {info_after}")
            logger.info(f"æ€»å…±åˆ é™¤äº† {total_deleted} ä¸ªé”®")
            
        except Exception as e:
            logger.error(f"Redisæ¸…ç†å¤±è´¥: {e}")
        
        logger.info("âœ… Redisæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
    
    async def _cleanup_elasticsearch(self):
        """æ¸…ç†Elasticsearchæµ‹è¯•æ•°æ®"""
        if not self.es_client:
            logger.warning("âš ï¸ Elasticsearchè¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        logger.info("ğŸ” æ¸…ç†Elasticsearchæµ‹è¯•æ•°æ®...")
        
        try:
            # è·å–æ‰€æœ‰ç´¢å¼•
            indices_response = await self.es_client.cat.indices(format='json')
            test_indices = [idx['index'] for idx in indices_response if 'test' in idx['index'] or idx['index'] in ['documents', 'document_chunks']]
            
            logger.info(f"å‘ç°æµ‹è¯•ç´¢å¼•: {test_indices}")
            
            # åˆ é™¤æµ‹è¯•ç´¢å¼•
            for index in test_indices:
                try:
                    # è·å–ç´¢å¼•ç»Ÿè®¡
                    stats = await self.es_client.count(index=index)
                    doc_count = stats['count']
                    
                    if doc_count > 0:
                        # åˆ é™¤ç´¢å¼•ä¸­çš„æµ‹è¯•æ•°æ®
                        delete_query = {
                            "query": {
                                "bool": {
                                    "should": [
                                        {"wildcard": {"title": "*æµ‹è¯•*"}},
                                        {"wildcard": {"content": "*æµ‹è¯•*"}},
                                        {"term": {"user_id": "550e8400-e29b-41d4-a716-446655440002"}}
                                    ]
                                }
                            }
                        }
                        
                        result = await self.es_client.delete_by_query(index=index, body=delete_query)
                        deleted = result.get('deleted', 0)
                        logger.info(f"ä»ç´¢å¼• {index} åˆ é™¤äº† {deleted} ä¸ªæ–‡æ¡£")
                    
                    # æˆ–è€…ç›´æ¥åˆ é™¤æ•´ä¸ªç´¢å¼•
                    # await self.es_client.indices.delete(index=index)
                    # logger.info(f"åˆ é™¤äº†ç´¢å¼•: {index}")
                    
                except Exception as e:
                    logger.error(f"æ¸…ç†ç´¢å¼• {index} å¤±è´¥: {e}")
            
            # åˆ·æ–°ç´¢å¼•
            for index in test_indices:
                try:
                    await self.es_client.indices.refresh(index=index)
                except:
                    pass
            
        except Exception as e:
            logger.error(f"Elasticsearchæ¸…ç†å¤±è´¥: {e}")
        
        logger.info("âœ… Elasticsearchæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
    
    async def _cleanup_neo4j(self):
        """æ¸…ç†Neo4jæµ‹è¯•æ•°æ®"""
        if not self.neo4j_driver:
            logger.warning("âš ï¸ Neo4jè¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†")
            return
        
        logger.info("ğŸ•¸ï¸ æ¸…ç†Neo4jæµ‹è¯•æ•°æ®...")
        
        try:
            async with self.neo4j_driver.session() as session:
                # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
                result = await session.run("MATCH (n) WHERE n.test_data = true RETURN labels(n) as labels, count(n) as count")
                stats_before = {}
                async for record in result:
                    labels = record['labels']
                    count = record['count']
                    for label in labels:
                        if label != 'test_data':
                            stats_before[label] = stats_before.get(label, 0) + count
                
                logger.info(f"æ¸…ç†å‰Neo4jç»Ÿè®¡: {stats_before}")
                
                # åˆ é™¤æ‰€æœ‰æµ‹è¯•æ•°æ®èŠ‚ç‚¹å’Œå…³ç³»
                result = await session.run("MATCH (n) WHERE n.test_data = true DETACH DELETE n RETURN count(n) as deleted")
                async for record in result:
                    deleted_count = record['deleted']
                    logger.info(f"åˆ é™¤äº† {deleted_count} ä¸ªæµ‹è¯•èŠ‚ç‚¹")
                
                # åˆ é™¤æµ‹è¯•ç”¨æˆ·ç›¸å…³çš„æ•°æ®
                test_user_queries = [
                    "MATCH (u:User) WHERE u.email ENDS WITH '@test.com' DETACH DELETE u",
                    "MATCH (d:Document) WHERE d.title CONTAINS 'æµ‹è¯•' DETACH DELETE d",
                    "MATCH (e:Entity) WHERE e.description CONTAINS 'æµ‹è¯•' DETACH DELETE e"
                ]
                
                for query in test_user_queries:
                    try:
                        result = await session.run(query)
                        # Neo4jä¸ç›´æ¥è¿”å›åˆ é™¤è®¡æ•°ï¼Œä½†æˆ‘ä»¬å¯ä»¥è®°å½•æ‰§è¡Œ
                        logger.info(f"æ‰§è¡Œæ¸…ç†æŸ¥è¯¢: {query[:50]}...")
                    except Exception as e:
                        logger.error(f"æ‰§è¡ŒNeo4jæ¸…ç†æŸ¥è¯¢å¤±è´¥: {query[:50]}... - {e}")
                
                # è·å–æ¸…ç†åçš„ç»Ÿè®¡
                result = await session.run("MATCH (n) RETURN labels(n) as labels, count(n) as count")
                stats_after = {}
                async for record in result:
                    labels = record['labels']
                    count = record['count']
                    for label in labels:
                        stats_after[label] = stats_after.get(label, 0) + count
                
                logger.info(f"æ¸…ç†åNeo4jç»Ÿè®¡: {stats_after}")
                
        except Exception as e:
            logger.error(f"Neo4jæ¸…ç†å¤±è´¥: {e}")
        
        logger.info("âœ… Neo4jæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
    
    async def _verify_cleanup(self):
        """éªŒè¯æ¸…ç†ç»“æœ"""
        logger.info("ğŸ” éªŒè¯æ¸…ç†ç»“æœ...")
        
        issues = []
        
        # éªŒè¯PostgreSQL
        if self.pg_pool:
            try:
                async with self.pg_pool.acquire() as conn:
                    test_users = await conn.fetchval("SELECT COUNT(*) FROM users WHERE email LIKE '%@test.com'")
                    test_docs = await conn.fetchval("SELECT COUNT(*) FROM documents WHERE title LIKE '%æµ‹è¯•%'")
                    
                    if test_users > 0:
                        issues.append(f"PostgreSQLä¸­ä»æœ‰ {test_users} ä¸ªæµ‹è¯•ç”¨æˆ·")
                    if test_docs > 0:
                        issues.append(f"PostgreSQLä¸­ä»æœ‰ {test_docs} ä¸ªæµ‹è¯•æ–‡æ¡£")
            except Exception as e:
                issues.append(f"PostgreSQLéªŒè¯å¤±è´¥: {e}")
        
        # éªŒè¯Redis
        if self.redis_client:
            try:
                test_keys = await self.redis_client.keys("*test*")
                if test_keys:
                    issues.append(f"Redisä¸­ä»æœ‰ {len(test_keys)} ä¸ªæµ‹è¯•é”®")
            except Exception as e:
                issues.append(f"RediséªŒè¯å¤±è´¥: {e}")
        
        # éªŒè¯Elasticsearch
        if self.es_client:
            try:
                for index in ['documents', 'document_chunks']:
                    if await self.es_client.indices.exists(index=index):
                        search_result = await self.es_client.search(
                            index=index,
                            body={
                                "query": {
                                    "bool": {
                                        "should": [
                                            {"wildcard": {"title": "*æµ‹è¯•*"}},
                                            {"wildcard": {"content": "*æµ‹è¯•*"}}
                                        ]
                                    }
                                }
                            }
                        )
                        
                        if search_result['hits']['total']['value'] > 0:
                            issues.append(f"Elasticsearchç´¢å¼• {index} ä¸­ä»æœ‰æµ‹è¯•æ•°æ®")
            except Exception as e:
                issues.append(f"ElasticsearchéªŒè¯å¤±è´¥: {e}")
        
        # éªŒè¯Neo4j
        if self.neo4j_driver:
            try:
                async with self.neo4j_driver.session() as session:
                    result = await session.run("MATCH (n) WHERE n.test_data = true RETURN count(n) as count")
                    async for record in result:
                        if record['count'] > 0:
                            issues.append(f"Neo4jä¸­ä»æœ‰ {record['count']} ä¸ªæµ‹è¯•æ•°æ®èŠ‚ç‚¹")
            except Exception as e:
                issues.append(f"Neo4jéªŒè¯å¤±è´¥: {e}")
        
        if issues:
            logger.warning("âš ï¸ æ¸…ç†éªŒè¯å‘ç°é—®é¢˜:")
            for issue in issues:
                logger.warning(f"  - {issue}")
        else:
            logger.info("âœ… æ¸…ç†éªŒè¯é€šè¿‡ï¼Œæ‰€æœ‰æµ‹è¯•æ•°æ®å·²æ¸…ç†")
    
    async def _cleanup_connections(self):
        """æ¸…ç†æ•°æ®åº“è¿æ¥"""
        logger.info("ğŸ§¹ æ¸…ç†æ•°æ®åº“è¿æ¥...")
        
        try:
            if self.pg_pool:
                await self.pg_pool.close()
            
            if self.redis_client:
                await self.redis_client.close()
            
            if self.es_client:
                await self.es_client.close()
            
            if self.neo4j_driver:
                await self.neo4j_driver.close()
            
            logger.info("âœ… æ•°æ®åº“è¿æ¥æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿æ¥æ—¶å‡ºé”™: {e}")


async def main():
    """
    ä¸»å‡½æ•°
    """
    import argparse
    
    parser = argparse.ArgumentParser(description='Knowledge RAG æµ‹è¯•ç¯å¢ƒæ¸…ç†å·¥å…·')
    parser.add_argument('--force', '-f', action='store_true', help='å¼ºåˆ¶æ¸…ç†ï¼Œè·³è¿‡ç¡®è®¤')
    parser.add_argument('--components', '-c', nargs='+', 
                       choices=['postgresql', 'redis', 'elasticsearch', 'neo4j'],
                       help='æŒ‡å®šè¦æ¸…ç†çš„ç»„ä»¶')
    
    args = parser.parse_args()
    
    cleaner = TestEnvironmentCleaner()
    
    try:
        if args.components:
            success = await cleaner.cleanup_specific(args.components)
        else:
            success = await cleaner.cleanup_all(force=args.force)
        
        if success:
            logger.info("ğŸ‰ æµ‹è¯•ç¯å¢ƒæ¸…ç†æˆåŠŸï¼")
            sys.exit(0)
        else:
            logger.error("ğŸ’¥ æµ‹è¯•ç¯å¢ƒæ¸…ç†å¤±è´¥ï¼")
            sys.exit(1)
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ¸…ç†è¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸ’¥ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())